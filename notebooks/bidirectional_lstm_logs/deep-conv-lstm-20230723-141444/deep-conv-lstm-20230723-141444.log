DEBUG: 2023-07-23 14:14:46,890: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/bidirectional_lstm_logs/deep-conv-lstm-20230723-141444/deep-conv-lstm-20230723-141444.log
DEBUG: 2023-07-23 14:14:57,989: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 14:14:57,990: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-07-23 14:14:57,993: utils.py: check_class_balance: train labels
DEBUG: 2023-07-23 14:14:57,994: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-07-23 14:14:57,994: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-07-23 14:14:57,995: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-07-23 14:14:57,996: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-07-23 14:14:57,996: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-07-23 14:14:57,997: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-07-23 14:14:57,998: utils.py: check_class_balance: test labels
DEBUG: 2023-07-23 14:14:57,999: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-07-23 14:14:57,999: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-07-23 14:14:58,001: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-07-23 14:14:58,003: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-07-23 14:14:58,004: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-07-23 14:14:58,005: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-07-23 14:15:00,078: 1755315602.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-07-23 14:15:01,137: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 14:15:01,138: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 14:15:02,059: lstm.py: __init__: Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:15:02,065: lstm.py: __init__: Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:15:02,073: lstm.py: __init__: Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:15:02,107: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 14:15:46,227: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 14:15:46,228: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6, 6)
WARNING: 2023-07-23 14:15:46,237: lstm.py: __init__: Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:15:46,242: lstm.py: __init__: Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:15:46,249: lstm.py: __init__: Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:15:46,275: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 14:15:51,558: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 14:15:51,559: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6, 6, 6)
WARNING: 2023-07-23 14:15:51,567: lstm.py: __init__: Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:15:51,572: lstm.py: __init__: Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:15:51,578: lstm.py: __init__: Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:15:51,609: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 14:16:44,054: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 14:16:44,055: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6, 6, 6, 6)
WARNING: 2023-07-23 14:16:44,064: lstm.py: __init__: Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:16:44,069: lstm.py: __init__: Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:16:44,074: lstm.py: __init__: Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:16:44,102: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
