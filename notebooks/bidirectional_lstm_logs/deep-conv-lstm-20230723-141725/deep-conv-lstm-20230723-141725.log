DEBUG: 2023-07-23 14:17:25,316: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/bidirectional_lstm_logs/deep-conv-lstm-20230723-141725/deep-conv-lstm-20230723-141725.log
DEBUG: 2023-07-23 14:17:36,372: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 14:17:36,373: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-07-23 14:17:36,376: utils.py: check_class_balance: train labels
DEBUG: 2023-07-23 14:17:36,377: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-07-23 14:17:36,377: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-07-23 14:17:36,379: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-07-23 14:17:36,379: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-07-23 14:17:36,380: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-07-23 14:17:36,381: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-07-23 14:17:36,382: utils.py: check_class_balance: test labels
DEBUG: 2023-07-23 14:17:36,383: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-07-23 14:17:36,388: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-07-23 14:17:36,389: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-07-23 14:17:36,391: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-07-23 14:17:36,391: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-07-23 14:17:36,392: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-07-23 14:17:36,426: 1755315602.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-07-23 14:17:36,459: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 14:17:36,460: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 14:17:37,370: lstm.py: __init__: Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:17:37,376: lstm.py: __init__: Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:17:37,381: lstm.py: __init__: Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:17:37,411: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 14:18:34,388: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 14:18:34,389: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6, 6)
WARNING: 2023-07-23 14:18:34,397: lstm.py: __init__: Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:18:34,405: lstm.py: __init__: Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:18:34,411: lstm.py: __init__: Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:18:34,447: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 14:23:55,398: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 14:23:55,399: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6, 6, 6)
WARNING: 2023-07-23 14:23:55,407: lstm.py: __init__: Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:23:55,416: lstm.py: __init__: Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:23:55,423: lstm.py: __init__: Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:23:55,449: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
WARNING: 2023-07-23 14:25:30,688: lstm.py: __init__: Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:25:30,693: lstm.py: __init__: Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:25:30,701: lstm.py: __init__: Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:25:39,550: lstm.py: __init__: Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:25:39,557: lstm.py: __init__: Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:25:39,562: lstm.py: __init__: Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:25:39,589: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
WARNING: 2023-07-23 14:26:21,042: lstm.py: __init__: Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:26:21,046: lstm.py: __init__: Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:26:21,058: lstm.py: __init__: Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:26:21,100: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
WARNING: 2023-07-23 14:26:57,798: lstm.py: __init__: Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:26:57,804: lstm.py: __init__: Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:26:57,814: lstm.py: __init__: Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:26:57,849: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
WARNING: 2023-07-23 14:31:46,087: lstm.py: __init__: Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:31:46,093: lstm.py: __init__: Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:31:46,101: lstm.py: __init__: Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:31:46,117: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
WARNING: 2023-07-23 14:32:02,469: lstm.py: __init__: Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:32:02,477: lstm.py: __init__: Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:32:02,482: lstm.py: __init__: Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:32:20,692: lstm.py: __init__: Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:32:20,697: lstm.py: __init__: Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:32:20,702: lstm.py: __init__: Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING: 2023-07-23 14:39:14,361: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.
