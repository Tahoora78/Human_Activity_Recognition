DEBUG: 2023-07-23 15:30:49,607: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/lstm_logs/deep-conv-lstm-20230723-153049/deep-conv-lstm-20230723-153049.log
DEBUG: 2023-07-23 15:31:00,415: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 15:31:00,416: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-07-23 15:31:00,420: utils.py: check_class_balance: train labels
DEBUG: 2023-07-23 15:31:00,421: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-07-23 15:31:00,422: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-07-23 15:31:00,423: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-07-23 15:31:00,423: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-07-23 15:31:00,424: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-07-23 15:31:00,425: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-07-23 15:31:00,426: utils.py: check_class_balance: test labels
DEBUG: 2023-07-23 15:31:00,427: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-07-23 15:31:00,428: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-07-23 15:31:00,429: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-07-23 15:31:00,430: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-07-23 15:31:00,431: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-07-23 15:31:00,432: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-07-23 15:31:00,463: 3941774885.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-07-23 15:31:00,495: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 15:31:00,496: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 15:31:02,125: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 15:31:13,169: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-07-23 15:31:31,915: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.094 - accuracy: 0.9612 - val_loss: 0.0858 - val_accuracy: 0.971
DEBUG: 2023-07-23 15:31:52,558: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0773 - accuracy: 0.9691 - val_loss: 0.0648 - val_accuracy: 0.9784
DEBUG: 2023-07-23 15:32:13,435: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1112 - accuracy: 0.95 - val_loss: 0.0677 - val_accuracy: 0.9784
DEBUG: 2023-07-23 15:32:34,117: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0615 - accuracy: 0.976 - val_loss: 0.0669 - val_accuracy: 0.9737
DEBUG: 2023-07-23 15:32:54,843: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0511 - accuracy: 0.9801 - val_loss: 0.0637 - val_accuracy: 0.9723
DEBUG: 2023-07-23 15:33:15,750: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0387 - accuracy: 0.9855 - val_loss: 0.0928 - val_accuracy: 0.975
DEBUG: 2023-07-23 15:33:36,548: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.092 - accuracy: 0.9681 - val_loss: 0.0787 - val_accuracy: 0.9723
DEBUG: 2023-07-23 15:33:57,397: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.046 - val_accuracy: 0.9865
DEBUG: 2023-07-23 15:34:18,388: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0238 - accuracy: 0.9912 - val_loss: 0.0356 - val_accuracy: 0.9865
DEBUG: 2023-07-23 15:34:39,360: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.031 - accuracy: 0.9882 - val_loss: 0.0403 - val_accuracy: 0.9879
DEBUG: 2023-07-23 15:35:00,372: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.032 - accuracy: 0.986 - val_loss: 0.0528 - val_accuracy: 0.9845
DEBUG: 2023-07-23 15:35:21,287: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0543 - accuracy: 0.9801 - val_loss: 0.044 - val_accuracy: 0.9852
DEBUG: 2023-07-23 15:35:42,250: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.026 - val_accuracy: 0.9919
DEBUG: 2023-07-23 15:36:03,244: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0308 - val_accuracy: 0.9858
DEBUG: 2023-07-23 15:36:24,265: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.0228 - val_accuracy: 0.9926
DEBUG: 2023-07-23 15:36:45,377: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0155 - val_accuracy: 0.998
DEBUG: 2023-07-23 15:37:06,452: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0122 - accuracy: 0.997 - val_loss: 0.0119 - val_accuracy: 0.998
DEBUG: 2023-07-23 15:37:27,439: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0114 - val_accuracy: 0.998
DEBUG: 2023-07-23 15:37:48,421: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0003 - accuracy: 1.0 - val_loss: 0.0111 - val_accuracy: 0.998
DEBUG: 2023-07-23 15:38:09,355: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.0001 - accuracy: 1.0 - val_loss: 0.0124 - val_accuracy: 0.998
DEBUG: 2023-07-23 15:38:24,263: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-07-23 15:38:32,871: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 15:38:32,871: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 15:38:33,591: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 15:39:01,608: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1085 - accuracy: 0.9603 - val_loss: 0.0932 - val_accuracy: 0.9588
DEBUG: 2023-07-23 15:39:22,672: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1165 - accuracy: 0.9578 - val_loss: 0.0784 - val_accuracy: 0.9615
DEBUG: 2023-07-23 15:39:43,768: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0466 - accuracy: 0.9794 - val_loss: 0.0681 - val_accuracy: 0.9737
DEBUG: 2023-07-23 15:40:04,865: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0588 - accuracy: 0.9774 - val_loss: 0.0623 - val_accuracy: 0.9683
DEBUG: 2023-07-23 15:40:26,329: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.049 - accuracy: 0.9794 - val_loss: 0.0644 - val_accuracy: 0.9777
DEBUG: 2023-07-23 15:40:47,783: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0345 - accuracy: 0.9857 - val_loss: 0.0618 - val_accuracy: 0.9851
DEBUG: 2023-07-23 15:41:09,972: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0518 - accuracy: 0.9762 - val_loss: 0.0462 - val_accuracy: 0.9804
DEBUG: 2023-07-23 15:41:31,252: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0338 - accuracy: 0.986 - val_loss: 0.0384 - val_accuracy: 0.9824
DEBUG: 2023-07-23 15:41:52,649: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0195 - accuracy: 0.9924 - val_loss: 0.0256 - val_accuracy: 0.9905
DEBUG: 2023-07-23 15:42:14,066: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0174 - accuracy: 0.9927 - val_loss: 0.0174 - val_accuracy: 0.9959
DEBUG: 2023-07-23 15:42:36,180: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.0338 - val_accuracy: 0.9878
DEBUG: 2023-07-23 15:42:58,117: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.0306 - val_accuracy: 0.9858
DEBUG: 2023-07-23 15:43:19,239: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.0406 - val_accuracy: 0.9912
DEBUG: 2023-07-23 15:43:40,500: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0137 - accuracy: 0.9948 - val_loss: 0.0141 - val_accuracy: 0.9953
DEBUG: 2023-07-23 15:44:01,535: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.03 - accuracy: 0.9902 - val_loss: 0.025 - val_accuracy: 0.9919
DEBUG: 2023-07-23 15:44:22,504: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.007 - val_accuracy: 0.9973
DEBUG: 2023-07-23 15:44:44,123: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0003 - accuracy: 1.0 - val_loss: 0.0071 - val_accuracy: 0.9973
DEBUG: 2023-07-23 15:45:05,400: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0088 - val_accuracy: 0.9973
DEBUG: 2023-07-23 15:45:26,647: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.0509 - val_accuracy: 0.9878
DEBUG: 2023-07-23 15:45:39,527: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 15:45:39,528: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 15:45:40,321: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 15:46:09,117: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.0866 - accuracy: 0.9666 - val_loss: 0.1539 - val_accuracy: 0.9548
DEBUG: 2023-07-23 15:46:30,485: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0867 - accuracy: 0.9683 - val_loss: 0.0784 - val_accuracy: 0.9764
DEBUG: 2023-07-23 15:46:52,137: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0631 - accuracy: 0.9745 - val_loss: 0.068 - val_accuracy: 0.9737
DEBUG: 2023-07-23 15:47:13,711: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0659 - accuracy: 0.9735 - val_loss: 0.0677 - val_accuracy: 0.9703
DEBUG: 2023-07-23 15:47:35,197: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0428 - accuracy: 0.983 - val_loss: 0.0566 - val_accuracy: 0.9804
DEBUG: 2023-07-23 15:47:56,725: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0663 - accuracy: 0.976 - val_loss: 0.0665 - val_accuracy: 0.9818
DEBUG: 2023-07-23 15:48:18,344: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0401 - accuracy: 0.9851 - val_loss: 0.0456 - val_accuracy: 0.9818
DEBUG: 2023-07-23 15:48:39,823: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0462 - accuracy: 0.9853 - val_loss: 0.0381 - val_accuracy: 0.9872
DEBUG: 2023-07-23 15:49:01,138: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.0405 - val_accuracy: 0.9851
DEBUG: 2023-07-23 15:49:22,547: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0455 - accuracy: 0.9835 - val_loss: 0.038 - val_accuracy: 0.9858
DEBUG: 2023-07-23 15:49:43,800: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0382 - val_accuracy: 0.9804
DEBUG: 2023-07-23 15:50:04,917: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.04 - accuracy: 0.9872 - val_loss: 0.0349 - val_accuracy: 0.9892
DEBUG: 2023-07-23 15:50:26,079: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0202 - accuracy: 0.9914 - val_loss: 0.0267 - val_accuracy: 0.9919
DEBUG: 2023-07-23 15:50:47,298: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0173 - val_accuracy: 0.9973
DEBUG: 2023-07-23 15:51:08,576: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0002 - accuracy: 1.0 - val_loss: 0.0236 - val_accuracy: 0.9966
DEBUG: 2023-07-23 15:51:29,857: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0001 - accuracy: 1.0 - val_loss: 0.0252 - val_accuracy: 0.9966
DEBUG: 2023-07-23 15:51:47,250: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 15:51:47,251: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 15:51:47,976: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 15:52:16,303: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.0811 - accuracy: 0.972 - val_loss: 0.0935 - val_accuracy: 0.9676
DEBUG: 2023-07-23 15:52:38,032: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0646 - accuracy: 0.973 - val_loss: 0.0598 - val_accuracy: 0.9723
DEBUG: 2023-07-23 15:52:59,263: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0645 - accuracy: 0.9725 - val_loss: 0.054 - val_accuracy: 0.9716
DEBUG: 2023-07-23 15:53:20,563: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0553 - accuracy: 0.9789 - val_loss: 0.0867 - val_accuracy: 0.9683
DEBUG: 2023-07-23 15:53:41,670: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0576 - accuracy: 0.9787 - val_loss: 0.0601 - val_accuracy: 0.9777
DEBUG: 2023-07-23 15:54:03,698: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0456 - accuracy: 0.9835 - val_loss: 0.0593 - val_accuracy: 0.9777
DEBUG: 2023-07-23 15:54:16,446: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 15:54:16,446: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 15:54:17,211: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 15:54:45,221: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1576 - accuracy: 0.9489 - val_loss: 0.116 - val_accuracy: 0.9588
DEBUG: 2023-07-23 15:55:06,932: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0804 - accuracy: 0.9706 - val_loss: 0.0775 - val_accuracy: 0.9703
DEBUG: 2023-07-23 15:55:28,344: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.062 - accuracy: 0.9749 - val_loss: 0.0585 - val_accuracy: 0.9804
DEBUG: 2023-07-23 15:55:49,689: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0601 - accuracy: 0.9801 - val_loss: 0.0709 - val_accuracy: 0.9811
DEBUG: 2023-07-23 15:56:10,941: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0705 - accuracy: 0.9722 - val_loss: 0.1328 - val_accuracy: 0.9399
DEBUG: 2023-07-23 15:56:32,408: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0494 - accuracy: 0.9796 - val_loss: 0.048 - val_accuracy: 0.9811
DEBUG: 2023-07-23 15:56:53,731: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.048 - accuracy: 0.9816 - val_loss: 0.0586 - val_accuracy: 0.9743
DEBUG: 2023-07-23 15:57:15,100: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0459 - accuracy: 0.9787 - val_loss: 0.0445 - val_accuracy: 0.9838
DEBUG: 2023-07-23 15:57:36,400: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.061 - accuracy: 0.986 - val_loss: 0.0719 - val_accuracy: 0.9784
DEBUG: 2023-07-23 15:57:57,949: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.0193 - val_accuracy: 0.9926
DEBUG: 2023-07-23 15:58:19,241: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.0687 - val_accuracy: 0.9831
DEBUG: 2023-07-23 15:58:40,517: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0169 - val_accuracy: 0.9919
DEBUG: 2023-07-23 15:59:01,906: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0353 - accuracy: 0.99 - val_loss: 0.0386 - val_accuracy: 0.9858
DEBUG: 2023-07-23 15:59:23,273: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0319 - val_accuracy: 0.9905
DEBUG: 2023-07-23 15:59:44,696: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0117 - val_accuracy: 0.9959
DEBUG: 2023-07-23 16:00:06,117: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.003 - accuracy: 0.9992 - val_loss: 0.006 - val_accuracy: 0.9993
DEBUG: 2023-07-23 16:00:27,512: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.004 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.998
DEBUG: 2023-07-23 16:00:48,744: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0143 - val_accuracy: 0.9953
DEBUG: 2023-07-23 16:01:09,964: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0242 - accuracy: 0.9941 - val_loss: 0.0332 - val_accuracy: 0.9885
DEBUG: 2023-07-23 16:01:31,144: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.01 - accuracy: 0.9973 - val_loss: 0.0134 - val_accuracy: 0.9953
DEBUG: 2023-07-23 16:01:40,193: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-07-23 16:01:40,195: 2155350369.py: <module>: ---train---
DEBUG: 2023-07-23 16:01:40,197: 2155350369.py: <module>: logloss=0.011999
DEBUG: 2023-07-23 16:01:40,198: 2155350369.py: <module>: accuracy=0.994194
DEBUG: 2023-07-23 16:01:40,200: 2155350369.py: <module>: precision=0.994816
DEBUG: 2023-07-23 16:01:40,203: 2155350369.py: <module>: recall=0.994635
DEBUG: 2023-07-23 16:01:40,204: 2155350369.py: <module>: f1=0.994692
DEBUG: 2023-07-23 16:01:40,205: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 1.0, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.983078, 'STANDING': 0.985073}
DEBUG: 2023-07-23 16:01:40,206: 2155350369.py: <module>: ---valid---
DEBUG: 2023-07-23 16:01:40,207: 2155350369.py: <module>: logloss=0.014329
DEBUG: 2023-07-23 16:01:40,208: 2155350369.py: <module>: accuracy=0.993788
DEBUG: 2023-07-23 16:01:40,209: 2155350369.py: <module>: precision=0.994457
DEBUG: 2023-07-23 16:01:40,210: 2155350369.py: <module>: recall=0.994259
DEBUG: 2023-07-23 16:01:40,211: 2155350369.py: <module>: f1=0.99432
DEBUG: 2023-07-23 16:01:40,214: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 1.0, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.98189, 'STANDING': 0.984028}
DEBUG: 2023-07-23 16:01:40,215: 2155350369.py: <module>: ---test---
DEBUG: 2023-07-23 16:01:40,216: 2155350369.py: <module>: logloss=0.410548
DEBUG: 2023-07-23 16:01:40,219: 2155350369.py: <module>: accuracy=0.938456
DEBUG: 2023-07-23 16:01:40,220: 2155350369.py: <module>: precision=0.93997
DEBUG: 2023-07-23 16:01:40,221: 2155350369.py: <module>: recall=0.940833
DEBUG: 2023-07-23 16:01:40,223: 2155350369.py: <module>: f1=0.939455
DEBUG: 2023-07-23 16:01:40,224: 2155350369.py: <module>: per-class f1={'LAYING': 0.990082, 'WALKING': 0.957992, 'WALKING_UPSTAIRS': 0.973549, 'WALKING_DOWNSTAIRS': 0.949336, 'SITTING': 0.878334, 'STANDING': 0.887438}
DEBUG: 2023-07-23 16:05:28,501: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-07-23 16:05:28,503: 2155350369.py: <module>: ---train---
DEBUG: 2023-07-23 16:05:28,504: 2155350369.py: <module>: logloss=0.011999
DEBUG: 2023-07-23 16:05:28,505: 2155350369.py: <module>: accuracy=0.994194
DEBUG: 2023-07-23 16:05:28,506: 2155350369.py: <module>: precision=0.994816
DEBUG: 2023-07-23 16:05:28,507: 2155350369.py: <module>: recall=0.994635
DEBUG: 2023-07-23 16:05:28,507: 2155350369.py: <module>: f1=0.994692
DEBUG: 2023-07-23 16:05:28,508: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 1.0, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.983078, 'STANDING': 0.985073}
DEBUG: 2023-07-23 16:05:28,509: 2155350369.py: <module>: ---valid---
DEBUG: 2023-07-23 16:05:28,509: 2155350369.py: <module>: logloss=0.014329
DEBUG: 2023-07-23 16:05:28,510: 2155350369.py: <module>: accuracy=0.993788
DEBUG: 2023-07-23 16:05:28,511: 2155350369.py: <module>: precision=0.994457
DEBUG: 2023-07-23 16:05:28,511: 2155350369.py: <module>: recall=0.994259
DEBUG: 2023-07-23 16:05:28,512: 2155350369.py: <module>: f1=0.99432
DEBUG: 2023-07-23 16:05:28,513: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 1.0, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.98189, 'STANDING': 0.984028}
DEBUG: 2023-07-23 16:05:28,514: 2155350369.py: <module>: ---test---
DEBUG: 2023-07-23 16:05:28,515: 2155350369.py: <module>: logloss=0.410548
DEBUG: 2023-07-23 16:05:28,515: 2155350369.py: <module>: accuracy=0.938456
DEBUG: 2023-07-23 16:05:28,516: 2155350369.py: <module>: precision=0.93997
DEBUG: 2023-07-23 16:05:28,516: 2155350369.py: <module>: recall=0.940833
DEBUG: 2023-07-23 16:05:28,518: 2155350369.py: <module>: f1=0.939455
DEBUG: 2023-07-23 16:05:28,518: 2155350369.py: <module>: per-class f1={'LAYING': 0.990082, 'WALKING': 0.957992, 'WALKING_UPSTAIRS': 0.973549, 'WALKING_DOWNSTAIRS': 0.949336, 'SITTING': 0.878334, 'STANDING': 0.887438}
DEBUG: 2023-07-23 16:05:37,350: 1695527446.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-07-23 16:05:37,354: 1695527446.py: <module>: accuracy=0.94954894754427
DEBUG: 2023-07-23 16:05:37,357: 1695527446.py: <module>: precision=0.9503528186662197
DEBUG: 2023-07-23 16:05:37,360: 1695527446.py: <module>: recall=0.9515551040301483
DEBUG: 2023-07-23 16:05:37,364: 1695527446.py: <module>: f1=0.9504523051889012
DEBUG: 2023-07-23 16:05:37,367: 1695527446.py: <module>: per-class f1=[0.99090909 0.96487603 0.98488121 0.95881007 0.89581305 0.90742438]
