DEBUG: 2023-07-21 14:49:13,648: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/lstm_logs/deep-conv-lstm-20230721-144912/deep-conv-lstm-20230721-144912.log
DEBUG: 2023-07-21 14:49:25,202: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 14:49:25,204: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-07-21 14:49:25,207: utils.py: check_class_balance: train labels
DEBUG: 2023-07-21 14:49:25,209: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-07-21 14:49:25,209: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-07-21 14:49:25,211: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-07-21 14:49:25,212: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-07-21 14:49:25,214: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-07-21 14:49:25,215: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-07-21 14:49:25,216: utils.py: check_class_balance: test labels
DEBUG: 2023-07-21 14:49:25,217: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-07-21 14:49:25,219: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-07-21 14:49:25,220: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-07-21 14:49:25,224: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-07-21 14:49:25,225: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-07-21 14:49:25,226: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-07-21 14:49:27,437: 3941774885.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-07-21 14:49:28,515: 3631112952.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 14:49:28,516: 3631112952.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-21 14:49:30,122: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 14:51:01,212: 3941774885.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-07-21 14:51:05,401: 3631112952.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 14:51:05,402: 3631112952.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6, 6)
WARNING: 2023-07-21 14:51:06,096: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 14:51:15,701: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-07-21 14:51:39,576: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.0983 - accuracy: 0.9591 - val_loss: 0.0747 - val_accuracy: 0.9696
DEBUG: 2023-07-21 14:52:06,519: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.063 - accuracy: 0.9752 - val_loss: 0.0485 - val_accuracy: 0.9845
DEBUG: 2023-07-21 14:52:33,340: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0321 - accuracy: 0.9877 - val_loss: 0.0447 - val_accuracy: 0.9845
DEBUG: 2023-07-21 14:53:00,905: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.0602 - val_accuracy: 0.9791
DEBUG: 2023-07-21 14:53:27,683: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0129 - val_accuracy: 0.9973
DEBUG: 2023-07-21 14:53:54,067: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.01 - accuracy: 0.9971 - val_loss: 0.0219 - val_accuracy: 0.9946
DEBUG: 2023-07-21 14:54:20,730: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.0245 - val_accuracy: 0.9933
DEBUG: 2023-07-21 14:54:47,248: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0277 - val_accuracy: 0.9933
DEBUG: 2023-07-21 14:55:13,921: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0067 - accuracy: 0.998 - val_loss: 0.0244 - val_accuracy: 0.9953
DEBUG: 2023-07-21 14:55:40,540: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0003 - accuracy: 1.0 - val_loss: 0.0116 - val_accuracy: 0.998
DEBUG: 2023-07-21 14:56:07,121: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0268 - accuracy: 0.9922 - val_loss: 0.0263 - val_accuracy: 0.9926
DEBUG: 2023-07-21 14:56:33,711: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0274 - val_accuracy: 0.9933
DEBUG: 2023-07-21 14:56:47,480: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-07-21 14:56:53,526: 3631112952.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 14:56:53,527: 3631112952.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6, 6)
WARNING: 2023-07-21 14:56:54,314: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 14:57:29,137: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.097 - accuracy: 0.9669 - val_loss: 0.0994 - val_accuracy: 0.9615
DEBUG: 2023-07-21 14:57:56,047: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0606 - accuracy: 0.976 - val_loss: 0.0893 - val_accuracy: 0.9635
DEBUG: 2023-07-21 14:58:22,655: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0359 - accuracy: 0.9877 - val_loss: 0.0609 - val_accuracy: 0.9838
DEBUG: 2023-07-21 14:58:49,790: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.0344 - val_accuracy: 0.9858
DEBUG: 2023-07-21 14:59:16,675: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0362 - val_accuracy: 0.9885
DEBUG: 2023-07-21 14:59:43,469: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0199 - val_accuracy: 0.9959
DEBUG: 2023-07-21 15:00:10,159: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0416 - accuracy: 0.9877 - val_loss: 0.0437 - val_accuracy: 0.9872
DEBUG: 2023-07-21 15:00:36,740: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.0233 - val_accuracy: 0.9932
DEBUG: 2023-07-21 15:01:03,290: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0178 - val_accuracy: 0.9939
DEBUG: 2023-07-21 15:01:29,764: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0002 - accuracy: 1.0 - val_loss: 0.0278 - val_accuracy: 0.9946
DEBUG: 2023-07-21 15:01:53,582: 3631112952.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 15:01:53,583: 3631112952.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6, 6)
WARNING: 2023-07-21 15:01:54,312: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 15:02:28,645: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.0763 - accuracy: 0.9671 - val_loss: 0.0906 - val_accuracy: 0.9622
DEBUG: 2023-07-21 15:02:55,508: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0393 - accuracy: 0.9838 - val_loss: 0.0493 - val_accuracy: 0.9764
DEBUG: 2023-07-21 15:03:22,346: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0256 - val_accuracy: 0.9899
DEBUG: 2023-07-21 15:03:49,353: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0213 - val_accuracy: 0.9926
DEBUG: 2023-07-21 15:04:16,514: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1142 - accuracy: 0.971 - val_loss: 0.0656 - val_accuracy: 0.9757
DEBUG: 2023-07-21 15:04:43,330: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0389 - accuracy: 0.988 - val_loss: 0.0201 - val_accuracy: 0.9912
DEBUG: 2023-07-21 15:05:10,236: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0212 - val_accuracy: 0.9959
DEBUG: 2023-07-21 15:05:37,608: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0002 - accuracy: 1.0 - val_loss: 0.03 - val_accuracy: 0.9946
DEBUG: 2023-07-21 15:06:26,577: 3631112952.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 15:06:26,578: 3631112952.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6, 6)
WARNING: 2023-07-21 15:06:27,341: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 15:07:01,574: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.103 - accuracy: 0.9575 - val_loss: 0.1098 - val_accuracy: 0.9635
DEBUG: 2023-07-21 15:07:28,262: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0478 - accuracy: 0.9806 - val_loss: 0.0487 - val_accuracy: 0.9818
DEBUG: 2023-07-21 15:07:54,927: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.036 - accuracy: 0.9878 - val_loss: 0.0373 - val_accuracy: 0.9899
DEBUG: 2023-07-21 15:08:21,409: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0644 - accuracy: 0.974 - val_loss: 0.0622 - val_accuracy: 0.973
DEBUG: 2023-07-21 15:08:47,942: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0436 - val_accuracy: 0.9838
DEBUG: 2023-07-21 15:09:14,598: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.0283 - val_accuracy: 0.9892
DEBUG: 2023-07-21 15:09:41,407: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.042 - val_accuracy: 0.9878
DEBUG: 2023-07-21 15:10:07,911: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0338 - val_accuracy: 0.9919
DEBUG: 2023-07-21 15:10:34,761: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.0418 - val_accuracy: 0.9919
DEBUG: 2023-07-21 15:10:55,411: 3631112952.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 15:10:55,412: 3631112952.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6, 6)
WARNING: 2023-07-21 15:10:56,038: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 15:11:29,559: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.0917 - accuracy: 0.962 - val_loss: 0.1208 - val_accuracy: 0.9561
DEBUG: 2023-07-21 15:11:56,262: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0537 - accuracy: 0.9776 - val_loss: 0.049 - val_accuracy: 0.9784
DEBUG: 2023-07-21 15:12:22,755: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0421 - accuracy: 0.9814 - val_loss: 0.0424 - val_accuracy: 0.977
DEBUG: 2023-07-21 15:12:49,304: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0521 - accuracy: 0.9828 - val_loss: 0.0329 - val_accuracy: 0.9885
DEBUG: 2023-07-21 15:13:15,736: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0311 - val_accuracy: 0.9919
DEBUG: 2023-07-21 15:13:42,332: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0205 - val_accuracy: 0.9953
DEBUG: 2023-07-21 15:14:08,957: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.0203 - val_accuracy: 0.9932
DEBUG: 2023-07-21 15:14:35,441: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0524 - accuracy: 0.9813 - val_loss: 0.0318 - val_accuracy: 0.9885
DEBUG: 2023-07-21 15:15:02,026: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0173 - val_accuracy: 0.9953
DEBUG: 2023-07-21 15:15:28,580: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0248 - val_accuracy: 0.9946
DEBUG: 2023-07-21 15:15:55,327: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0118 - accuracy: 0.997 - val_loss: 0.0192 - val_accuracy: 0.9953
DEBUG: 2023-07-21 15:16:21,940: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0596 - val_accuracy: 0.9851
DEBUG: 2023-07-21 15:16:48,513: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0393 - accuracy: 0.9865 - val_loss: 0.0135 - val_accuracy: 0.9946
