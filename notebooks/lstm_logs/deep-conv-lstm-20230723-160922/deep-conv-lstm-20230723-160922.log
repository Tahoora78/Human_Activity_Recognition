DEBUG: 2023-07-23 16:09:22,128: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/lstm_logs/deep-conv-lstm-20230723-160922/deep-conv-lstm-20230723-160922.log
DEBUG: 2023-07-23 16:09:33,868: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 16:09:33,869: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-07-23 16:09:33,872: utils.py: check_class_balance: train labels
DEBUG: 2023-07-23 16:09:33,873: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-07-23 16:09:33,873: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-07-23 16:09:33,874: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-07-23 16:09:33,875: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-07-23 16:09:33,876: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-07-23 16:09:33,877: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-07-23 16:09:33,878: utils.py: check_class_balance: test labels
DEBUG: 2023-07-23 16:09:33,879: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-07-23 16:09:33,880: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-07-23 16:09:33,882: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-07-23 16:09:33,882: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-07-23 16:09:33,884: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-07-23 16:09:33,885: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-07-23 16:09:33,979: 3941774885.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-07-23 16:09:34,037: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 16:09:34,040: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 16:09:35,659: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 16:09:45,392: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-07-23 16:10:00,522: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2713 - accuracy: 0.9115 - val_loss: 0.1906 - val_accuracy: 0.9406
DEBUG: 2023-07-23 16:10:17,393: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0916 - accuracy: 0.9613 - val_loss: 0.1144 - val_accuracy: 0.9555
DEBUG: 2023-07-23 16:10:34,321: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0704 - accuracy: 0.9656 - val_loss: 0.0635 - val_accuracy: 0.9777
DEBUG: 2023-07-23 16:10:51,852: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1061 - accuracy: 0.9566 - val_loss: 0.1166 - val_accuracy: 0.9494
DEBUG: 2023-07-23 16:11:09,097: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0704 - accuracy: 0.9715 - val_loss: 0.0731 - val_accuracy: 0.9757
DEBUG: 2023-07-23 16:11:26,082: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0997 - accuracy: 0.9532 - val_loss: 0.0896 - val_accuracy: 0.9582
DEBUG: 2023-07-23 16:11:43,095: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.053 - accuracy: 0.9811 - val_loss: 0.0683 - val_accuracy: 0.9825
DEBUG: 2023-07-23 16:12:00,323: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0482 - accuracy: 0.9828 - val_loss: 0.0495 - val_accuracy: 0.9831
DEBUG: 2023-07-23 16:12:17,269: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.0476 - val_accuracy: 0.9845
DEBUG: 2023-07-23 16:12:34,143: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0481 - accuracy: 0.9809 - val_loss: 0.0554 - val_accuracy: 0.9845
DEBUG: 2023-07-23 16:12:51,558: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0422 - accuracy: 0.9846 - val_loss: 0.0325 - val_accuracy: 0.9892
DEBUG: 2023-07-23 16:13:09,255: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0457 - accuracy: 0.986 - val_loss: 0.0787 - val_accuracy: 0.969
DEBUG: 2023-07-23 16:13:26,858: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0351 - accuracy: 0.9885 - val_loss: 0.0356 - val_accuracy: 0.9912
DEBUG: 2023-07-23 16:13:33,976: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-07-23 16:13:43,140: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 16:13:43,141: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 16:13:43,783: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 16:14:09,100: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2126 - accuracy: 0.9273 - val_loss: 0.1557 - val_accuracy: 0.9433
DEBUG: 2023-07-23 16:14:27,054: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0888 - accuracy: 0.9637 - val_loss: 0.0781 - val_accuracy: 0.9635
DEBUG: 2023-07-23 16:14:44,999: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0857 - accuracy: 0.9627 - val_loss: 0.1234 - val_accuracy: 0.948
DEBUG: 2023-07-23 16:15:02,798: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.064 - accuracy: 0.973 - val_loss: 0.0709 - val_accuracy: 0.9703
DEBUG: 2023-07-23 16:15:20,314: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.2393 - accuracy: 0.935 - val_loss: 0.1294 - val_accuracy: 0.9487
DEBUG: 2023-07-23 16:15:37,602: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0697 - accuracy: 0.9772 - val_loss: 0.0677 - val_accuracy: 0.973
DEBUG: 2023-07-23 16:15:55,222: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0931 - accuracy: 0.9668 - val_loss: 0.1094 - val_accuracy: 0.9622
DEBUG: 2023-07-23 16:16:13,082: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0676 - accuracy: 0.9728 - val_loss: 0.0577 - val_accuracy: 0.9764
DEBUG: 2023-07-23 16:16:30,191: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.079 - accuracy: 0.975 - val_loss: 0.0875 - val_accuracy: 0.9703
DEBUG: 2023-07-23 16:16:47,732: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0657 - accuracy: 0.9755 - val_loss: 0.063 - val_accuracy: 0.977
DEBUG: 2023-07-23 16:17:05,619: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1018 - accuracy: 0.9619 - val_loss: 0.0816 - val_accuracy: 0.9689
DEBUG: 2023-07-23 16:17:22,857: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0491 - accuracy: 0.9848 - val_loss: 0.0955 - val_accuracy: 0.9683
DEBUG: 2023-07-23 16:17:39,930: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0499 - accuracy: 0.9791 - val_loss: 0.0505 - val_accuracy: 0.9811
DEBUG: 2023-07-23 16:17:56,997: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0375 - accuracy: 0.9846 - val_loss: 0.0412 - val_accuracy: 0.9845
DEBUG: 2023-07-23 16:18:14,201: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.04 - accuracy: 0.987 - val_loss: 0.0627 - val_accuracy: 0.9791
DEBUG: 2023-07-23 16:18:31,263: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0466 - accuracy: 0.9791 - val_loss: 0.0513 - val_accuracy: 0.9777
DEBUG: 2023-07-23 16:18:48,820: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0255 - accuracy: 0.9897 - val_loss: 0.0412 - val_accuracy: 0.9845
DEBUG: 2023-07-23 16:19:05,958: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0245 - accuracy: 0.9892 - val_loss: 0.0318 - val_accuracy: 0.9851
DEBUG: 2023-07-23 16:19:22,967: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0517 - accuracy: 0.9806 - val_loss: 0.0576 - val_accuracy: 0.9737
DEBUG: 2023-07-23 16:19:45,115: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 16:19:45,115: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 16:19:45,625: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 16:20:07,058: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1691 - accuracy: 0.9382 - val_loss: 0.1413 - val_accuracy: 0.9453
DEBUG: 2023-07-23 16:20:24,214: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1354 - accuracy: 0.9502 - val_loss: 0.0858 - val_accuracy: 0.9737
DEBUG: 2023-07-23 16:20:41,307: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0867 - accuracy: 0.9666 - val_loss: 0.1006 - val_accuracy: 0.9669
DEBUG: 2023-07-23 16:20:58,297: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.0681 - val_accuracy: 0.9797
DEBUG: 2023-07-23 16:21:15,328: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.071 - accuracy: 0.9765 - val_loss: 0.1106 - val_accuracy: 0.9716
DEBUG: 2023-07-23 16:21:32,430: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0511 - accuracy: 0.9792 - val_loss: 0.0705 - val_accuracy: 0.9764
DEBUG: 2023-07-23 16:21:49,643: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0487 - accuracy: 0.9863 - val_loss: 0.0584 - val_accuracy: 0.9804
DEBUG: 2023-07-23 16:22:06,808: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0417 - accuracy: 0.9851 - val_loss: 0.0464 - val_accuracy: 0.9851
DEBUG: 2023-07-23 16:22:23,927: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0351 - val_accuracy: 0.9872
DEBUG: 2023-07-23 16:22:41,050: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0553 - val_accuracy: 0.9865
DEBUG: 2023-07-23 16:22:58,361: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.0253 - val_accuracy: 0.9939
DEBUG: 2023-07-23 16:23:15,355: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0728 - accuracy: 0.977 - val_loss: 0.0962 - val_accuracy: 0.9561
DEBUG: 2023-07-23 16:23:32,811: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.021 - accuracy: 0.9948 - val_loss: 0.0348 - val_accuracy: 0.9858
DEBUG: 2023-07-23 16:23:49,835: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0214 - val_accuracy: 0.9926
DEBUG: 2023-07-23 16:24:07,467: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.0269 - val_accuracy: 0.9919
DEBUG: 2023-07-23 16:24:24,872: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0478 - accuracy: 0.9808 - val_loss: 0.0429 - val_accuracy: 0.9845
DEBUG: 2023-07-23 16:24:42,432: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0106 - accuracy: 0.997 - val_loss: 0.0122 - val_accuracy: 0.9953
DEBUG: 2023-07-23 16:24:59,629: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0495 - accuracy: 0.9803 - val_loss: 0.0323 - val_accuracy: 0.9838
DEBUG: 2023-07-23 16:25:16,865: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0105 - accuracy: 0.998 - val_loss: 0.0269 - val_accuracy: 0.9939
DEBUG: 2023-07-23 16:25:34,132: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.0048 - accuracy: 0.9978 - val_loss: 0.0093 - val_accuracy: 0.9966
DEBUG: 2023-07-23 16:25:51,391: keras_callback.py: on_epoch_end: Epoch 210/10000 - loss: 0.0004 - accuracy: 1.0 - val_loss: 0.0077 - val_accuracy: 0.998
DEBUG: 2023-07-23 16:26:08,620: keras_callback.py: on_epoch_end: Epoch 220/10000 - loss: 0.056 - accuracy: 0.9875 - val_loss: 0.058 - val_accuracy: 0.9831
DEBUG: 2023-07-23 16:26:26,005: keras_callback.py: on_epoch_end: Epoch 230/10000 - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0154 - val_accuracy: 0.9939
DEBUG: 2023-07-23 16:26:44,496: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 16:26:44,497: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 16:26:45,257: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 16:27:09,215: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2041 - accuracy: 0.9246 - val_loss: 0.1854 - val_accuracy: 0.9453
DEBUG: 2023-07-23 16:27:27,043: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.139 - accuracy: 0.9553 - val_loss: 0.1254 - val_accuracy: 0.9581
DEBUG: 2023-07-23 16:27:45,501: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0935 - accuracy: 0.962 - val_loss: 0.0931 - val_accuracy: 0.9676
DEBUG: 2023-07-23 16:28:03,058: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0605 - accuracy: 0.9769 - val_loss: 0.0726 - val_accuracy: 0.9689
DEBUG: 2023-07-23 16:28:20,637: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.111 - accuracy: 0.9642 - val_loss: 0.1426 - val_accuracy: 0.9554
DEBUG: 2023-07-23 16:28:38,258: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0913 - accuracy: 0.9581 - val_loss: 0.0933 - val_accuracy: 0.9642
DEBUG: 2023-07-23 16:28:56,121: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1025 - accuracy: 0.9649 - val_loss: 0.1013 - val_accuracy: 0.9541
DEBUG: 2023-07-23 16:29:15,030: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0558 - accuracy: 0.9772 - val_loss: 0.06 - val_accuracy: 0.9743
DEBUG: 2023-07-23 16:29:33,932: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0565 - accuracy: 0.977 - val_loss: 0.0534 - val_accuracy: 0.9737
DEBUG: 2023-07-23 16:29:53,498: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0518 - accuracy: 0.9794 - val_loss: 0.0535 - val_accuracy: 0.9784
DEBUG: 2023-07-23 16:30:10,751: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0394 - accuracy: 0.983 - val_loss: 0.3699 - val_accuracy: 0.9392
DEBUG: 2023-07-23 16:30:27,947: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0398 - accuracy: 0.9841 - val_loss: 0.0588 - val_accuracy: 0.977
DEBUG: 2023-07-23 16:30:45,094: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0634 - accuracy: 0.9772 - val_loss: 0.0752 - val_accuracy: 0.973
DEBUG: 2023-07-23 16:30:55,447: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 16:30:55,448: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 16:30:56,005: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 16:31:18,067: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1343 - accuracy: 0.9495 - val_loss: 0.13 - val_accuracy: 0.9521
DEBUG: 2023-07-23 16:31:35,354: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.0831 - accuracy: 0.9681 - val_loss: 0.0791 - val_accuracy: 0.9656
DEBUG: 2023-07-23 16:31:52,331: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.087 - accuracy: 0.9657 - val_loss: 0.0726 - val_accuracy: 0.971
DEBUG: 2023-07-23 16:32:09,313: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0862 - accuracy: 0.9654 - val_loss: 0.1003 - val_accuracy: 0.9676
DEBUG: 2023-07-23 16:32:26,437: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0469 - accuracy: 0.9828 - val_loss: 0.0669 - val_accuracy: 0.9764
DEBUG: 2023-07-23 16:32:43,549: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0336 - accuracy: 0.9873 - val_loss: 0.0616 - val_accuracy: 0.9851
DEBUG: 2023-07-23 16:33:00,907: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0684 - accuracy: 0.9722 - val_loss: 0.0723 - val_accuracy: 0.9743
DEBUG: 2023-07-23 16:33:18,501: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0658 - accuracy: 0.9792 - val_loss: 0.1324 - val_accuracy: 0.9561
DEBUG: 2023-07-23 16:33:36,013: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0411 - accuracy: 0.984 - val_loss: 0.0409 - val_accuracy: 0.9845
DEBUG: 2023-07-23 16:33:54,382: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0254 - accuracy: 0.9904 - val_loss: 0.0908 - val_accuracy: 0.9777
DEBUG: 2023-07-23 16:34:13,579: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.0348 - val_accuracy: 0.9885
DEBUG: 2023-07-23 16:34:35,086: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0195 - accuracy: 0.9954 - val_loss: 0.0441 - val_accuracy: 0.9872
DEBUG: 2023-07-23 16:34:54,746: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0448 - val_accuracy: 0.9851
DEBUG: 2023-07-23 16:35:12,595: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0096 - accuracy: 0.9958 - val_loss: 0.0226 - val_accuracy: 0.9932
DEBUG: 2023-07-23 16:35:30,144: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0287 - val_accuracy: 0.9899
DEBUG: 2023-07-23 16:35:48,101: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0167 - accuracy: 0.9931 - val_loss: 0.0302 - val_accuracy: 0.9865
DEBUG: 2023-07-23 16:36:05,811: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0285 - accuracy: 0.989 - val_loss: 0.0222 - val_accuracy: 0.9926
DEBUG: 2023-07-23 16:38:18,371: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-07-23 16:38:18,373: 2155350369.py: <module>: ---train---
DEBUG: 2023-07-23 16:38:18,375: 2155350369.py: <module>: logloss=0.014064
DEBUG: 2023-07-23 16:38:18,376: 2155350369.py: <module>: accuracy=0.993755
DEBUG: 2023-07-23 16:38:18,377: 2155350369.py: <module>: precision=0.994484
DEBUG: 2023-07-23 16:38:18,378: 2155350369.py: <module>: recall=0.994171
DEBUG: 2023-07-23 16:38:18,379: 2155350369.py: <module>: f1=0.994291
DEBUG: 2023-07-23 16:38:18,434: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 1.0, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.981813, 'STANDING': 0.983936}
DEBUG: 2023-07-23 16:38:18,435: 2155350369.py: <module>: ---valid---
DEBUG: 2023-07-23 16:38:18,435: 2155350369.py: <module>: logloss=0.02292
DEBUG: 2023-07-23 16:38:18,437: 2155350369.py: <module>: accuracy=0.990683
DEBUG: 2023-07-23 16:38:18,437: 2155350369.py: <module>: precision=0.991738
DEBUG: 2023-07-23 16:38:18,438: 2155350369.py: <module>: recall=0.991265
DEBUG: 2023-07-23 16:38:18,439: 2155350369.py: <module>: f1=0.991435
DEBUG: 2023-07-23 16:38:18,440: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.999184, 'WALKING_UPSTAIRS': 0.999065, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.973586, 'STANDING': 0.976773}
DEBUG: 2023-07-23 16:38:18,441: 2155350369.py: <module>: ---test---
DEBUG: 2023-07-23 16:38:18,442: 2155350369.py: <module>: logloss=0.478896
DEBUG: 2023-07-23 16:38:18,444: 2155350369.py: <module>: accuracy=0.929168
DEBUG: 2023-07-23 16:38:18,445: 2155350369.py: <module>: precision=0.930036
DEBUG: 2023-07-23 16:38:18,446: 2155350369.py: <module>: recall=0.930877
DEBUG: 2023-07-23 16:38:18,447: 2155350369.py: <module>: f1=0.92953
DEBUG: 2023-07-23 16:38:18,448: 2155350369.py: <module>: per-class f1={'LAYING': 0.996001, 'WALKING': 0.93807, 'WALKING_UPSTAIRS': 0.957514, 'WALKING_DOWNSTAIRS': 0.93429, 'SITTING': 0.866218, 'STANDING': 0.885086}
DEBUG: 2023-07-23 16:38:19,381: 1695527446.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-07-23 16:38:19,389: 1695527446.py: <module>: accuracy=0.9365185432676244
DEBUG: 2023-07-23 16:38:19,394: 1695527446.py: <module>: precision=0.9373068227973239
DEBUG: 2023-07-23 16:38:19,400: 1695527446.py: <module>: recall=0.9383001520126943
DEBUG: 2023-07-23 16:38:19,404: 1695527446.py: <module>: f1=0.9367157537886981
DEBUG: 2023-07-23 16:38:19,408: 1695527446.py: <module>: per-class f1=[0.99543379 0.93558606 0.97518878 0.93095768 0.88339921 0.899729  ]
