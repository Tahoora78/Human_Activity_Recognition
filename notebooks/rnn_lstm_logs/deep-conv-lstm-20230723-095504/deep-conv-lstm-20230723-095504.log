DEBUG: 2023-07-23 09:55:04,605: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/rnn_lstm_logs/deep-conv-lstm-20230723-095504/deep-conv-lstm-20230723-095504.log
DEBUG: 2023-07-23 09:55:16,469: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 09:55:16,470: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-07-23 09:55:16,473: utils.py: check_class_balance: train labels
DEBUG: 2023-07-23 09:55:16,473: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-07-23 09:55:16,474: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-07-23 09:55:16,475: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-07-23 09:55:16,476: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-07-23 09:55:16,477: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-07-23 09:55:16,479: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-07-23 09:55:16,480: utils.py: check_class_balance: test labels
DEBUG: 2023-07-23 09:55:16,481: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-07-23 09:55:16,482: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-07-23 09:55:16,484: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-07-23 09:55:16,484: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-07-23 09:55:16,485: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-07-23 09:55:16,486: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-07-23 09:55:16,518: 582463155.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-07-23 09:55:16,553: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 09:55:16,554: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 09:55:18,987: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 09:55:26,017: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-07-23 09:55:34,254: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1185 - accuracy: 0.9531 - val_loss: 0.1083 - val_accuracy: 0.9615
DEBUG: 2023-07-23 09:55:47,347: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1013 - accuracy: 0.9566 - val_loss: 0.098 - val_accuracy: 0.969
DEBUG: 2023-07-23 09:56:02,891: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0968 - accuracy: 0.9573 - val_loss: 0.0973 - val_accuracy: 0.9656
DEBUG: 2023-07-23 09:56:17,888: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0998 - accuracy: 0.9558 - val_loss: 0.0862 - val_accuracy: 0.9663
DEBUG: 2023-07-23 09:56:31,877: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1022 - accuracy: 0.9561 - val_loss: 0.0859 - val_accuracy: 0.969
DEBUG: 2023-07-23 09:56:45,139: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0845 - accuracy: 0.96 - val_loss: 0.0802 - val_accuracy: 0.9676
DEBUG: 2023-07-23 09:56:52,986: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-07-23 09:56:58,476: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 09:56:58,476: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 09:56:58,794: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 09:57:13,745: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1379 - accuracy: 0.9494 - val_loss: 0.1466 - val_accuracy: 0.9453
DEBUG: 2023-07-23 09:57:26,489: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.102 - accuracy: 0.9603 - val_loss: 0.116 - val_accuracy: 0.9581
DEBUG: 2023-07-23 09:57:39,166: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1142 - accuracy: 0.9553 - val_loss: 0.1056 - val_accuracy: 0.9534
DEBUG: 2023-07-23 09:57:51,728: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0805 - accuracy: 0.9656 - val_loss: 0.0913 - val_accuracy: 0.9588
DEBUG: 2023-07-23 09:58:04,476: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0912 - accuracy: 0.9649 - val_loss: 0.0756 - val_accuracy: 0.9669
DEBUG: 2023-07-23 09:58:18,254: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0877 - accuracy: 0.9622 - val_loss: 0.0819 - val_accuracy: 0.9696
DEBUG: 2023-07-23 09:58:31,284: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.08 - accuracy: 0.9649 - val_loss: 0.079 - val_accuracy: 0.9615
DEBUG: 2023-07-23 09:58:45,409: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1475 - accuracy: 0.9526 - val_loss: 0.1786 - val_accuracy: 0.948
DEBUG: 2023-07-23 09:58:58,521: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0743 - accuracy: 0.9693 - val_loss: 0.0628 - val_accuracy: 0.9703
DEBUG: 2023-07-23 09:59:13,185: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.094 - accuracy: 0.9617 - val_loss: 0.0936 - val_accuracy: 0.9588
DEBUG: 2023-07-23 09:59:28,117: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1002 - accuracy: 0.9625 - val_loss: 0.0738 - val_accuracy: 0.9669
DEBUG: 2023-07-23 09:59:39,526: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0653 - accuracy: 0.9674 - val_loss: 0.0544 - val_accuracy: 0.9669
DEBUG: 2023-07-23 09:59:53,782: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.072 - accuracy: 0.9681 - val_loss: 0.059 - val_accuracy: 0.9723
DEBUG: 2023-07-23 10:00:08,382: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.072 - accuracy: 0.9635 - val_loss: 0.058 - val_accuracy: 0.9656
DEBUG: 2023-07-23 10:00:23,209: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0694 - accuracy: 0.9696 - val_loss: 0.0581 - val_accuracy: 0.9683
DEBUG: 2023-07-23 10:00:37,427: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0708 - accuracy: 0.9706 - val_loss: 0.0792 - val_accuracy: 0.9629
DEBUG: 2023-07-23 10:00:53,066: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0518 - accuracy: 0.9804 - val_loss: 0.0715 - val_accuracy: 0.9689
DEBUG: 2023-07-23 10:01:05,022: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0991 - accuracy: 0.9654 - val_loss: 0.0741 - val_accuracy: 0.9743
DEBUG: 2023-07-23 10:01:18,932: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0841 - accuracy: 0.9652 - val_loss: 0.0606 - val_accuracy: 0.9757
DEBUG: 2023-07-23 10:01:32,095: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.0671 - accuracy: 0.9732 - val_loss: 0.0864 - val_accuracy: 0.9656
DEBUG: 2023-07-23 10:01:45,067: keras_callback.py: on_epoch_end: Epoch 210/10000 - loss: 0.0793 - accuracy: 0.975 - val_loss: 0.1096 - val_accuracy: 0.9615
DEBUG: 2023-07-23 10:01:56,704: keras_callback.py: on_epoch_end: Epoch 220/10000 - loss: 0.0718 - accuracy: 0.9688 - val_loss: 0.0642 - val_accuracy: 0.9716
DEBUG: 2023-07-23 10:02:10,641: keras_callback.py: on_epoch_end: Epoch 230/10000 - loss: 0.0972 - accuracy: 0.9588 - val_loss: 0.0976 - val_accuracy: 0.9581
DEBUG: 2023-07-23 10:02:28,195: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 10:02:28,196: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 10:02:28,542: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 10:02:44,367: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2419 - accuracy: 0.9214 - val_loss: 0.3204 - val_accuracy: 0.8812
DEBUG: 2023-07-23 10:02:57,732: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1241 - accuracy: 0.9534 - val_loss: 0.143 - val_accuracy: 0.9426
DEBUG: 2023-07-23 10:03:13,048: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1532 - accuracy: 0.944 - val_loss: 0.1278 - val_accuracy: 0.9467
DEBUG: 2023-07-23 10:03:28,683: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1314 - accuracy: 0.9521 - val_loss: 0.1443 - val_accuracy: 0.9453
DEBUG: 2023-07-23 10:03:44,307: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.085 - accuracy: 0.963 - val_loss: 0.1185 - val_accuracy: 0.9534
DEBUG: 2023-07-23 10:04:01,626: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0979 - accuracy: 0.9581 - val_loss: 0.1122 - val_accuracy: 0.9527
DEBUG: 2023-07-23 10:04:16,181: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1148 - accuracy: 0.9561 - val_loss: 0.137 - val_accuracy: 0.944
DEBUG: 2023-07-23 10:04:32,714: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0805 - accuracy: 0.9644 - val_loss: 0.1016 - val_accuracy: 0.9548
DEBUG: 2023-07-23 10:04:49,314: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0707 - accuracy: 0.9673 - val_loss: 0.0914 - val_accuracy: 0.9588
DEBUG: 2023-07-23 10:05:05,785: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0633 - accuracy: 0.9681 - val_loss: 0.0941 - val_accuracy: 0.9554
DEBUG: 2023-07-23 10:05:20,771: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0735 - accuracy: 0.9644 - val_loss: 0.088 - val_accuracy: 0.9575
DEBUG: 2023-07-23 10:05:34,737: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0785 - accuracy: 0.9649 - val_loss: 0.0951 - val_accuracy: 0.9541
DEBUG: 2023-07-23 10:05:50,986: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0599 - accuracy: 0.9703 - val_loss: 0.0763 - val_accuracy: 0.9689
DEBUG: 2023-07-23 10:06:07,305: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0828 - accuracy: 0.9598 - val_loss: 0.0797 - val_accuracy: 0.9642
DEBUG: 2023-07-23 10:06:23,059: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0751 - accuracy: 0.9659 - val_loss: 0.0832 - val_accuracy: 0.9656
DEBUG: 2023-07-23 10:06:39,293: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0963 - accuracy: 0.962 - val_loss: 0.0951 - val_accuracy: 0.9568
DEBUG: 2023-07-23 10:06:56,212: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0927 - accuracy: 0.9602 - val_loss: 0.0947 - val_accuracy: 0.9568
DEBUG: 2023-07-23 10:07:13,955: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0734 - accuracy: 0.9644 - val_loss: 0.0947 - val_accuracy: 0.9581
DEBUG: 2023-07-23 10:07:32,266: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 10:07:32,267: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 10:07:32,844: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 10:07:42,912: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1407 - accuracy: 0.9473 - val_loss: 0.1164 - val_accuracy: 0.9487
DEBUG: 2023-07-23 10:07:49,190: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1146 - accuracy: 0.9559 - val_loss: 0.091 - val_accuracy: 0.9554
DEBUG: 2023-07-23 10:07:55,419: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0834 - accuracy: 0.9639 - val_loss: 0.1044 - val_accuracy: 0.9656
DEBUG: 2023-07-23 10:08:01,711: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1 - accuracy: 0.9586 - val_loss: 0.0883 - val_accuracy: 0.9635
DEBUG: 2023-07-23 10:08:08,010: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0795 - accuracy: 0.9691 - val_loss: 0.0733 - val_accuracy: 0.9696
DEBUG: 2023-07-23 10:08:14,291: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0836 - accuracy: 0.9679 - val_loss: 0.0731 - val_accuracy: 0.9703
DEBUG: 2023-07-23 10:08:20,515: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0921 - accuracy: 0.9683 - val_loss: 0.1254 - val_accuracy: 0.946
DEBUG: 2023-07-23 10:08:26,756: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0938 - accuracy: 0.9671 - val_loss: 0.0919 - val_accuracy: 0.9642
DEBUG: 2023-07-23 10:08:33,520: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-23 10:08:33,521: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-23 10:08:33,930: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-23 10:08:43,355: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1769 - accuracy: 0.9392 - val_loss: 0.2305 - val_accuracy: 0.9392
DEBUG: 2023-07-23 10:08:49,764: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1074 - accuracy: 0.9566 - val_loss: 0.1088 - val_accuracy: 0.9541
DEBUG: 2023-07-23 10:08:56,146: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0912 - accuracy: 0.961 - val_loss: 0.0912 - val_accuracy: 0.9615
DEBUG: 2023-07-23 10:09:02,395: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1128 - accuracy: 0.9553 - val_loss: 0.1257 - val_accuracy: 0.9548
DEBUG: 2023-07-23 10:09:08,736: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0907 - accuracy: 0.9654 - val_loss: 0.1061 - val_accuracy: 0.9514
DEBUG: 2023-07-23 10:09:15,043: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0689 - accuracy: 0.9669 - val_loss: 0.0929 - val_accuracy: 0.9669
DEBUG: 2023-07-23 10:09:21,307: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0766 - accuracy: 0.9686 - val_loss: 0.0859 - val_accuracy: 0.9608
DEBUG: 2023-07-23 10:09:27,604: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.07 - accuracy: 0.9718 - val_loss: 0.0832 - val_accuracy: 0.9669
DEBUG: 2023-07-23 10:09:33,895: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1685 - accuracy: 0.9462 - val_loss: 0.1439 - val_accuracy: 0.9386
DEBUG: 2023-07-23 10:09:40,201: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.07 - accuracy: 0.9654 - val_loss: 0.0726 - val_accuracy: 0.9689
DEBUG: 2023-07-23 10:09:46,521: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0691 - accuracy: 0.9693 - val_loss: 0.0811 - val_accuracy: 0.9689
DEBUG: 2023-07-23 10:09:54,392: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-07-23 10:09:54,394: 2155350369.py: <module>: ---train---
DEBUG: 2023-07-23 10:09:54,395: 2155350369.py: <module>: logloss=0.055428
DEBUG: 2023-07-23 10:09:54,396: 2155350369.py: <module>: accuracy=0.976201
DEBUG: 2023-07-23 10:09:54,397: 2155350369.py: <module>: precision=0.978938
DEBUG: 2023-07-23 10:09:54,399: 2155350369.py: <module>: recall=0.977918
DEBUG: 2023-07-23 10:09:54,400: 2155350369.py: <module>: f1=0.97822
DEBUG: 2023-07-23 10:09:54,403: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 1.0, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.930144, 'STANDING': 0.939178}
DEBUG: 2023-07-23 10:09:54,405: 2155350369.py: <module>: ---valid---
DEBUG: 2023-07-23 10:09:54,406: 2155350369.py: <module>: logloss=0.061677
DEBUG: 2023-07-23 10:09:54,408: 2155350369.py: <module>: accuracy=0.974346
DEBUG: 2023-07-23 10:09:54,411: 2155350369.py: <module>: precision=0.977192
DEBUG: 2023-07-23 10:09:54,413: 2155350369.py: <module>: recall=0.976187
DEBUG: 2023-07-23 10:09:54,419: 2155350369.py: <module>: f1=0.976401
DEBUG: 2023-07-23 10:09:54,422: 2155350369.py: <module>: per-class f1={'LAYING': 0.999646, 'WALKING': 0.998367, 'WALKING_UPSTAIRS': 0.999534, 'WALKING_DOWNSTAIRS': 0.998987, 'SITTING': 0.92601, 'STANDING': 0.935861}
DEBUG: 2023-07-23 10:09:54,423: 2155350369.py: <module>: ---test---
DEBUG: 2023-07-23 10:09:54,425: 2155350369.py: <module>: logloss=0.370221
DEBUG: 2023-07-23 10:09:54,427: 2155350369.py: <module>: accuracy=0.939258
DEBUG: 2023-07-23 10:09:54,429: 2155350369.py: <module>: precision=0.940232
DEBUG: 2023-07-23 10:09:54,432: 2155350369.py: <module>: recall=0.940972
DEBUG: 2023-07-23 10:09:54,433: 2155350369.py: <module>: f1=0.939891
DEBUG: 2023-07-23 10:09:54,436: 2155350369.py: <module>: per-class f1={'LAYING': 0.995631, 'WALKING': 0.946283, 'WALKING_UPSTAIRS': 0.967161, 'WALKING_DOWNSTAIRS': 0.948856, 'SITTING': 0.88386, 'STANDING': 0.897557}
DEBUG: 2023-07-23 10:09:54,450: 1672468834.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-07-23 10:09:54,454: 1672468834.py: <module>: accuracy=0.9492148346140996
DEBUG: 2023-07-23 10:09:54,457: 1672468834.py: <module>: precision=0.9495194976139824
DEBUG: 2023-07-23 10:09:54,461: 1672468834.py: <module>: recall=0.9510946552144363
DEBUG: 2023-07-23 10:09:54,466: 1672468834.py: <module>: f1=0.9495114198863682
DEBUG: 2023-07-23 10:09:54,471: 1672468834.py: <module>: per-class f1=[0.99908341 0.95368421 0.97985154 0.9478458  0.90184645 0.9147571 ]
DEBUG: 2023-07-23 10:11:14,627: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-07-23 10:11:14,629: 2155350369.py: <module>: ---train---
DEBUG: 2023-07-23 10:11:14,631: 2155350369.py: <module>: logloss=0.055428
DEBUG: 2023-07-23 10:11:14,631: 2155350369.py: <module>: accuracy=0.976201
DEBUG: 2023-07-23 10:11:14,633: 2155350369.py: <module>: precision=0.978938
DEBUG: 2023-07-23 10:11:14,633: 2155350369.py: <module>: recall=0.977918
DEBUG: 2023-07-23 10:11:14,634: 2155350369.py: <module>: f1=0.97822
DEBUG: 2023-07-23 10:11:14,635: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 1.0, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.930144, 'STANDING': 0.939178}
DEBUG: 2023-07-23 10:11:14,636: 2155350369.py: <module>: ---valid---
DEBUG: 2023-07-23 10:11:14,637: 2155350369.py: <module>: logloss=0.061677
DEBUG: 2023-07-23 10:11:14,638: 2155350369.py: <module>: accuracy=0.974346
DEBUG: 2023-07-23 10:11:14,638: 2155350369.py: <module>: precision=0.977192
DEBUG: 2023-07-23 10:11:14,639: 2155350369.py: <module>: recall=0.976187
DEBUG: 2023-07-23 10:11:14,640: 2155350369.py: <module>: f1=0.976401
DEBUG: 2023-07-23 10:11:14,641: 2155350369.py: <module>: per-class f1={'LAYING': 0.999646, 'WALKING': 0.998367, 'WALKING_UPSTAIRS': 0.999534, 'WALKING_DOWNSTAIRS': 0.998987, 'SITTING': 0.92601, 'STANDING': 0.935861}
DEBUG: 2023-07-23 10:11:14,642: 2155350369.py: <module>: ---test---
DEBUG: 2023-07-23 10:11:14,643: 2155350369.py: <module>: logloss=0.370221
DEBUG: 2023-07-23 10:11:14,644: 2155350369.py: <module>: accuracy=0.939258
DEBUG: 2023-07-23 10:11:14,645: 2155350369.py: <module>: precision=0.940232
DEBUG: 2023-07-23 10:11:14,646: 2155350369.py: <module>: recall=0.940972
DEBUG: 2023-07-23 10:11:14,647: 2155350369.py: <module>: f1=0.939891
DEBUG: 2023-07-23 10:11:14,648: 2155350369.py: <module>: per-class f1={'LAYING': 0.995631, 'WALKING': 0.946283, 'WALKING_UPSTAIRS': 0.967161, 'WALKING_DOWNSTAIRS': 0.948856, 'SITTING': 0.88386, 'STANDING': 0.897557}
DEBUG: 2023-07-23 10:11:18,351: 1672468834.py: <module>: ---Final Test Scores Averaged over Folds---
