DEBUG: 2023-07-21 15:46:27,833: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/rnn_lstm_logs/deep-conv-lstm-20230721-154626/deep-conv-lstm-20230721-154626.log
DEBUG: 2023-07-21 15:46:40,055: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 15:46:40,056: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-07-21 15:46:40,060: utils.py: check_class_balance: train labels
DEBUG: 2023-07-21 15:46:40,061: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-07-21 15:46:40,061: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-07-21 15:46:40,062: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-07-21 15:46:40,064: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-07-21 15:46:40,065: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-07-21 15:46:40,066: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-07-21 15:46:40,067: utils.py: check_class_balance: test labels
DEBUG: 2023-07-21 15:46:40,067: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-07-21 15:46:40,069: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-07-21 15:46:40,069: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-07-21 15:46:40,070: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-07-21 15:46:40,071: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-07-21 15:46:40,072: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-07-21 15:46:42,703: 582463155.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-07-21 15:46:43,583: 3631112952.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 15:46:43,584: 3631112952.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-21 15:46:46,135: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 15:46:53,266: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-07-21 15:46:59,085: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2006 - accuracy: 0.9338 - val_loss: 0.2281 - val_accuracy: 0.9379
DEBUG: 2023-07-21 15:47:05,454: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1087 - accuracy: 0.9553 - val_loss: 0.1211 - val_accuracy: 0.9528
DEBUG: 2023-07-21 15:47:11,724: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0964 - accuracy: 0.9591 - val_loss: 0.1143 - val_accuracy: 0.9636
DEBUG: 2023-07-21 15:47:17,911: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0956 - accuracy: 0.9608 - val_loss: 0.0922 - val_accuracy: 0.971
DEBUG: 2023-07-21 15:47:24,082: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0867 - accuracy: 0.9651 - val_loss: 0.0835 - val_accuracy: 0.9737
DEBUG: 2023-07-21 15:47:30,249: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0835 - accuracy: 0.9679 - val_loss: 0.0829 - val_accuracy: 0.9771
DEBUG: 2023-07-21 15:47:36,390: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1039 - accuracy: 0.9595 - val_loss: 0.0884 - val_accuracy: 0.9656
DEBUG: 2023-07-21 15:47:42,585: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0836 - accuracy: 0.9644 - val_loss: 0.081 - val_accuracy: 0.9737
DEBUG: 2023-07-21 15:47:48,764: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.083 - accuracy: 0.9684 - val_loss: 0.0867 - val_accuracy: 0.9737
DEBUG: 2023-07-21 15:47:54,945: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.075 - accuracy: 0.9676 - val_loss: 0.0895 - val_accuracy: 0.9703
DEBUG: 2023-07-21 15:47:59,544: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-07-21 15:48:02,230: 3631112952.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 15:48:02,231: 3631112952.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-21 15:48:02,562: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 15:48:12,293: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2319 - accuracy: 0.9197 - val_loss: 0.2048 - val_accuracy: 0.9298
DEBUG: 2023-07-21 15:48:18,605: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1434 - accuracy: 0.9458 - val_loss: 0.1538 - val_accuracy: 0.946
DEBUG: 2023-07-21 15:48:24,943: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1394 - accuracy: 0.9462 - val_loss: 0.1235 - val_accuracy: 0.9541
DEBUG: 2023-07-21 15:48:31,256: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.112 - accuracy: 0.9556 - val_loss: 0.1159 - val_accuracy: 0.9534
DEBUG: 2023-07-21 15:48:37,566: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1008 - accuracy: 0.9598 - val_loss: 0.1406 - val_accuracy: 0.9534
DEBUG: 2023-07-21 15:48:43,869: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0913 - accuracy: 0.9625 - val_loss: 0.0933 - val_accuracy: 0.9608
DEBUG: 2023-07-21 15:48:50,195: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0904 - accuracy: 0.9634 - val_loss: 0.0744 - val_accuracy: 0.9568
DEBUG: 2023-07-21 15:48:56,436: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0918 - accuracy: 0.9635 - val_loss: 0.1124 - val_accuracy: 0.9514
DEBUG: 2023-07-21 15:49:02,727: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0971 - accuracy: 0.9641 - val_loss: 0.1028 - val_accuracy: 0.9602
DEBUG: 2023-07-21 15:49:09,073: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0913 - accuracy: 0.9644 - val_loss: 0.074 - val_accuracy: 0.9656
DEBUG: 2023-07-21 15:49:15,357: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0815 - accuracy: 0.9598 - val_loss: 0.0787 - val_accuracy: 0.9615
DEBUG: 2023-07-21 15:49:21,670: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0789 - accuracy: 0.9671 - val_loss: 0.0852 - val_accuracy: 0.9649
DEBUG: 2023-07-21 15:49:27,935: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1228 - accuracy: 0.9527 - val_loss: 0.1106 - val_accuracy: 0.9561
DEBUG: 2023-07-21 15:49:34,202: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.1116 - accuracy: 0.9566 - val_loss: 0.0946 - val_accuracy: 0.9622
DEBUG: 2023-07-21 15:49:40,886: 3631112952.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 15:49:40,886: 3631112952.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-21 15:49:41,263: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 15:49:51,006: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2456 - accuracy: 0.9234 - val_loss: 0.2331 - val_accuracy: 0.9156
DEBUG: 2023-07-21 15:49:57,265: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1436 - accuracy: 0.9519 - val_loss: 0.2667 - val_accuracy: 0.9372
DEBUG: 2023-07-21 15:50:03,582: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1054 - accuracy: 0.9578 - val_loss: 0.1101 - val_accuracy: 0.948
DEBUG: 2023-07-21 15:50:09,917: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1138 - accuracy: 0.95 - val_loss: 0.1351 - val_accuracy: 0.9453
DEBUG: 2023-07-21 15:50:16,171: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0995 - accuracy: 0.9581 - val_loss: 0.1112 - val_accuracy: 0.9494
DEBUG: 2023-07-21 15:50:22,481: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.086 - accuracy: 0.9612 - val_loss: 0.0983 - val_accuracy: 0.9527
DEBUG: 2023-07-21 15:50:28,774: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1065 - accuracy: 0.9588 - val_loss: 0.1176 - val_accuracy: 0.946
DEBUG: 2023-07-21 15:50:35,064: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0822 - accuracy: 0.963 - val_loss: 0.1137 - val_accuracy: 0.9494
DEBUG: 2023-07-21 15:50:41,334: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.071 - accuracy: 0.9681 - val_loss: 0.097 - val_accuracy: 0.9588
DEBUG: 2023-07-21 15:50:46,414: 3631112952.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 15:50:46,415: 3631112952.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-21 15:50:46,759: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 15:50:56,322: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1606 - accuracy: 0.9453 - val_loss: 0.1453 - val_accuracy: 0.9446
DEBUG: 2023-07-21 15:51:02,722: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1489 - accuracy: 0.9419 - val_loss: 0.0885 - val_accuracy: 0.9534
DEBUG: 2023-07-21 15:51:09,103: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0851 - accuracy: 0.9608 - val_loss: 0.0929 - val_accuracy: 0.9615
DEBUG: 2023-07-21 15:51:15,483: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0794 - accuracy: 0.9666 - val_loss: 0.0749 - val_accuracy: 0.9622
DEBUG: 2023-07-21 15:51:21,952: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0877 - accuracy: 0.962 - val_loss: 0.0848 - val_accuracy: 0.9608
DEBUG: 2023-07-21 15:51:28,243: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0901 - accuracy: 0.9615 - val_loss: 0.076 - val_accuracy: 0.9608
DEBUG: 2023-07-21 15:51:34,625: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0836 - accuracy: 0.9637 - val_loss: 0.0737 - val_accuracy: 0.9669
DEBUG: 2023-07-21 15:51:42,425: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0743 - accuracy: 0.97 - val_loss: 0.0798 - val_accuracy: 0.9696
DEBUG: 2023-07-21 15:51:49,288: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0798 - accuracy: 0.9674 - val_loss: 0.0772 - val_accuracy: 0.9662
DEBUG: 2023-07-21 15:51:56,029: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1087 - accuracy: 0.9565 - val_loss: 0.0707 - val_accuracy: 0.9669
DEBUG: 2023-07-21 15:52:02,440: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0692 - accuracy: 0.974 - val_loss: 0.1008 - val_accuracy: 0.9581
DEBUG: 2023-07-21 15:52:09,017: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.064 - accuracy: 0.974 - val_loss: 0.0827 - val_accuracy: 0.9642
DEBUG: 2023-07-21 15:52:15,973: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.067 - accuracy: 0.9754 - val_loss: 0.0627 - val_accuracy: 0.9737
DEBUG: 2023-07-21 15:52:23,767: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.074 - accuracy: 0.9703 - val_loss: 0.068 - val_accuracy: 0.9723
DEBUG: 2023-07-21 15:52:30,744: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0801 - accuracy: 0.9683 - val_loss: 0.0883 - val_accuracy: 0.9662
DEBUG: 2023-07-21 15:52:37,369: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0679 - accuracy: 0.9705 - val_loss: 0.0699 - val_accuracy: 0.9689
DEBUG: 2023-07-21 15:52:42,323: 3631112952.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-07-21 15:52:42,324: 3631112952.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-07-21 15:52:42,728: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-07-21 15:52:54,458: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.139 - accuracy: 0.9477 - val_loss: 0.1108 - val_accuracy: 0.9527
DEBUG: 2023-07-21 15:53:01,632: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.098 - accuracy: 0.9586 - val_loss: 0.096 - val_accuracy: 0.9581
DEBUG: 2023-07-21 15:53:08,691: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1042 - accuracy: 0.9553 - val_loss: 0.1448 - val_accuracy: 0.9318
DEBUG: 2023-07-21 15:53:15,941: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0873 - accuracy: 0.9635 - val_loss: 0.1012 - val_accuracy: 0.9615
DEBUG: 2023-07-21 15:53:23,296: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0953 - accuracy: 0.9603 - val_loss: 0.0905 - val_accuracy: 0.9602
DEBUG: 2023-07-21 15:53:32,105: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0753 - accuracy: 0.9662 - val_loss: 0.0893 - val_accuracy: 0.9676
DEBUG: 2023-07-21 15:53:39,049: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0816 - accuracy: 0.9661 - val_loss: 0.0758 - val_accuracy: 0.9629
DEBUG: 2023-07-21 15:53:46,058: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.068 - accuracy: 0.9683 - val_loss: 0.0665 - val_accuracy: 0.9669
DEBUG: 2023-07-21 15:53:52,761: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0682 - accuracy: 0.9691 - val_loss: 0.0706 - val_accuracy: 0.9743
DEBUG: 2023-07-21 15:53:59,444: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0624 - accuracy: 0.9725 - val_loss: 0.0723 - val_accuracy: 0.977
