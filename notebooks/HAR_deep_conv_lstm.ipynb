{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from logging import basicConfig, getLogger, StreamHandler, DEBUG, WARNING\n",
    "import os\n",
    "import sys\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow import keras\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from src.data_prep.load import load_raw_data\n",
    "from src.utils import check_class_balance, round\n",
    "from src.utils import plot_feature_importance, plot_shap_summary, plot_confusion_matrix\n",
    "from models.deep_conv_lstm import train_and_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_DIR = os.path.dirname(os.path.abspath('__file__'))  # Path to current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEC_TIME = \"deep-conv-lstm-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "LOG_DIR = os.path.join(CUR_DIR, f\"../logs/deep_cnn_lstm_logs/{EXEC_TIME}\")\n",
    "os.makedirs(LOG_DIR, exist_ok=True)  # Create log directory\n",
    "\n",
    "formatter = \"%(levelname)s: %(asctime)s: %(filename)s: %(funcName)s: %(message)s\"\n",
    "basicConfig(filename=f\"{LOG_DIR}/{EXEC_TIME}.log\", level=DEBUG, format=formatter)\n",
    "mpl_logger = getLogger(\"matplotlib\")  # Suppress matplotlib logging\n",
    "mpl_logger.setLevel(WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle logging to both logging and stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/deep_cnn_lstm_logs/deep-conv-lstm-20230730-143924/deep-conv-lstm-20230730-143924.log\n",
      "/home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/deep_cnn_lstm_logs/deep-conv-lstm-20230730-143924/deep-conv-lstm-20230730-143924.log\n",
      "/home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/deep_cnn_lstm_logs/deep-conv-lstm-20230730-143924/deep-conv-lstm-20230730-143924.log\n",
      "X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)\n",
      "X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)\n",
      "X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)\n",
      "y_train.shape=(7406, 1) y_test.shape=(2993, 1)\n",
      "y_train.shape=(7406, 1) y_test.shape=(2993, 1)\n",
      "y_train.shape=(7406, 1) y_test.shape=(2993, 1)\n",
      "train labels\n",
      "train labels\n",
      "train labels\n",
      "LAYING (0): 1412 samples (19.07 %)\n",
      "LAYING (0): 1412 samples (19.07 %)\n",
      "LAYING (0): 1412 samples (19.07 %)\n",
      "WALKING (1): 1224 samples (16.53 %)\n",
      "WALKING (1): 1224 samples (16.53 %)\n",
      "WALKING (1): 1224 samples (16.53 %)\n",
      "WALKING_UPSTAIRS (2): 1072 samples (14.47 %)\n",
      "WALKING_UPSTAIRS (2): 1072 samples (14.47 %)\n",
      "WALKING_UPSTAIRS (2): 1072 samples (14.47 %)\n",
      "WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)\n",
      "WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)\n",
      "WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)\n",
      "SITTING (4): 1290 samples (17.42 %)\n",
      "SITTING (4): 1290 samples (17.42 %)\n",
      "SITTING (4): 1290 samples (17.42 %)\n",
      "STANDING (5): 1421 samples (19.19 %)\n",
      "STANDING (5): 1421 samples (19.19 %)\n",
      "STANDING (5): 1421 samples (19.19 %)\n",
      "test labels\n",
      "test labels\n",
      "test labels\n",
      "LAYING (0): 545 samples (18.21 %)\n",
      "LAYING (0): 545 samples (18.21 %)\n",
      "LAYING (0): 545 samples (18.21 %)\n",
      "WALKING (1): 496 samples (16.57 %)\n",
      "WALKING (1): 496 samples (16.57 %)\n",
      "WALKING (1): 496 samples (16.57 %)\n",
      "WALKING_UPSTAIRS (2): 470 samples (15.7 %)\n",
      "WALKING_UPSTAIRS (2): 470 samples (15.7 %)\n",
      "WALKING_UPSTAIRS (2): 470 samples (15.7 %)\n",
      "WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)\n",
      "WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)\n",
      "WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)\n",
      "SITTING (4): 507 samples (16.94 %)\n",
      "SITTING (4): 507 samples (16.94 %)\n",
      "SITTING (4): 507 samples (16.94 %)\n",
      "STANDING (5): 556 samples (18.58 %)\n",
      "STANDING (5): 556 samples (18.58 %)\n",
      "STANDING (5): 556 samples (18.58 %)\n"
     ]
    }
   ],
   "source": [
    "getLogger().addHandler(StreamHandler(sys.stdout))\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.debug(f\"{LOG_DIR}/{EXEC_TIME}.log\")\n",
    "\n",
    "X_train, X_test, y_train, y_test, label2act, act2label = load_raw_data()\n",
    "logger.debug(f\"{X_train.shape=} {X_test.shape=}\")\n",
    "logger.debug(f\"{y_train.shape=} {y_test.shape=}\")\n",
    "\n",
    "check_class_balance(y_train.flatten(), y_test.flatten(), label2act=label2act)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data by preserving the percentage of samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=71)\n",
    "valid_preds = np.zeros((X_train.shape[0], 6))\n",
    "test_preds = np.zeros((n_splits, X_test.shape[0], 6))\n",
    "models = []\n",
    "scores: Dict[str, Dict[str, List[Any]]] = {\n",
    "    \"logloss\": {\"train\": [], \"valid\": [], \"test\": []},\n",
    "    \"accuracy\": {\"train\": [], \"valid\": [], \"test\": []},\n",
    "    \"precision\": {\"train\": [], \"valid\": [], \"test\": []},\n",
    "    \"recall\": {\"train\": [], \"valid\": [], \"test\": []},\n",
    "    \"f1\": {\"train\": [], \"valid\": [], \"test\": []},\n",
    "    \"cm\": {\"train\": [], \"valid\": [], \"test\": []},\n",
    "    \"per_class_f1\": {\"train\": [], \"valid\": [], \"test\": []},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.0001, 'verbose': 0}\n",
      "dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.0001, 'verbose': 0}\n",
      "dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.0001, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(CUR_DIR, \"../configs/default.json\"), \"r\") as f:\n",
    "    dcl_params = json.load(f)[\"deep_conv_lstm_params\"]\n",
    "    logger.debug(f\"{dcl_params=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)\n",
      "X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)\n",
      "X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)\n",
      "y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)\n",
      "y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)\n",
      "y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 14:39:41.424269: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-30 14:39:41.426450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-30 14:39:41.428527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-30 14:39:41.704463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-30 14:39:41.706287: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-30 14:39:41.707695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm_8\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mX_tr\u001b[39m.\u001b[39mshape\u001b[39m=}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mX_val\u001b[39m.\u001b[39mshape\u001b[39m=}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mX_test\u001b[39m.\u001b[39mshape\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00my_tr\u001b[39m.\u001b[39mshape\u001b[39m=}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00my_val\u001b[39m.\u001b[39mshape\u001b[39m=}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00my_test\u001b[39m.\u001b[39mshape\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m pred_tr, pred_val, pred_test, model \u001b[39m=\u001b[39m train_and_predict(\n\u001b[1;32m     16\u001b[0m     LOG_DIR, fold_id, X_tr, X_val, X_test, y_tr, y_val, dcl_params\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m models\u001b[39m.\u001b[39mappend(model)\n\u001b[1;32m     20\u001b[0m valid_preds[valid_index] \u001b[39m=\u001b[39m pred_val\n",
      "File \u001b[0;32m~/Projects/college_project/Human_Activity_Recognition/notebooks/../models/deep_conv_lstm.py:39\u001b[0m, in \u001b[0;36mtrain_and_predict\u001b[0;34m(LOG_DIR, fold_id, X_train, X_valid, X_test, y_train, y_valid, dcl_params)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_and_predict\u001b[39m(\n\u001b[1;32m     20\u001b[0m     LOG_DIR: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     21\u001b[0m     fold_id: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     dcl_params: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     28\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray, Model]:\n\u001b[1;32m     29\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train DeepConvLSTM\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m        X_train, X_valid, X_test: input signals of shape (num_samples, window_size, num_channels, 1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m        model: trained best model\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     model \u001b[39m=\u001b[39m build_model(\n\u001b[1;32m     40\u001b[0m         input_shape\u001b[39m=\u001b[39;49mX_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m:], output_dim\u001b[39m=\u001b[39;49my_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], lr\u001b[39m=\u001b[39;49mdcl_params[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m     plot_model(model, path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mLOG_DIR\u001b[39m}\u001b[39;00m\u001b[39m/model.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m     callbacks \u001b[39m=\u001b[39m create_callback(\n\u001b[1;32m     45\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     46\u001b[0m         path_chpt\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mLOG_DIR\u001b[39m}\u001b[39;00m\u001b[39m/trained_model_fold\u001b[39m\u001b[39m{\u001b[39;00mfold_id\u001b[39m}\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m     48\u001b[0m         epochs\u001b[39m=\u001b[39mdcl_params[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     49\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/college_project/Human_Activity_Recognition/notebooks/../models/deep_conv_lstm.py:108\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(input_shape, output_dim, lr)\u001b[0m\n\u001b[1;32m    106\u001b[0m model\u001b[39m.\u001b[39madd(LSTM(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtanh\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    107\u001b[0m model\u001b[39m.\u001b[39madd(Dropout(\u001b[39m0.5\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m--> 108\u001b[0m model\u001b[39m.\u001b[39;49madd(LSTM(\u001b[39m64\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtanh\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    109\u001b[0m model\u001b[39m.\u001b[39madd(Dropout(\u001b[39m0.5\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    110\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m6\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/input_spec.py:235\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    233\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[0;32m--> 235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    237\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"lstm_8\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)"
     ]
    }
   ],
   "source": [
    "y_test = keras.utils.to_categorical(y_test, 6)\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_tr = X_train[train_index, :]\n",
    "    X_val = X_train[valid_index, :]\n",
    "    y_tr = y_train[train_index]\n",
    "    y_val = y_train[valid_index]\n",
    "    \n",
    "    y_tr = keras.utils.to_categorical(y_tr, 6)\n",
    "    y_val = keras.utils.to_categorical(y_val, 6)\n",
    "\n",
    "    logger.debug(f\"{X_tr.shape=} {X_val.shape=} {X_test.shape=}\")\n",
    "    logger.debug(f\"{y_tr.shape=} {y_val.shape=} {y_test.shape=}\")\n",
    "\n",
    "    pred_tr, pred_val, pred_test, model = train_and_predict(\n",
    "        LOG_DIR, fold_id, X_tr, X_val, X_test, y_tr, y_val, dcl_params\n",
    "    )\n",
    "    models.append(model)\n",
    "\n",
    "    valid_preds[valid_index] = pred_val\n",
    "    test_preds[fold_id] = pred_test\n",
    "\n",
    "    for pred, X, y, mode in zip(\n",
    "        [pred_tr, pred_val, pred_test], [X_tr, X_val, X_test], [y_tr, y_val, y_test], [\"train\", \"valid\", \"test\"]\n",
    "    ):\n",
    "        loss, acc = model.evaluate(X, y, verbose=0)\n",
    "        pred = pred.argmax(axis=1)\n",
    "        y = y.argmax(axis=1)\n",
    "        scores[\"logloss\"][mode].append(loss)\n",
    "        scores[\"accuracy\"][mode].append(acc)\n",
    "        scores[\"precision\"][mode].append(precision_score(y, pred, average=\"macro\"))\n",
    "        scores[\"recall\"][mode].append(recall_score(y, pred, average=\"macro\"))\n",
    "        scores[\"f1\"][mode].append(f1_score(y, pred, average=\"macro\"))\n",
    "        scores[\"cm\"][mode].append(confusion_matrix(y, pred, normalize=\"true\"))\n",
    "        scores[\"per_class_f1\"][mode].append(f1_score(y, pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output cross validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"---Cross Validation Scores---\")\n",
    "for mode in [\"train\", \"valid\", \"test\"]:\n",
    "    logger.debug(f\"---{mode}---\")\n",
    "    for metric in [\"logloss\", \"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "        logger.debug(f\"{metric}={round(np.mean(scores[metric][mode]))}\")\n",
    "\n",
    "    class_f1_mat = scores[\"per_class_f1\"][mode]\n",
    "    class_f1_result = {}\n",
    "    for class_id in range(6):\n",
    "        mean_class_f1 = np.mean([class_f1_mat[i][class_id] for i in range(n_splits)])\n",
    "        class_f1_result[label2act[class_id]] = mean_class_f1\n",
    "    logger.debug(f\"per-class f1={round(class_f1_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output final scores averaged over folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"---Final Test Scores Averaged over Folds---\")\n",
    "test_pred = np.mean(test_preds, axis=0).argmax(axis=1)  # average over folds\n",
    "y_test = y_test.argmax(axis=1)\n",
    "logger.debug(f\"accuracy={accuracy_score(y_test, test_pred)}\")\n",
    "logger.debug(f\"precision={precision_score(y_test, test_pred, average='macro')}\")\n",
    "logger.debug(f\"recall={recall_score(y_test, test_pred, average='macro')}\")\n",
    "logger.debug(f\"f1={f1_score(y_test, test_pred, average='macro')}\")\n",
    "logger.debug(f\"per-class f1={f1_score(y_test, test_pred, average=None)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    cms=scores[\"cm\"],\n",
    "    labels=[\n",
    "        \"LAYING\",\n",
    "        \"WALKING\",\n",
    "        \"WALKING_UPSTAIRS\",\n",
    "        \"WALKING_DOWNSTAIRS\",\n",
    "        \"SITTING\",\n",
    "        \"STANDING\",\n",
    "    ],\n",
    "    path=f\"{LOG_DIR}/comfusion_matrix.png\",\n",
    ")\n",
    "\n",
    "np.save(f\"{LOG_DIR}/valid_oof.npy\", valid_preds)\n",
    "np.save(f\"{LOG_DIR}/test_oof.npy\", np.mean(test_preds, axis=0))  # Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    y_predicted_train = model.predict(X_train).argmax(axis=1)\n",
    "\n",
    "    y_predicted_test = model.predict(X_test).argmax(axis=1)\n",
    "    print(\"Train acc, error\",accuracy_score( y_train, y_predicted_train), np.sqrt(metrics.mean_squared_error(y_train, y_predicted_train)), \n",
    "          \"Test acc, error\", accuracy_score( y_test, y_predicted_test), np.sqrt(metrics.mean_squared_error(y_test, y_predicted_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
