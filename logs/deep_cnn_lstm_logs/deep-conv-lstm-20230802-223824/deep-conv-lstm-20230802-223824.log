DEBUG: 2023-08-02 22:38:24,075: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/deep_cnn_lstm_logs/deep-conv-lstm-20230802-223824/deep-conv-lstm-20230802-223824.log
DEBUG: 2023-08-02 22:38:35,102: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 22:38:35,102: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 22:38:35,106: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 22:38:35,107: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 22:38:35,107: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 22:38:35,108: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 22:38:35,109: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 22:38:35,109: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 22:38:35,110: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 22:38:35,111: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 22:38:35,112: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 22:38:35,113: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 22:38:35,114: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 22:38:35,115: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 22:38:35,115: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 22:38:35,116: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 22:38:35,148: 3941774885.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.0001, 'verbose': 0}
DEBUG: 2023-08-02 22:38:35,181: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 22:38:35,182: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 22:38:39,602: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 22:38:52,036: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 22:38:58,219: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2322 - accuracy: 0.9423 - val_loss: 0.2123 - val_accuracy: 0.9487
DEBUG: 2023-08-02 22:39:04,760: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2052 - accuracy: 0.946 - val_loss: 0.1727 - val_accuracy: 0.9588
DEBUG: 2023-08-02 22:39:11,780: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1625 - accuracy: 0.9531 - val_loss: 0.1199 - val_accuracy: 0.9703
DEBUG: 2023-08-02 22:39:18,502: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1603 - accuracy: 0.9561 - val_loss: 0.1183 - val_accuracy: 0.969
DEBUG: 2023-08-02 22:39:25,271: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1485 - accuracy: 0.9571 - val_loss: 0.1236 - val_accuracy: 0.9723
DEBUG: 2023-08-02 22:39:31,947: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1162 - accuracy: 0.9669 - val_loss: 0.1494 - val_accuracy: 0.9622
DEBUG: 2023-08-02 22:39:38,349: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1339 - accuracy: 0.958 - val_loss: 0.099 - val_accuracy: 0.9703
DEBUG: 2023-08-02 22:39:44,661: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1233 - accuracy: 0.9563 - val_loss: 0.0906 - val_accuracy: 0.9683
DEBUG: 2023-08-02 22:39:51,332: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1178 - accuracy: 0.9674 - val_loss: 0.094 - val_accuracy: 0.9737
DEBUG: 2023-08-02 22:39:57,760: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1233 - accuracy: 0.9575 - val_loss: 0.0998 - val_accuracy: 0.9703
DEBUG: 2023-08-02 22:40:04,719: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1245 - accuracy: 0.9612 - val_loss: 0.0916 - val_accuracy: 0.971
DEBUG: 2023-08-02 22:40:11,191: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0936 - accuracy: 0.9696 - val_loss: 0.0712 - val_accuracy: 0.9791
DEBUG: 2023-08-02 22:40:18,160: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0869 - accuracy: 0.9767 - val_loss: 0.0639 - val_accuracy: 0.9838
DEBUG: 2023-08-02 22:40:25,272: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0888 - accuracy: 0.975 - val_loss: 0.0625 - val_accuracy: 0.9838
DEBUG: 2023-08-02 22:40:31,956: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.083 - accuracy: 0.9762 - val_loss: 0.0641 - val_accuracy: 0.9838
DEBUG: 2023-08-02 22:40:38,587: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.1007 - accuracy: 0.9738 - val_loss: 0.0806 - val_accuracy: 0.9798
DEBUG: 2023-08-02 22:40:45,315: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.1147 - accuracy: 0.9588 - val_loss: 0.0879 - val_accuracy: 0.973
DEBUG: 2023-08-02 22:40:48,372: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 22:40:54,820: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 22:40:54,821: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 22:40:55,395: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 22:41:07,603: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2405 - accuracy: 0.9457 - val_loss: 0.2129 - val_accuracy: 0.9467
DEBUG: 2023-08-02 22:41:14,100: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2848 - accuracy: 0.9403 - val_loss: 0.1947 - val_accuracy: 0.9507
DEBUG: 2023-08-02 22:41:20,308: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1446 - accuracy: 0.9647 - val_loss: 0.1374 - val_accuracy: 0.9656
DEBUG: 2023-08-02 22:41:26,759: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1166 - accuracy: 0.9689 - val_loss: 0.1197 - val_accuracy: 0.9669
DEBUG: 2023-08-02 22:41:33,210: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0923 - accuracy: 0.9806 - val_loss: 0.0824 - val_accuracy: 0.9784
DEBUG: 2023-08-02 22:41:40,521: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1156 - accuracy: 0.9747 - val_loss: 0.0964 - val_accuracy: 0.971
DEBUG: 2023-08-02 22:41:47,543: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0739 - accuracy: 0.9848 - val_loss: 0.0726 - val_accuracy: 0.9804
DEBUG: 2023-08-02 22:41:54,625: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0795 - accuracy: 0.985 - val_loss: 0.0862 - val_accuracy: 0.9764
DEBUG: 2023-08-02 22:42:04,043: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 22:42:04,044: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 22:42:04,579: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 22:42:16,319: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2755 - accuracy: 0.936 - val_loss: 0.2249 - val_accuracy: 0.9413
DEBUG: 2023-08-02 22:42:22,775: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2044 - accuracy: 0.9465 - val_loss: 0.1772 - val_accuracy: 0.9446
DEBUG: 2023-08-02 22:42:29,356: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.171 - accuracy: 0.9551 - val_loss: 0.1586 - val_accuracy: 0.9514
DEBUG: 2023-08-02 22:42:35,969: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1625 - accuracy: 0.9477 - val_loss: 0.1473 - val_accuracy: 0.9527
DEBUG: 2023-08-02 22:42:42,980: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.194 - accuracy: 0.9433 - val_loss: 0.1664 - val_accuracy: 0.9534
DEBUG: 2023-08-02 22:42:49,436: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.179 - accuracy: 0.95 - val_loss: 0.1531 - val_accuracy: 0.9473
DEBUG: 2023-08-02 22:42:55,986: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1287 - accuracy: 0.9598 - val_loss: 0.1166 - val_accuracy: 0.9588
DEBUG: 2023-08-02 22:43:02,824: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1197 - accuracy: 0.9573 - val_loss: 0.1174 - val_accuracy: 0.9595
DEBUG: 2023-08-02 22:43:12,472: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 22:43:12,473: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 22:43:13,094: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 22:43:25,603: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2245 - accuracy: 0.9482 - val_loss: 0.1597 - val_accuracy: 0.9608
DEBUG: 2023-08-02 22:43:32,584: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1758 - accuracy: 0.9539 - val_loss: 0.1588 - val_accuracy: 0.9602
DEBUG: 2023-08-02 22:43:39,181: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1818 - accuracy: 0.9511 - val_loss: 0.1301 - val_accuracy: 0.9669
DEBUG: 2023-08-02 22:43:45,990: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1308 - accuracy: 0.9603 - val_loss: 0.1063 - val_accuracy: 0.9656
DEBUG: 2023-08-02 22:43:52,570: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.115 - accuracy: 0.9644 - val_loss: 0.099 - val_accuracy: 0.9703
DEBUG: 2023-08-02 22:43:59,231: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0951 - accuracy: 0.9711 - val_loss: 0.0916 - val_accuracy: 0.9656
DEBUG: 2023-08-02 22:44:05,983: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0979 - accuracy: 0.9684 - val_loss: 0.0958 - val_accuracy: 0.9676
DEBUG: 2023-08-02 22:44:12,588: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1342 - accuracy: 0.961 - val_loss: 0.0988 - val_accuracy: 0.9656
DEBUG: 2023-08-02 22:44:18,967: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0899 - accuracy: 0.9688 - val_loss: 0.1018 - val_accuracy: 0.9662
DEBUG: 2023-08-02 22:44:25,334: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0968 - accuracy: 0.9681 - val_loss: 0.0923 - val_accuracy: 0.9662
DEBUG: 2023-08-02 22:44:32,114: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1129 - accuracy: 0.9654 - val_loss: 0.2789 - val_accuracy: 0.9426
DEBUG: 2023-08-02 22:44:38,332: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0827 - accuracy: 0.9737 - val_loss: 0.0816 - val_accuracy: 0.9608
DEBUG: 2023-08-02 22:44:44,746: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0741 - accuracy: 0.9774 - val_loss: 0.0729 - val_accuracy: 0.9764
DEBUG: 2023-08-02 22:44:51,943: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0757 - accuracy: 0.9752 - val_loss: 0.0813 - val_accuracy: 0.9635
DEBUG: 2023-08-02 22:44:58,903: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0887 - accuracy: 0.9757 - val_loss: 0.0994 - val_accuracy: 0.9716
DEBUG: 2023-08-02 22:45:06,200: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0732 - accuracy: 0.9796 - val_loss: 0.0617 - val_accuracy: 0.9818
DEBUG: 2023-08-02 22:45:13,346: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0779 - accuracy: 0.9779 - val_loss: 0.0647 - val_accuracy: 0.9777
DEBUG: 2023-08-02 22:45:20,349: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0789 - accuracy: 0.9693 - val_loss: 0.0665 - val_accuracy: 0.973
DEBUG: 2023-08-02 22:45:27,453: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0714 - accuracy: 0.9757 - val_loss: 0.0644 - val_accuracy: 0.9764
DEBUG: 2023-08-02 22:45:34,800: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 22:45:34,801: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 22:45:35,396: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 22:45:47,458: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2641 - accuracy: 0.9381 - val_loss: 0.2373 - val_accuracy: 0.9332
DEBUG: 2023-08-02 22:45:53,840: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2024 - accuracy: 0.9445 - val_loss: 0.161 - val_accuracy: 0.95
DEBUG: 2023-08-02 22:46:00,361: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1357 - accuracy: 0.9605 - val_loss: 0.1572 - val_accuracy: 0.9527
DEBUG: 2023-08-02 22:46:06,632: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1179 - accuracy: 0.9635 - val_loss: 0.1139 - val_accuracy: 0.9656
DEBUG: 2023-08-02 22:46:13,098: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1078 - accuracy: 0.9671 - val_loss: 0.1001 - val_accuracy: 0.9676
DEBUG: 2023-08-02 22:46:19,711: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1413 - accuracy: 0.9548 - val_loss: 0.162 - val_accuracy: 0.9608
DEBUG: 2023-08-02 22:46:26,043: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0903 - accuracy: 0.9725 - val_loss: 0.0968 - val_accuracy: 0.9676
DEBUG: 2023-08-02 22:46:32,538: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.071 - accuracy: 0.9797 - val_loss: 0.0682 - val_accuracy: 0.9811
DEBUG: 2023-08-02 22:46:38,888: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0776 - accuracy: 0.9722 - val_loss: 0.0943 - val_accuracy: 0.9676
DEBUG: 2023-08-02 22:46:45,280: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0766 - accuracy: 0.9787 - val_loss: 0.0874 - val_accuracy: 0.973
DEBUG: 2023-08-02 22:46:51,638: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1098 - accuracy: 0.9674 - val_loss: 0.0947 - val_accuracy: 0.9683
DEBUG: 2023-08-02 22:46:58,110: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0577 - accuracy: 0.9835 - val_loss: 0.0588 - val_accuracy: 0.9824
DEBUG: 2023-08-02 22:47:04,485: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0639 - accuracy: 0.9818 - val_loss: 0.0578 - val_accuracy: 0.9851
DEBUG: 2023-08-02 22:47:10,826: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.075 - accuracy: 0.9808 - val_loss: 0.076 - val_accuracy: 0.9811
DEBUG: 2023-08-02 22:47:17,421: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0825 - accuracy: 0.974 - val_loss: 0.1032 - val_accuracy: 0.9656
DEBUG: 2023-08-02 22:47:23,803: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0829 - accuracy: 0.9801 - val_loss: 0.1281 - val_accuracy: 0.9635
DEBUG: 2023-08-02 23:07:33,831: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 23:07:33,833: 2155350369.py: <module>: ---train---
DEBUG: 2023-08-02 23:07:33,835: 2155350369.py: <module>: logloss=0.069158
DEBUG: 2023-08-02 23:07:33,836: 2155350369.py: <module>: accuracy=0.980826
DEBUG: 2023-08-02 23:07:33,837: 2155350369.py: <module>: precision=0.982982
DEBUG: 2023-08-02 23:07:33,838: 2155350369.py: <module>: recall=0.982066
DEBUG: 2023-08-02 23:07:33,839: 2155350369.py: <module>: f1=0.982343
DEBUG: 2023-08-02 23:07:33,840: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.998572, 'WALKING_UPSTAIRS': 0.999417, 'WALKING_DOWNSTAIRS': 0.998349, 'SITTING': 0.945446, 'STANDING': 0.952276}
DEBUG: 2023-08-02 23:07:33,840: 2155350369.py: <module>: ---valid---
DEBUG: 2023-08-02 23:07:33,841: 2155350369.py: <module>: logloss=0.069841
DEBUG: 2023-08-02 23:07:33,842: 2155350369.py: <module>: accuracy=0.980016
DEBUG: 2023-08-02 23:07:33,844: 2155350369.py: <module>: precision=0.982207
DEBUG: 2023-08-02 23:07:33,845: 2155350369.py: <module>: recall=0.981472
DEBUG: 2023-08-02 23:07:33,846: 2155350369.py: <module>: f1=0.981643
DEBUG: 2023-08-02 23:07:33,848: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.998367, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 0.998987, 'SITTING': 0.94308, 'STANDING': 0.949425}
DEBUG: 2023-08-02 23:07:33,849: 2155350369.py: <module>: ---test---
DEBUG: 2023-08-02 23:07:33,850: 2155350369.py: <module>: logloss=0.424359
DEBUG: 2023-08-02 23:07:33,851: 2155350369.py: <module>: accuracy=0.927765
DEBUG: 2023-08-02 23:07:33,855: 2155350369.py: <module>: precision=0.928839
DEBUG: 2023-08-02 23:07:33,856: 2155350369.py: <module>: recall=0.929536
DEBUG: 2023-08-02 23:07:33,857: 2155350369.py: <module>: f1=0.928013
DEBUG: 2023-08-02 23:07:33,859: 2155350369.py: <module>: per-class f1={'LAYING': 0.995083, 'WALKING': 0.94254, 'WALKING_UPSTAIRS': 0.95896, 'WALKING_DOWNSTAIRS': 0.925733, 'SITTING': 0.861556, 'STANDING': 0.884208}
DEBUG: 2023-08-02 23:07:36,716: 1695527446.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 23:07:36,719: 1695527446.py: <module>: accuracy=0.9338456398262612
DEBUG: 2023-08-02 23:07:36,722: 1695527446.py: <module>: precision=0.9350623270313719
DEBUG: 2023-08-02 23:07:36,725: 1695527446.py: <module>: recall=0.9355863454035341
DEBUG: 2023-08-02 23:07:36,728: 1695527446.py: <module>: f1=0.9341904168460369
DEBUG: 2023-08-02 23:07:36,732: 1695527446.py: <module>: per-class f1=[0.99543379 0.95036959 0.97198276 0.92547275 0.872      0.88988362]
