DEBUG: 2023-08-02 17:52:32,143: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/deep_cnn_lstm_logs/deep-conv-lstm-20230802-175232/deep-conv-lstm-20230802-175232.log
DEBUG: 2023-08-02 17:52:44,233: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:52:44,234: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 17:52:44,237: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 17:52:44,238: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 17:52:44,239: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 17:52:44,240: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 17:52:44,241: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 17:52:44,242: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 17:52:44,242: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 17:52:44,243: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 17:52:44,244: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 17:52:44,246: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 17:52:44,247: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 17:52:44,248: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 17:52:44,249: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 17:52:44,249: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 17:52:44,284: 3941774885.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.0001, 'verbose': 0}
DEBUG: 2023-08-02 17:52:44,315: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:52:44,316: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 17:52:47,037: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 17:52:56,610: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 17:53:02,875: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.215 - accuracy: 0.948 - val_loss: 0.1792 - val_accuracy: 0.9602
DEBUG: 2023-08-02 17:53:09,957: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1595 - accuracy: 0.9568 - val_loss: 0.1345 - val_accuracy: 0.9663
DEBUG: 2023-08-02 17:53:16,593: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.132 - accuracy: 0.9573 - val_loss: 0.1159 - val_accuracy: 0.969
DEBUG: 2023-08-02 17:53:23,584: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1323 - accuracy: 0.9522 - val_loss: 0.108 - val_accuracy: 0.969
DEBUG: 2023-08-02 17:53:30,430: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1094 - accuracy: 0.9597 - val_loss: 0.1032 - val_accuracy: 0.9683
DEBUG: 2023-08-02 17:53:38,297: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0963 - accuracy: 0.964 - val_loss: 0.0938 - val_accuracy: 0.9669
DEBUG: 2023-08-02 17:53:45,237: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.2044 - accuracy: 0.9335 - val_loss: 0.1774 - val_accuracy: 0.9487
DEBUG: 2023-08-02 17:53:52,225: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1373 - accuracy: 0.9553 - val_loss: 0.1238 - val_accuracy: 0.9588
DEBUG: 2023-08-02 17:53:59,077: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1271 - accuracy: 0.9581 - val_loss: 0.1115 - val_accuracy: 0.9656
DEBUG: 2023-08-02 17:54:00,578: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 17:54:07,324: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:54:07,325: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 17:54:07,988: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 17:54:21,640: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2832 - accuracy: 0.9386 - val_loss: 0.2551 - val_accuracy: 0.9359
DEBUG: 2023-08-02 17:54:28,979: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2656 - accuracy: 0.9369 - val_loss: 0.1569 - val_accuracy: 0.9568
DEBUG: 2023-08-02 17:54:35,849: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1331 - accuracy: 0.9747 - val_loss: 0.124 - val_accuracy: 0.973
DEBUG: 2023-08-02 17:54:43,055: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1186 - accuracy: 0.977 - val_loss: 0.1329 - val_accuracy: 0.9629
DEBUG: 2023-08-02 17:54:49,914: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1534 - accuracy: 0.9576 - val_loss: 0.1443 - val_accuracy: 0.9568
DEBUG: 2023-08-02 17:54:57,311: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.2543 - accuracy: 0.9389 - val_loss: 0.1447 - val_accuracy: 0.9629
DEBUG: 2023-08-02 17:55:04,263: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1044 - accuracy: 0.9776 - val_loss: 0.0965 - val_accuracy: 0.9737
DEBUG: 2023-08-02 17:55:11,116: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0814 - accuracy: 0.9838 - val_loss: 0.0861 - val_accuracy: 0.977
DEBUG: 2023-08-02 17:55:17,674: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1492 - accuracy: 0.9666 - val_loss: 0.138 - val_accuracy: 0.9669
DEBUG: 2023-08-02 17:55:24,347: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0831 - accuracy: 0.9824 - val_loss: 0.0788 - val_accuracy: 0.9838
DEBUG: 2023-08-02 17:55:31,029: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0871 - accuracy: 0.983 - val_loss: 0.0985 - val_accuracy: 0.9743
DEBUG: 2023-08-02 17:55:37,899: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1283 - accuracy: 0.9755 - val_loss: 0.1438 - val_accuracy: 0.9588
DEBUG: 2023-08-02 17:55:44,688: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.082 - accuracy: 0.9862 - val_loss: 0.0822 - val_accuracy: 0.9818
DEBUG: 2023-08-02 17:55:51,533: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0842 - accuracy: 0.9821 - val_loss: 0.0759 - val_accuracy: 0.9824
DEBUG: 2023-08-02 17:56:03,994: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:56:03,995: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 17:56:04,622: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 17:56:17,403: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2818 - accuracy: 0.9349 - val_loss: 0.2215 - val_accuracy: 0.944
DEBUG: 2023-08-02 17:56:24,499: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1905 - accuracy: 0.9553 - val_loss: 0.1731 - val_accuracy: 0.9534
DEBUG: 2023-08-02 17:56:31,395: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1883 - accuracy: 0.9512 - val_loss: 0.1819 - val_accuracy: 0.9548
DEBUG: 2023-08-02 17:56:38,049: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.237 - accuracy: 0.9424 - val_loss: 0.1938 - val_accuracy: 0.9494
DEBUG: 2023-08-02 17:56:44,817: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1609 - accuracy: 0.958 - val_loss: 0.1533 - val_accuracy: 0.9602
DEBUG: 2023-08-02 17:56:51,925: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1398 - accuracy: 0.9612 - val_loss: 0.1386 - val_accuracy: 0.9561
DEBUG: 2023-08-02 17:56:58,693: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1196 - accuracy: 0.9639 - val_loss: 0.1558 - val_accuracy: 0.9548
DEBUG: 2023-08-02 17:57:05,283: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1056 - accuracy: 0.9654 - val_loss: 0.1143 - val_accuracy: 0.9656
DEBUG: 2023-08-02 17:57:12,258: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1376 - accuracy: 0.9581 - val_loss: 0.1127 - val_accuracy: 0.9723
DEBUG: 2023-08-02 17:57:19,217: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0983 - accuracy: 0.9693 - val_loss: 0.106 - val_accuracy: 0.9764
DEBUG: 2023-08-02 17:57:26,209: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1081 - accuracy: 0.9654 - val_loss: 0.106 - val_accuracy: 0.9723
DEBUG: 2023-08-02 17:57:33,675: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1357 - accuracy: 0.9593 - val_loss: 0.1072 - val_accuracy: 0.9615
DEBUG: 2023-08-02 17:57:41,807: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1461 - accuracy: 0.9543 - val_loss: 0.1201 - val_accuracy: 0.9615
DEBUG: 2023-08-02 17:57:49,745: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0949 - accuracy: 0.9752 - val_loss: 0.0916 - val_accuracy: 0.9784
DEBUG: 2023-08-02 17:57:57,004: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0772 - accuracy: 0.9797 - val_loss: 0.0906 - val_accuracy: 0.977
DEBUG: 2023-08-02 17:58:04,207: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.073 - accuracy: 0.9806 - val_loss: 0.0877 - val_accuracy: 0.9757
DEBUG: 2023-08-02 17:58:11,408: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.072 - accuracy: 0.9787 - val_loss: 0.0903 - val_accuracy: 0.9737
DEBUG: 2023-08-02 17:58:18,170: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0951 - accuracy: 0.9713 - val_loss: 0.0954 - val_accuracy: 0.9689
DEBUG: 2023-08-02 17:58:25,081: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.101 - accuracy: 0.9693 - val_loss: 0.09 - val_accuracy: 0.9723
DEBUG: 2023-08-02 17:58:32,143: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.0828 - accuracy: 0.9723 - val_loss: 0.0954 - val_accuracy: 0.9629
DEBUG: 2023-08-02 17:58:39,562: keras_callback.py: on_epoch_end: Epoch 210/10000 - loss: 0.0729 - accuracy: 0.9754 - val_loss: 0.0992 - val_accuracy: 0.9689
DEBUG: 2023-08-02 17:58:47,177: keras_callback.py: on_epoch_end: Epoch 220/10000 - loss: 0.0669 - accuracy: 0.9789 - val_loss: 0.087 - val_accuracy: 0.9804
DEBUG: 2023-08-02 17:58:54,257: keras_callback.py: on_epoch_end: Epoch 230/10000 - loss: 0.0579 - accuracy: 0.9841 - val_loss: 0.0665 - val_accuracy: 0.9845
DEBUG: 2023-08-02 17:59:01,473: keras_callback.py: on_epoch_end: Epoch 240/10000 - loss: 0.0456 - accuracy: 0.9885 - val_loss: 0.0476 - val_accuracy: 0.9899
DEBUG: 2023-08-02 17:59:08,141: keras_callback.py: on_epoch_end: Epoch 250/10000 - loss: 0.0422 - accuracy: 0.9929 - val_loss: 0.039 - val_accuracy: 0.9912
DEBUG: 2023-08-02 17:59:14,657: keras_callback.py: on_epoch_end: Epoch 260/10000 - loss: 0.0394 - accuracy: 0.9929 - val_loss: 0.0313 - val_accuracy: 0.9953
DEBUG: 2023-08-02 17:59:21,888: keras_callback.py: on_epoch_end: Epoch 270/10000 - loss: 0.0634 - accuracy: 0.9835 - val_loss: 0.0624 - val_accuracy: 0.9811
DEBUG: 2023-08-02 17:59:33,295: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:59:33,296: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 17:59:33,920: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 17:59:45,353: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2858 - accuracy: 0.9438 - val_loss: 0.2087 - val_accuracy: 0.9554
DEBUG: 2023-08-02 17:59:51,024: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2141 - accuracy: 0.9551 - val_loss: 0.1641 - val_accuracy: 0.9588
DEBUG: 2023-08-02 17:59:56,645: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1601 - accuracy: 0.9646 - val_loss: 0.1385 - val_accuracy: 0.9656
DEBUG: 2023-08-02 18:00:02,281: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2251 - accuracy: 0.9278 - val_loss: 0.1564 - val_accuracy: 0.9413
DEBUG: 2023-08-02 18:00:07,909: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1373 - accuracy: 0.9698 - val_loss: 0.1499 - val_accuracy: 0.9689
DEBUG: 2023-08-02 18:00:13,488: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1329 - accuracy: 0.9743 - val_loss: 0.1103 - val_accuracy: 0.9797
DEBUG: 2023-08-02 18:00:19,099: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.073 - accuracy: 0.9902 - val_loss: 0.0823 - val_accuracy: 0.9824
DEBUG: 2023-08-02 18:00:24,738: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0679 - accuracy: 0.9867 - val_loss: 0.0701 - val_accuracy: 0.9851
DEBUG: 2023-08-02 18:00:30,390: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0635 - accuracy: 0.985 - val_loss: 0.0663 - val_accuracy: 0.9858
DEBUG: 2023-08-02 18:00:35,959: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0872 - accuracy: 0.9797 - val_loss: 0.0707 - val_accuracy: 0.9824
DEBUG: 2023-08-02 18:00:41,469: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1088 - accuracy: 0.9716 - val_loss: 0.4798 - val_accuracy: 0.8515
DEBUG: 2023-08-02 18:00:47,128: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0613 - accuracy: 0.989 - val_loss: 0.0584 - val_accuracy: 0.9885
DEBUG: 2023-08-02 18:00:52,648: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0534 - accuracy: 0.9911 - val_loss: 0.0591 - val_accuracy: 0.9892
DEBUG: 2023-08-02 18:00:58,203: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0453 - accuracy: 0.9904 - val_loss: 0.0566 - val_accuracy: 0.9878
DEBUG: 2023-08-02 18:01:03,902: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0361 - accuracy: 0.9944 - val_loss: 0.0432 - val_accuracy: 0.9932
DEBUG: 2023-08-02 18:01:09,498: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0424 - accuracy: 0.9911 - val_loss: 0.0424 - val_accuracy: 0.9932
DEBUG: 2023-08-02 18:01:15,077: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0373 - accuracy: 0.9948 - val_loss: 0.0498 - val_accuracy: 0.9865
DEBUG: 2023-08-02 18:01:20,679: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0258 - accuracy: 0.9965 - val_loss: 0.0219 - val_accuracy: 0.9973
DEBUG: 2023-08-02 18:01:26,396: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0384 - accuracy: 0.9944 - val_loss: 0.0473 - val_accuracy: 0.9905
DEBUG: 2023-08-02 18:01:32,005: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.0516 - accuracy: 0.9875 - val_loss: 0.061 - val_accuracy: 0.9845
DEBUG: 2023-08-02 18:01:37,625: keras_callback.py: on_epoch_end: Epoch 210/10000 - loss: 0.0413 - accuracy: 0.9934 - val_loss: 0.0795 - val_accuracy: 0.9851
DEBUG: 2023-08-02 18:01:45,200: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 18:01:45,201: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 18:01:45,627: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 18:01:55,751: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2611 - accuracy: 0.9345 - val_loss: 0.1972 - val_accuracy: 0.946
DEBUG: 2023-08-02 18:02:01,417: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1668 - accuracy: 0.9586 - val_loss: 0.1422 - val_accuracy: 0.9595
DEBUG: 2023-08-02 18:02:07,006: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1464 - accuracy: 0.9585 - val_loss: 0.1333 - val_accuracy: 0.9548
DEBUG: 2023-08-02 18:02:12,655: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1498 - accuracy: 0.9531 - val_loss: 0.147 - val_accuracy: 0.9615
DEBUG: 2023-08-02 18:02:18,265: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1796 - accuracy: 0.9526 - val_loss: 0.1365 - val_accuracy: 0.9568
DEBUG: 2023-08-02 18:02:23,814: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1015 - accuracy: 0.9657 - val_loss: 0.1066 - val_accuracy: 0.9649
DEBUG: 2023-08-02 18:02:29,544: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1093 - accuracy: 0.9639 - val_loss: 0.0979 - val_accuracy: 0.9669
DEBUG: 2023-08-02 18:02:35,191: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0953 - accuracy: 0.9657 - val_loss: 0.1653 - val_accuracy: 0.923
DEBUG: 2023-08-02 18:02:40,725: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0979 - accuracy: 0.9683 - val_loss: 0.0952 - val_accuracy: 0.9629
DEBUG: 2023-08-02 18:02:46,380: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1031 - accuracy: 0.9698 - val_loss: 0.0855 - val_accuracy: 0.9757
DEBUG: 2023-08-02 18:02:52,166: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0654 - accuracy: 0.9828 - val_loss: 0.1036 - val_accuracy: 0.9737
DEBUG: 2023-08-02 18:02:57,627: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1041 - accuracy: 0.9634 - val_loss: 0.095 - val_accuracy: 0.9703
DEBUG: 2023-08-02 18:03:03,325: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0689 - accuracy: 0.9811 - val_loss: 0.0676 - val_accuracy: 0.9804
DEBUG: 2023-08-02 18:25:05,342: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 18:25:05,344: 2155350369.py: <module>: ---train---
DEBUG: 2023-08-02 18:25:05,345: 2155350369.py: <module>: logloss=0.047152
DEBUG: 2023-08-02 18:25:05,345: 2155350369.py: <module>: accuracy=0.987442
DEBUG: 2023-08-02 18:25:05,346: 2155350369.py: <module>: precision=0.988701
DEBUG: 2023-08-02 18:25:05,347: 2155350369.py: <module>: recall=0.98867
DEBUG: 2023-08-02 18:25:05,348: 2155350369.py: <module>: f1=0.988552
DEBUG: 2023-08-02 18:25:05,349: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 1.0, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.964898, 'STANDING': 0.966413}
DEBUG: 2023-08-02 18:25:05,349: 2155350369.py: <module>: ---valid---
DEBUG: 2023-08-02 18:25:05,350: 2155350369.py: <module>: logloss=0.049956
DEBUG: 2023-08-02 18:25:05,351: 2155350369.py: <module>: accuracy=0.988795
DEBUG: 2023-08-02 18:25:05,352: 2155350369.py: <module>: precision=0.989791
DEBUG: 2023-08-02 18:25:05,353: 2155350369.py: <module>: recall=0.989805
DEBUG: 2023-08-02 18:25:05,354: 2155350369.py: <module>: f1=0.989754
DEBUG: 2023-08-02 18:25:05,355: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.999185, 'WALKING_UPSTAIRS': 0.999532, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.969014, 'STANDING': 0.970795}
DEBUG: 2023-08-02 18:25:05,356: 2155350369.py: <module>: ---test---
DEBUG: 2023-08-02 18:25:05,357: 2155350369.py: <module>: logloss=0.497172
DEBUG: 2023-08-02 18:25:05,358: 2155350369.py: <module>: accuracy=0.925693
DEBUG: 2023-08-02 18:25:05,359: 2155350369.py: <module>: precision=0.928005
DEBUG: 2023-08-02 18:25:05,359: 2155350369.py: <module>: recall=0.927854
DEBUG: 2023-08-02 18:25:05,361: 2155350369.py: <module>: f1=0.926126
DEBUG: 2023-08-02 18:25:05,362: 2155350369.py: <module>: per-class f1={'LAYING': 0.997083, 'WALKING': 0.936686, 'WALKING_UPSTAIRS': 0.963014, 'WALKING_DOWNSTAIRS': 0.928077, 'SITTING': 0.85744, 'STANDING': 0.874457}
DEBUG: 2023-08-02 18:25:07,599: 1695527446.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 18:25:07,602: 1695527446.py: <module>: accuracy=0.9371867691279653
DEBUG: 2023-08-02 18:25:07,605: 1695527446.py: <module>: precision=0.9386599322610985
DEBUG: 2023-08-02 18:25:07,608: 1695527446.py: <module>: recall=0.9389348556974153
DEBUG: 2023-08-02 18:25:07,611: 1695527446.py: <module>: f1=0.9375222448323138
DEBUG: 2023-08-02 18:25:07,613: 1695527446.py: <module>: per-class f1=[1.         0.94814815 0.97749196 0.93214683 0.8733536  0.89399293]
