DEBUG: 2023-08-02 17:19:53,296: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/deep_cnn_lstm_logs/deep-conv-lstm-20230802-171953/deep-conv-lstm-20230802-171953.log
DEBUG: 2023-08-02 17:20:06,238: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:20:06,239: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 17:20:06,243: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 17:20:06,244: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 17:20:06,246: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 17:20:06,247: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 17:20:06,250: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 17:20:06,250: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 17:20:06,251: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 17:20:06,253: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 17:20:06,254: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 17:20:06,254: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 17:20:06,255: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 17:20:06,256: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 17:20:06,257: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 17:20:06,258: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 17:20:06,288: 3941774885.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.0001, 'verbose': 0}
DEBUG: 2023-08-02 17:20:06,322: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:20:06,323: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 17:20:09,302: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 17:20:20,987: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 17:20:27,747: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3681 - accuracy: 0.9191 - val_loss: 0.242 - val_accuracy: 0.944
DEBUG: 2023-08-02 17:20:35,057: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2304 - accuracy: 0.9438 - val_loss: 0.163 - val_accuracy: 0.9602
DEBUG: 2023-08-02 17:20:42,032: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2329 - accuracy: 0.9448 - val_loss: 0.1851 - val_accuracy: 0.9541
DEBUG: 2023-08-02 17:20:49,098: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1829 - accuracy: 0.9534 - val_loss: 0.115 - val_accuracy: 0.9717
DEBUG: 2023-08-02 17:20:56,023: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1515 - accuracy: 0.96 - val_loss: 0.1012 - val_accuracy: 0.9757
DEBUG: 2023-08-02 17:21:02,919: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1687 - accuracy: 0.9489 - val_loss: 0.1229 - val_accuracy: 0.9629
DEBUG: 2023-08-02 17:21:09,613: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.143 - accuracy: 0.9613 - val_loss: 0.1044 - val_accuracy: 0.9791
DEBUG: 2023-08-02 17:21:16,419: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1271 - accuracy: 0.9673 - val_loss: 0.1194 - val_accuracy: 0.948
DEBUG: 2023-08-02 17:21:23,197: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1909 - accuracy: 0.9489 - val_loss: 0.1182 - val_accuracy: 0.9737
DEBUG: 2023-08-02 17:21:29,851: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1277 - accuracy: 0.9624 - val_loss: 0.0814 - val_accuracy: 0.9798
DEBUG: 2023-08-02 17:21:36,697: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1016 - accuracy: 0.9725 - val_loss: 0.0741 - val_accuracy: 0.9811
DEBUG: 2023-08-02 17:21:43,502: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1068 - accuracy: 0.9757 - val_loss: 0.074 - val_accuracy: 0.9845
DEBUG: 2023-08-02 17:21:50,135: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1151 - accuracy: 0.9669 - val_loss: 0.0931 - val_accuracy: 0.9737
DEBUG: 2023-08-02 17:21:56,891: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.1012 - accuracy: 0.975 - val_loss: 0.0676 - val_accuracy: 0.9852
DEBUG: 2023-08-02 17:22:03,678: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0859 - accuracy: 0.9801 - val_loss: 0.0592 - val_accuracy: 0.9885
DEBUG: 2023-08-02 17:22:10,498: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0802 - accuracy: 0.9791 - val_loss: 0.0564 - val_accuracy: 0.9885
DEBUG: 2023-08-02 17:22:17,176: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.1007 - accuracy: 0.9676 - val_loss: 0.0953 - val_accuracy: 0.971
DEBUG: 2023-08-02 17:22:24,072: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0635 - accuracy: 0.9824 - val_loss: 0.0521 - val_accuracy: 0.9885
DEBUG: 2023-08-02 17:22:30,874: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0884 - accuracy: 0.973 - val_loss: 0.0498 - val_accuracy: 0.9872
DEBUG: 2023-08-02 17:22:37,709: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.0697 - accuracy: 0.9762 - val_loss: 0.04 - val_accuracy: 0.9879
DEBUG: 2023-08-02 17:22:44,643: keras_callback.py: on_epoch_end: Epoch 210/10000 - loss: 0.0682 - accuracy: 0.9792 - val_loss: 0.0433 - val_accuracy: 0.9885
DEBUG: 2023-08-02 17:22:51,447: keras_callback.py: on_epoch_end: Epoch 220/10000 - loss: 0.0683 - accuracy: 0.9804 - val_loss: 0.0425 - val_accuracy: 0.9885
DEBUG: 2023-08-02 17:22:58,240: keras_callback.py: on_epoch_end: Epoch 230/10000 - loss: 0.08 - accuracy: 0.9804 - val_loss: 0.0543 - val_accuracy: 0.9852
DEBUG: 2023-08-02 17:23:05,217: keras_callback.py: on_epoch_end: Epoch 240/10000 - loss: 0.0599 - accuracy: 0.9818 - val_loss: 0.0542 - val_accuracy: 0.9885
DEBUG: 2023-08-02 17:23:11,250: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 17:23:18,539: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:23:18,540: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 17:23:19,238: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 17:23:32,844: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3128 - accuracy: 0.9369 - val_loss: 0.1862 - val_accuracy: 0.9527
DEBUG: 2023-08-02 17:23:39,829: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.3524 - accuracy: 0.9198 - val_loss: 0.2233 - val_accuracy: 0.9392
DEBUG: 2023-08-02 17:23:46,849: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.5955 - accuracy: 0.8643 - val_loss: 0.2484 - val_accuracy: 0.9386
DEBUG: 2023-08-02 17:23:53,862: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2007 - accuracy: 0.9551 - val_loss: 0.1633 - val_accuracy: 0.9575
DEBUG: 2023-08-02 17:24:00,951: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1532 - accuracy: 0.9646 - val_loss: 0.1016 - val_accuracy: 0.9716
DEBUG: 2023-08-02 17:24:07,742: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.3927 - accuracy: 0.8633 - val_loss: 0.2534 - val_accuracy: 0.9298
DEBUG: 2023-08-02 17:24:14,833: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1874 - accuracy: 0.9492 - val_loss: 0.1469 - val_accuracy: 0.9446
DEBUG: 2023-08-02 17:24:21,791: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1695 - accuracy: 0.9514 - val_loss: 0.1272 - val_accuracy: 0.9534
DEBUG: 2023-08-02 17:24:29,403: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:24:29,404: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 17:24:30,077: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 17:24:43,528: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.4531 - accuracy: 0.8621 - val_loss: 0.2705 - val_accuracy: 0.9446
DEBUG: 2023-08-02 17:24:50,748: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2498 - accuracy: 0.936 - val_loss: 0.1624 - val_accuracy: 0.9588
DEBUG: 2023-08-02 17:24:57,707: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2723 - accuracy: 0.9278 - val_loss: 0.1721 - val_accuracy: 0.9487
DEBUG: 2023-08-02 17:25:04,614: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1963 - accuracy: 0.9478 - val_loss: 0.1355 - val_accuracy: 0.9656
DEBUG: 2023-08-02 17:25:11,820: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1427 - accuracy: 0.9647 - val_loss: 0.1029 - val_accuracy: 0.977
DEBUG: 2023-08-02 17:25:18,960: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1417 - accuracy: 0.9656 - val_loss: 0.0957 - val_accuracy: 0.9811
DEBUG: 2023-08-02 17:25:26,108: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1784 - accuracy: 0.9538 - val_loss: 0.13 - val_accuracy: 0.9683
DEBUG: 2023-08-02 17:25:33,153: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1826 - accuracy: 0.9544 - val_loss: 0.1131 - val_accuracy: 0.9737
DEBUG: 2023-08-02 17:25:40,125: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.139 - accuracy: 0.9651 - val_loss: 0.1034 - val_accuracy: 0.9804
DEBUG: 2023-08-02 17:25:47,499: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:25:47,500: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 17:25:48,159: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 17:26:01,969: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3016 - accuracy: 0.9458 - val_loss: 0.2369 - val_accuracy: 0.948
DEBUG: 2023-08-02 17:26:09,159: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2495 - accuracy: 0.9463 - val_loss: 0.171 - val_accuracy: 0.9527
DEBUG: 2023-08-02 17:26:16,059: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.3483 - accuracy: 0.9225 - val_loss: 0.199 - val_accuracy: 0.948
DEBUG: 2023-08-02 17:26:23,252: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2119 - accuracy: 0.9571 - val_loss: 0.1517 - val_accuracy: 0.9595
DEBUG: 2023-08-02 17:26:30,449: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1642 - accuracy: 0.9627 - val_loss: 0.1271 - val_accuracy: 0.9689
DEBUG: 2023-08-02 17:26:37,788: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1606 - accuracy: 0.9634 - val_loss: 0.1246 - val_accuracy: 0.9683
DEBUG: 2023-08-02 17:26:45,139: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1873 - accuracy: 0.9502 - val_loss: 0.1612 - val_accuracy: 0.9514
DEBUG: 2023-08-02 17:26:52,422: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1444 - accuracy: 0.9646 - val_loss: 0.101 - val_accuracy: 0.9743
DEBUG: 2023-08-02 17:26:59,721: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1345 - accuracy: 0.9614 - val_loss: 0.0988 - val_accuracy: 0.9696
DEBUG: 2023-08-02 17:27:07,092: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1169 - accuracy: 0.9706 - val_loss: 0.0899 - val_accuracy: 0.9703
DEBUG: 2023-08-02 17:27:14,707: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1188 - accuracy: 0.9669 - val_loss: 0.3044 - val_accuracy: 0.9534
DEBUG: 2023-08-02 17:27:22,053: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.2576 - accuracy: 0.9325 - val_loss: 0.1275 - val_accuracy: 0.9615
DEBUG: 2023-08-02 17:27:29,504: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1108 - accuracy: 0.9691 - val_loss: 0.0789 - val_accuracy: 0.9743
DEBUG: 2023-08-02 17:27:42,124: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 17:27:42,125: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 17:27:42,781: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 17:27:56,542: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3481 - accuracy: 0.9327 - val_loss: 0.2131 - val_accuracy: 0.9494
DEBUG: 2023-08-02 17:28:04,020: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2539 - accuracy: 0.946 - val_loss: 0.2288 - val_accuracy: 0.9338
DEBUG: 2023-08-02 17:28:11,351: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2001 - accuracy: 0.9507 - val_loss: 0.1524 - val_accuracy: 0.9541
DEBUG: 2023-08-02 17:28:18,687: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1887 - accuracy: 0.9536 - val_loss: 0.1335 - val_accuracy: 0.9575
DEBUG: 2023-08-02 17:28:26,292: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1565 - accuracy: 0.9585 - val_loss: 0.1284 - val_accuracy: 0.9561
DEBUG: 2023-08-02 17:28:33,998: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1575 - accuracy: 0.9585 - val_loss: 0.1205 - val_accuracy: 0.971
DEBUG: 2023-08-02 17:28:41,860: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1394 - accuracy: 0.9571 - val_loss: 0.1122 - val_accuracy: 0.9656
DEBUG: 2023-08-02 17:28:49,567: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1201 - accuracy: 0.9657 - val_loss: 0.1008 - val_accuracy: 0.9683
DEBUG: 2023-08-02 17:28:57,160: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1096 - accuracy: 0.9624 - val_loss: 0.0971 - val_accuracy: 0.9635
DEBUG: 2023-08-02 17:29:04,272: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1103 - accuracy: 0.9654 - val_loss: 0.0897 - val_accuracy: 0.9689
DEBUG: 2023-08-02 17:29:11,603: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0983 - accuracy: 0.9679 - val_loss: 0.083 - val_accuracy: 0.9757
DEBUG: 2023-08-02 17:29:18,626: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0909 - accuracy: 0.9723 - val_loss: 0.0887 - val_accuracy: 0.973
DEBUG: 2023-08-02 17:29:25,665: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0794 - accuracy: 0.9772 - val_loss: 0.0739 - val_accuracy: 0.9797
DEBUG: 2023-08-02 17:29:33,107: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0946 - accuracy: 0.9718 - val_loss: 0.0632 - val_accuracy: 0.9845
DEBUG: 2023-08-02 17:29:41,252: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.1943 - accuracy: 0.9433 - val_loss: 0.1538 - val_accuracy: 0.9467
DEBUG: 2023-08-02 17:29:49,717: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0917 - accuracy: 0.9666 - val_loss: 0.0923 - val_accuracy: 0.9703
DEBUG: 2023-08-02 17:29:56,954: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0853 - accuracy: 0.973 - val_loss: 0.0887 - val_accuracy: 0.971
DEBUG: 2023-08-02 17:31:32,551: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 17:31:32,552: 2155350369.py: <module>: ---train---
DEBUG: 2023-08-02 17:31:32,553: 2155350369.py: <module>: logloss=0.069451
DEBUG: 2023-08-02 17:31:32,554: 2155350369.py: <module>: accuracy=0.982312
DEBUG: 2023-08-02 17:31:32,556: 2155350369.py: <module>: precision=0.984387
DEBUG: 2023-08-02 17:31:32,557: 2155350369.py: <module>: recall=0.983463
DEBUG: 2023-08-02 17:31:32,558: 2155350369.py: <module>: f1=0.983766
DEBUG: 2023-08-02 17:31:32,560: 2155350369.py: <module>: per-class f1={'LAYING': 0.999823, 'WALKING': 0.999387, 'WALKING_UPSTAIRS': 0.999534, 'WALKING_DOWNSTAIRS': 0.999366, 'SITTING': 0.949084, 'STANDING': 0.955403}
DEBUG: 2023-08-02 17:31:32,561: 2155350369.py: <module>: ---valid---
DEBUG: 2023-08-02 17:31:32,562: 2155350369.py: <module>: logloss=0.074817
DEBUG: 2023-08-02 17:31:32,563: 2155350369.py: <module>: accuracy=0.979745
DEBUG: 2023-08-02 17:31:32,564: 2155350369.py: <module>: precision=0.982386
DEBUG: 2023-08-02 17:31:32,565: 2155350369.py: <module>: recall=0.980992
DEBUG: 2023-08-02 17:31:32,565: 2155350369.py: <module>: f1=0.981386
DEBUG: 2023-08-02 17:31:32,566: 2155350369.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.999591, 'WALKING_UPSTAIRS': 0.999065, 'WALKING_DOWNSTAIRS': 0.999494, 'SITTING': 0.940997, 'STANDING': 0.949167}
DEBUG: 2023-08-02 17:31:32,567: 2155350369.py: <module>: ---test---
DEBUG: 2023-08-02 17:31:32,568: 2155350369.py: <module>: logloss=0.453717
DEBUG: 2023-08-02 17:31:32,569: 2155350369.py: <module>: accuracy=0.931507
DEBUG: 2023-08-02 17:31:32,569: 2155350369.py: <module>: precision=0.932335
DEBUG: 2023-08-02 17:31:32,570: 2155350369.py: <module>: recall=0.933152
DEBUG: 2023-08-02 17:31:32,572: 2155350369.py: <module>: f1=0.93163
DEBUG: 2023-08-02 17:31:32,573: 2155350369.py: <module>: per-class f1={'LAYING': 0.986204, 'WALKING': 0.941174, 'WALKING_UPSTAIRS': 0.956608, 'WALKING_DOWNSTAIRS': 0.930581, 'SITTING': 0.879669, 'STANDING': 0.895544}
DEBUG: 2023-08-02 17:31:35,643: 1695527446.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 17:31:35,648: 1695527446.py: <module>: accuracy=0.9438690277313732
DEBUG: 2023-08-02 17:31:35,652: 1695527446.py: <module>: precision=0.94446600928477
DEBUG: 2023-08-02 17:31:35,657: 1695527446.py: <module>: recall=0.9454895922519923
DEBUG: 2023-08-02 17:31:35,660: 1695527446.py: <module>: f1=0.9436354646961974
DEBUG: 2023-08-02 17:31:35,665: 1695527446.py: <module>: per-class f1=[0.9981685  0.94267516 0.97314715 0.92596685 0.90480864 0.91704649]
WARNING: 2023-08-02 17:33:12,805: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
WARNING: 2023-08-02 17:33:22,332: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
WARNING: 2023-08-02 17:33:31,121: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
