DEBUG: 2023-08-02 00:42:09,306: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/stacked_lstm_logs/deep-conv-lstm-20230802-004209/deep-conv-lstm-20230802-004209.log
DEBUG: 2023-08-02 00:42:19,882: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:42:19,884: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 00:42:19,886: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 00:42:19,887: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 00:42:19,888: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 00:42:19,890: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 00:42:19,892: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 00:42:19,892: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 00:42:19,893: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 00:42:19,894: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 00:42:19,895: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 00:42:19,896: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 00:42:19,897: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 00:42:19,898: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 00:42:19,898: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 00:42:19,899: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 00:42:19,941: 1134177668.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-08-02 00:42:19,975: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:42:19,976: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 00:42:22,861: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 00:42:32,071: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 00:42:40,788: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2126 - accuracy: 0.9419 - val_loss: 0.1796 - val_accuracy: 0.9528
DEBUG: 2023-08-02 00:42:50,429: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1884 - accuracy: 0.9468 - val_loss: 0.162 - val_accuracy: 0.9568
DEBUG: 2023-08-02 00:43:00,533: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2672 - accuracy: 0.9191 - val_loss: 0.196 - val_accuracy: 0.9447
DEBUG: 2023-08-02 00:43:10,357: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1476 - accuracy: 0.9517 - val_loss: 0.1181 - val_accuracy: 0.9602
DEBUG: 2023-08-02 00:43:20,803: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1693 - accuracy: 0.9468 - val_loss: 0.1565 - val_accuracy: 0.9541
DEBUG: 2023-08-02 00:43:31,121: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1369 - accuracy: 0.9573 - val_loss: 0.1171 - val_accuracy: 0.9669
DEBUG: 2023-08-02 00:43:42,162: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.2181 - accuracy: 0.9249 - val_loss: 0.1303 - val_accuracy: 0.9582
DEBUG: 2023-08-02 00:43:52,532: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1262 - accuracy: 0.9559 - val_loss: 0.122 - val_accuracy: 0.9636
DEBUG: 2023-08-02 00:44:02,920: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1198 - accuracy: 0.9578 - val_loss: 0.148 - val_accuracy: 0.9575
DEBUG: 2023-08-02 00:44:07,302: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 00:44:16,440: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:44:16,441: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 00:44:17,584: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 00:44:33,817: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2594 - accuracy: 0.9296 - val_loss: 0.2368 - val_accuracy: 0.9379
DEBUG: 2023-08-02 00:44:43,288: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1815 - accuracy: 0.9473 - val_loss: 0.1723 - val_accuracy: 0.948
DEBUG: 2023-08-02 00:44:52,605: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1738 - accuracy: 0.9485 - val_loss: 0.1465 - val_accuracy: 0.9507
DEBUG: 2023-08-02 00:45:02,716: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1403 - accuracy: 0.961 - val_loss: 0.1386 - val_accuracy: 0.9575
DEBUG: 2023-08-02 00:45:12,566: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1346 - accuracy: 0.9565 - val_loss: 0.1432 - val_accuracy: 0.9548
DEBUG: 2023-08-02 00:45:22,299: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1108 - accuracy: 0.9595 - val_loss: 0.1021 - val_accuracy: 0.9642
DEBUG: 2023-08-02 00:45:31,735: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.6114 - accuracy: 0.8287 - val_loss: 0.3919 - val_accuracy: 0.8798
DEBUG: 2023-08-02 00:45:41,412: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1182 - accuracy: 0.9583 - val_loss: 0.1076 - val_accuracy: 0.9541
DEBUG: 2023-08-02 00:46:01,090: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:46:01,090: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 00:46:02,016: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 00:46:20,908: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2354 - accuracy: 0.9376 - val_loss: 0.2064 - val_accuracy: 0.944
DEBUG: 2023-08-02 00:46:31,732: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1538 - accuracy: 0.9473 - val_loss: 0.1546 - val_accuracy: 0.9487
DEBUG: 2023-08-02 00:46:41,870: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1222 - accuracy: 0.9554 - val_loss: 0.1434 - val_accuracy: 0.946
DEBUG: 2023-08-02 00:46:51,358: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2032 - accuracy: 0.9408 - val_loss: 0.1802 - val_accuracy: 0.9338
DEBUG: 2023-08-02 00:47:00,979: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1398 - accuracy: 0.9527 - val_loss: 0.1392 - val_accuracy: 0.9527
DEBUG: 2023-08-02 00:47:16,573: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:47:16,574: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 00:47:17,479: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 00:47:34,848: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2375 - accuracy: 0.9354 - val_loss: 0.2544 - val_accuracy: 0.9284
DEBUG: 2023-08-02 00:47:44,609: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.305 - accuracy: 0.9127 - val_loss: 0.1898 - val_accuracy: 0.9392
DEBUG: 2023-08-02 00:47:54,540: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1449 - accuracy: 0.9534 - val_loss: 0.1795 - val_accuracy: 0.95
DEBUG: 2023-08-02 00:48:04,543: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1494 - accuracy: 0.9505 - val_loss: 0.1507 - val_accuracy: 0.9487
DEBUG: 2023-08-02 00:48:13,739: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1222 - accuracy: 0.9575 - val_loss: 0.1302 - val_accuracy: 0.9541
DEBUG: 2023-08-02 00:48:22,907: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1241 - accuracy: 0.9532 - val_loss: 0.1109 - val_accuracy: 0.9588
DEBUG: 2023-08-02 00:48:32,043: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1101 - accuracy: 0.9585 - val_loss: 0.1102 - val_accuracy: 0.9575
DEBUG: 2023-08-02 00:48:41,208: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1055 - accuracy: 0.9657 - val_loss: 0.1465 - val_accuracy: 0.9521
DEBUG: 2023-08-02 00:48:50,321: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0939 - accuracy: 0.9632 - val_loss: 0.1062 - val_accuracy: 0.9595
DEBUG: 2023-08-02 00:48:59,416: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.141 - accuracy: 0.9554 - val_loss: 0.109 - val_accuracy: 0.9575
DEBUG: 2023-08-02 00:49:08,564: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0918 - accuracy: 0.9708 - val_loss: 0.0913 - val_accuracy: 0.9676
DEBUG: 2023-08-02 00:49:17,638: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.2062 - accuracy: 0.9301 - val_loss: 0.1437 - val_accuracy: 0.95
DEBUG: 2023-08-02 00:49:26,816: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0875 - accuracy: 0.9679 - val_loss: 0.0952 - val_accuracy: 0.9649
DEBUG: 2023-08-02 00:49:35,995: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0801 - accuracy: 0.97 - val_loss: 0.0851 - val_accuracy: 0.9649
DEBUG: 2023-08-02 00:49:45,055: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0855 - accuracy: 0.9662 - val_loss: 0.0841 - val_accuracy: 0.9669
DEBUG: 2023-08-02 00:49:54,176: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0765 - accuracy: 0.97 - val_loss: 0.086 - val_accuracy: 0.9629
DEBUG: 2023-08-02 00:50:03,275: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.1004 - accuracy: 0.9649 - val_loss: 0.092 - val_accuracy: 0.9669
DEBUG: 2023-08-02 00:50:12,473: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0735 - accuracy: 0.9722 - val_loss: 0.0689 - val_accuracy: 0.9743
DEBUG: 2023-08-02 00:50:21,690: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.064 - accuracy: 0.9789 - val_loss: 0.0587 - val_accuracy: 0.9824
DEBUG: 2023-08-02 00:50:30,779: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.0646 - accuracy: 0.9811 - val_loss: 0.061 - val_accuracy: 0.9818
DEBUG: 2023-08-02 00:50:39,902: keras_callback.py: on_epoch_end: Epoch 210/10000 - loss: 0.0761 - accuracy: 0.9728 - val_loss: 0.0862 - val_accuracy: 0.9649
DEBUG: 2023-08-02 00:50:49,154: keras_callback.py: on_epoch_end: Epoch 220/10000 - loss: 0.0922 - accuracy: 0.9668 - val_loss: 0.0959 - val_accuracy: 0.9635
DEBUG: 2023-08-02 00:50:58,003: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:50:58,003: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 00:50:58,846: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 00:51:15,003: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.24 - accuracy: 0.9418 - val_loss: 0.1938 - val_accuracy: 0.9473
DEBUG: 2023-08-02 00:51:24,423: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1414 - accuracy: 0.957 - val_loss: 0.1391 - val_accuracy: 0.9494
DEBUG: 2023-08-02 00:51:33,693: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1816 - accuracy: 0.9446 - val_loss: 0.1376 - val_accuracy: 0.9494
DEBUG: 2023-08-02 00:51:42,953: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1451 - accuracy: 0.9538 - val_loss: 0.1365 - val_accuracy: 0.9561
DEBUG: 2023-08-02 00:51:52,195: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1075 - accuracy: 0.9592 - val_loss: 0.1204 - val_accuracy: 0.9581
DEBUG: 2023-08-02 00:52:01,282: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1068 - accuracy: 0.9575 - val_loss: 0.1062 - val_accuracy: 0.9548
DEBUG: 2023-08-02 00:52:10,628: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1017 - accuracy: 0.9654 - val_loss: 0.1125 - val_accuracy: 0.9561
DEBUG: 2023-08-02 00:52:19,893: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1008 - accuracy: 0.9615 - val_loss: 0.0932 - val_accuracy: 0.9642
DEBUG: 2023-08-02 00:52:29,496: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0898 - accuracy: 0.96 - val_loss: 0.0977 - val_accuracy: 0.9561
DEBUG: 2023-08-02 00:52:40,199: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0759 - accuracy: 0.9705 - val_loss: 0.0727 - val_accuracy: 0.9723
DEBUG: 2023-08-02 00:52:50,193: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0813 - accuracy: 0.9703 - val_loss: 0.0855 - val_accuracy: 0.9689
DEBUG: 2023-08-02 00:52:59,880: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.2274 - accuracy: 0.9288 - val_loss: 0.1273 - val_accuracy: 0.9494
DEBUG: 2023-08-02 00:53:09,603: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1592 - accuracy: 0.9505 - val_loss: 0.1433 - val_accuracy: 0.9487
DEBUG: 2023-08-02 00:53:22,603: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.1003 - accuracy: 0.9654 - val_loss: 0.1023 - val_accuracy: 0.9561
