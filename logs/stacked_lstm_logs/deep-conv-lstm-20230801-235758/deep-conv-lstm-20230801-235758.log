DEBUG: 2023-08-01 23:57:58,737: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/stacked_lstm_logs/deep-conv-lstm-20230801-235758/deep-conv-lstm-20230801-235758.log
DEBUG: 2023-08-01 23:58:10,029: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-01 23:58:10,030: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-01 23:58:10,034: utils.py: check_class_balance: train labels
DEBUG: 2023-08-01 23:58:10,035: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-01 23:58:10,035: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-01 23:58:10,036: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-01 23:58:10,037: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-01 23:58:10,038: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-01 23:58:10,039: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-01 23:58:10,040: utils.py: check_class_balance: test labels
DEBUG: 2023-08-01 23:58:10,041: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-01 23:58:10,042: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-01 23:58:10,043: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-01 23:58:10,043: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-01 23:58:10,044: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-01 23:58:10,045: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-01 23:58:10,078: 1134177668.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-08-01 23:58:10,111: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-01 23:58:10,112: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-01 23:58:13,021: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-01 23:58:23,369: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-01 23:58:33,205: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1895 - accuracy: 0.9379 - val_loss: 0.1644 - val_accuracy: 0.9528
DEBUG: 2023-08-01 23:58:43,379: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1695 - accuracy: 0.9435 - val_loss: 0.1774 - val_accuracy: 0.9528
DEBUG: 2023-08-01 23:58:53,061: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1167 - accuracy: 0.9536 - val_loss: 0.0998 - val_accuracy: 0.971
DEBUG: 2023-08-01 23:59:04,532: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.109 - accuracy: 0.9548 - val_loss: 0.1022 - val_accuracy: 0.9663
DEBUG: 2023-08-01 23:59:14,605: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1709 - accuracy: 0.944 - val_loss: 0.1645 - val_accuracy: 0.944
DEBUG: 2023-08-01 23:59:24,634: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1128 - accuracy: 0.95 - val_loss: 0.094 - val_accuracy: 0.9622
DEBUG: 2023-08-01 23:59:35,005: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0994 - accuracy: 0.9549 - val_loss: 0.0824 - val_accuracy: 0.969
DEBUG: 2023-08-01 23:59:45,513: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0908 - accuracy: 0.9619 - val_loss: 0.0845 - val_accuracy: 0.9636
DEBUG: 2023-08-01 23:59:56,159: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0827 - accuracy: 0.9642 - val_loss: 0.0718 - val_accuracy: 0.971
DEBUG: 2023-08-02 00:00:06,830: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0848 - accuracy: 0.9646 - val_loss: 0.0788 - val_accuracy: 0.9696
DEBUG: 2023-08-02 00:00:17,324: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0736 - accuracy: 0.9708 - val_loss: 0.0753 - val_accuracy: 0.9744
DEBUG: 2023-08-02 00:00:28,437: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0843 - accuracy: 0.9684 - val_loss: 0.0836 - val_accuracy: 0.9642
DEBUG: 2023-08-02 00:00:28,657: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 00:00:39,994: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:00:39,994: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 00:00:41,437: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 00:01:00,470: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.4752 - accuracy: 0.8385 - val_loss: 0.2919 - val_accuracy: 0.9278
DEBUG: 2023-08-02 00:01:10,309: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1741 - accuracy: 0.9457 - val_loss: 0.1619 - val_accuracy: 0.95
DEBUG: 2023-08-02 00:01:20,628: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1212 - accuracy: 0.9608 - val_loss: 0.1208 - val_accuracy: 0.9608
DEBUG: 2023-08-02 00:01:30,348: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1226 - accuracy: 0.9583 - val_loss: 0.1189 - val_accuracy: 0.9561
DEBUG: 2023-08-02 00:01:39,968: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0952 - accuracy: 0.9656 - val_loss: 0.0886 - val_accuracy: 0.9629
DEBUG: 2023-08-02 00:01:49,452: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.101 - accuracy: 0.9647 - val_loss: 0.1168 - val_accuracy: 0.9534
DEBUG: 2023-08-02 00:01:58,975: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0904 - accuracy: 0.9671 - val_loss: 0.0891 - val_accuracy: 0.9554
DEBUG: 2023-08-02 00:02:08,465: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1401 - accuracy: 0.9548 - val_loss: 0.1118 - val_accuracy: 0.9554
DEBUG: 2023-08-02 00:02:18,372: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0786 - accuracy: 0.9728 - val_loss: 0.0692 - val_accuracy: 0.9703
DEBUG: 2023-08-02 00:02:27,851: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.095 - accuracy: 0.9641 - val_loss: 0.0682 - val_accuracy: 0.9662
DEBUG: 2023-08-02 00:02:37,389: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0663 - accuracy: 0.9747 - val_loss: 0.0993 - val_accuracy: 0.9689
DEBUG: 2023-08-02 00:02:46,955: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0843 - accuracy: 0.9713 - val_loss: 0.061 - val_accuracy: 0.9703
DEBUG: 2023-08-02 00:02:56,619: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0569 - accuracy: 0.9797 - val_loss: 0.0708 - val_accuracy: 0.9784
DEBUG: 2023-08-02 00:03:06,241: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.1134 - accuracy: 0.9627 - val_loss: 0.1083 - val_accuracy: 0.9629
DEBUG: 2023-08-02 00:03:15,728: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.053 - accuracy: 0.9836 - val_loss: 0.0509 - val_accuracy: 0.9791
DEBUG: 2023-08-02 00:03:25,222: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0597 - accuracy: 0.9764 - val_loss: 0.0525 - val_accuracy: 0.9757
DEBUG: 2023-08-02 00:03:34,710: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.05 - accuracy: 0.9772 - val_loss: 0.0677 - val_accuracy: 0.9716
DEBUG: 2023-08-02 00:03:44,167: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0493 - accuracy: 0.9814 - val_loss: 0.0863 - val_accuracy: 0.9743
DEBUG: 2023-08-02 00:03:53,943: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0334 - accuracy: 0.989 - val_loss: 0.0464 - val_accuracy: 0.9804
DEBUG: 2023-08-02 00:04:03,487: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.2652 - accuracy: 0.9252 - val_loss: 0.2991 - val_accuracy: 0.9244
DEBUG: 2023-08-02 00:04:12,897: keras_callback.py: on_epoch_end: Epoch 210/10000 - loss: 0.0502 - accuracy: 0.9833 - val_loss: 0.0557 - val_accuracy: 0.9784
DEBUG: 2023-08-02 00:04:29,141: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:04:29,142: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 00:04:30,103: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 00:04:48,139: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2055 - accuracy: 0.9389 - val_loss: 0.1862 - val_accuracy: 0.9365
DEBUG: 2023-08-02 00:04:57,905: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1367 - accuracy: 0.9548 - val_loss: 0.1326 - val_accuracy: 0.9487
DEBUG: 2023-08-02 00:05:07,788: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1447 - accuracy: 0.9478 - val_loss: 0.12 - val_accuracy: 0.9514
DEBUG: 2023-08-02 00:05:17,546: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1026 - accuracy: 0.9561 - val_loss: 0.1064 - val_accuracy: 0.9521
DEBUG: 2023-08-02 00:05:27,192: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1074 - accuracy: 0.957 - val_loss: 0.1155 - val_accuracy: 0.9554
DEBUG: 2023-08-02 00:05:36,813: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0896 - accuracy: 0.9644 - val_loss: 0.1102 - val_accuracy: 0.9541
DEBUG: 2023-08-02 00:05:46,525: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1305 - accuracy: 0.9499 - val_loss: 0.1155 - val_accuracy: 0.9507
DEBUG: 2023-08-02 00:05:56,455: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0749 - accuracy: 0.9661 - val_loss: 0.0902 - val_accuracy: 0.9642
DEBUG: 2023-08-02 00:06:06,151: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0856 - accuracy: 0.9649 - val_loss: 0.09 - val_accuracy: 0.9622
DEBUG: 2023-08-02 00:06:15,895: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0781 - accuracy: 0.9669 - val_loss: 0.1213 - val_accuracy: 0.9561
DEBUG: 2023-08-02 00:06:25,739: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0725 - accuracy: 0.9708 - val_loss: 0.1013 - val_accuracy: 0.9608
DEBUG: 2023-08-02 00:06:35,477: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0669 - accuracy: 0.971 - val_loss: 0.0748 - val_accuracy: 0.9669
DEBUG: 2023-08-02 00:06:45,021: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0593 - accuracy: 0.9725 - val_loss: 0.0767 - val_accuracy: 0.9615
DEBUG: 2023-08-02 00:06:54,650: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0819 - accuracy: 0.9583 - val_loss: 0.1062 - val_accuracy: 0.944
DEBUG: 2023-08-02 00:07:10,890: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:07:10,891: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 00:07:11,831: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 00:07:29,540: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.156 - accuracy: 0.9553 - val_loss: 0.1385 - val_accuracy: 0.9541
DEBUG: 2023-08-02 00:07:39,455: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.128 - accuracy: 0.9529 - val_loss: 0.0998 - val_accuracy: 0.9602
DEBUG: 2023-08-02 00:07:49,197: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1335 - accuracy: 0.9526 - val_loss: 0.1238 - val_accuracy: 0.9541
DEBUG: 2023-08-02 00:07:58,836: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2054 - accuracy: 0.9306 - val_loss: 0.1603 - val_accuracy: 0.9419
DEBUG: 2023-08-02 00:08:08,714: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1007 - accuracy: 0.9578 - val_loss: 0.0916 - val_accuracy: 0.9608
DEBUG: 2023-08-02 00:08:18,498: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.094 - accuracy: 0.9624 - val_loss: 0.0795 - val_accuracy: 0.9642
DEBUG: 2023-08-02 00:08:28,214: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1258 - accuracy: 0.9561 - val_loss: 0.0901 - val_accuracy: 0.9662
DEBUG: 2023-08-02 00:08:37,937: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0908 - accuracy: 0.9614 - val_loss: 0.0769 - val_accuracy: 0.9615
DEBUG: 2023-08-02 00:08:47,606: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0839 - accuracy: 0.9681 - val_loss: 0.0794 - val_accuracy: 0.9689
DEBUG: 2023-08-02 00:09:00,163: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 00:09:00,164: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 00:09:01,108: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 00:09:18,823: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1856 - accuracy: 0.9455 - val_loss: 0.1676 - val_accuracy: 0.946
DEBUG: 2023-08-02 00:09:28,601: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1313 - accuracy: 0.9529 - val_loss: 0.1474 - val_accuracy: 0.9426
DEBUG: 2023-08-02 00:09:38,253: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1573 - accuracy: 0.949 - val_loss: 0.1247 - val_accuracy: 0.9494
DEBUG: 2023-08-02 00:09:47,894: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.099 - accuracy: 0.9642 - val_loss: 0.1102 - val_accuracy: 0.9527
DEBUG: 2023-08-02 00:09:57,726: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1019 - accuracy: 0.9624 - val_loss: 0.1123 - val_accuracy: 0.9527
DEBUG: 2023-08-02 00:10:07,603: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0945 - accuracy: 0.9614 - val_loss: 0.1003 - val_accuracy: 0.9548
DEBUG: 2023-08-02 00:10:17,493: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1078 - accuracy: 0.9593 - val_loss: 0.1092 - val_accuracy: 0.9514
DEBUG: 2023-08-02 00:10:27,192: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0909 - accuracy: 0.9647 - val_loss: 0.0994 - val_accuracy: 0.9554
DEBUG: 2023-08-02 00:10:36,890: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0904 - accuracy: 0.9639 - val_loss: 0.1002 - val_accuracy: 0.9561
DEBUG: 2023-08-02 00:10:46,610: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0844 - accuracy: 0.9681 - val_loss: 0.1011 - val_accuracy: 0.9554
DEBUG: 2023-08-02 00:10:56,355: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0863 - accuracy: 0.9657 - val_loss: 0.0966 - val_accuracy: 0.9656
DEBUG: 2023-08-02 00:11:06,016: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0801 - accuracy: 0.9684 - val_loss: 0.097 - val_accuracy: 0.9595
DEBUG: 2023-08-02 00:11:15,774: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0983 - accuracy: 0.9615 - val_loss: 0.0967 - val_accuracy: 0.9548
DEBUG: 2023-08-02 00:11:25,822: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.3071 - accuracy: 0.9159 - val_loss: 0.1415 - val_accuracy: 0.9446
DEBUG: 2023-08-02 00:11:35,552: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0686 - accuracy: 0.9693 - val_loss: 0.088 - val_accuracy: 0.9554
DEBUG: 2023-08-02 00:11:45,321: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0651 - accuracy: 0.9715 - val_loss: 0.0757 - val_accuracy: 0.9696
DEBUG: 2023-08-02 00:11:55,111: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0629 - accuracy: 0.9749 - val_loss: 0.0828 - val_accuracy: 0.9662
DEBUG: 2023-08-02 00:12:04,792: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0608 - accuracy: 0.9752 - val_loss: 0.0946 - val_accuracy: 0.9548
DEBUG: 2023-08-02 00:12:14,396: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.0574 - accuracy: 0.9764 - val_loss: 0.0838 - val_accuracy: 0.9696
DEBUG: 2023-08-02 00:12:24,280: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.0613 - accuracy: 0.9693 - val_loss: 0.0937 - val_accuracy: 0.9696
DEBUG: 2023-08-02 00:12:34,057: keras_callback.py: on_epoch_end: Epoch 210/10000 - loss: 0.0585 - accuracy: 0.9799 - val_loss: 0.0816 - val_accuracy: 0.9743
DEBUG: 2023-08-02 00:12:44,021: keras_callback.py: on_epoch_end: Epoch 220/10000 - loss: 0.05 - accuracy: 0.9826 - val_loss: 0.0679 - val_accuracy: 0.9791
DEBUG: 2023-08-02 00:12:53,838: keras_callback.py: on_epoch_end: Epoch 230/10000 - loss: 0.0429 - accuracy: 0.9855 - val_loss: 0.052 - val_accuracy: 0.9831
DEBUG: 2023-08-02 00:13:03,703: keras_callback.py: on_epoch_end: Epoch 240/10000 - loss: 0.0666 - accuracy: 0.9728 - val_loss: 0.0594 - val_accuracy: 0.9784
DEBUG: 2023-08-02 00:13:13,456: keras_callback.py: on_epoch_end: Epoch 250/10000 - loss: 0.0392 - accuracy: 0.9865 - val_loss: 0.0525 - val_accuracy: 0.9797
DEBUG: 2023-08-02 00:13:23,240: keras_callback.py: on_epoch_end: Epoch 260/10000 - loss: 0.0506 - accuracy: 0.9803 - val_loss: 0.0566 - val_accuracy: 0.9818
DEBUG: 2023-08-02 00:13:32,944: keras_callback.py: on_epoch_end: Epoch 270/10000 - loss: 0.0345 - accuracy: 0.9853 - val_loss: 0.0577 - val_accuracy: 0.9797
DEBUG: 2023-08-02 00:25:18,501: 4266479415.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 00:25:18,503: 4266479415.py: <module>: ---train---
DEBUG: 2023-08-02 00:25:18,504: 4266479415.py: <module>: logloss=0.056765
DEBUG: 2023-08-02 00:25:18,504: 4266479415.py: <module>: accuracy=0.97664
DEBUG: 2023-08-02 00:25:18,505: 4266479415.py: <module>: precision=0.979156
DEBUG: 2023-08-02 00:25:18,506: 4266479415.py: <module>: recall=0.978567
DEBUG: 2023-08-02 00:25:18,507: 4266479415.py: <module>: f1=0.978656
DEBUG: 2023-08-02 00:25:18,508: 4266479415.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 1.0, 'WALKING_UPSTAIRS': 1.0, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.932707, 'STANDING': 0.939228}
DEBUG: 2023-08-02 00:25:18,509: 4266479415.py: <module>: ---valid---
DEBUG: 2023-08-02 00:25:18,510: 4266479415.py: <module>: logloss=0.060903
DEBUG: 2023-08-02 00:25:18,511: 4266479415.py: <module>: accuracy=0.976101
DEBUG: 2023-08-02 00:25:18,512: 4266479415.py: <module>: precision=0.978537
DEBUG: 2023-08-02 00:25:18,514: 4266479415.py: <module>: recall=0.977879
DEBUG: 2023-08-02 00:25:18,514: 4266479415.py: <module>: f1=0.97806
DEBUG: 2023-08-02 00:25:18,516: 4266479415.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.998778, 'WALKING_UPSTAIRS': 0.998595, 'WALKING_DOWNSTAIRS': 0.999494, 'SITTING': 0.932028, 'STANDING': 0.939467}
DEBUG: 2023-08-02 00:25:18,517: 4266479415.py: <module>: ---test---
DEBUG: 2023-08-02 00:25:18,518: 4266479415.py: <module>: logloss=0.444966
DEBUG: 2023-08-02 00:25:18,519: 4266479415.py: <module>: accuracy=0.930839
DEBUG: 2023-08-02 00:25:18,520: 4266479415.py: <module>: precision=0.932053
DEBUG: 2023-08-02 00:25:18,521: 4266479415.py: <module>: recall=0.932748
DEBUG: 2023-08-02 00:25:18,521: 4266479415.py: <module>: f1=0.930964
DEBUG: 2023-08-02 00:25:18,522: 4266479415.py: <module>: per-class f1={'LAYING': 0.99009, 'WALKING': 0.939863, 'WALKING_UPSTAIRS': 0.953038, 'WALKING_DOWNSTAIRS': 0.929513, 'SITTING': 0.877665, 'STANDING': 0.895616}
DEBUG: 2023-08-02 00:25:20,119: 2315415076.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 00:25:25,068: 1695527446.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 00:25:25,072: 1695527446.py: <module>: accuracy=0.9395255596391581
DEBUG: 2023-08-02 00:25:25,076: 1695527446.py: <module>: precision=0.9402795834885803
DEBUG: 2023-08-02 00:25:25,081: 1695527446.py: <module>: recall=0.9412854825568419
DEBUG: 2023-08-02 00:25:25,085: 1695527446.py: <module>: f1=0.939481073473297
DEBUG: 2023-08-02 00:25:25,089: 1695527446.py: <module>: per-class f1=[0.9981685  0.94503171 0.96544276 0.92699115 0.89365854 0.90759378]
