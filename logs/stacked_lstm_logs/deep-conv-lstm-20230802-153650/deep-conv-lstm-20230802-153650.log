DEBUG: 2023-08-02 15:36:50,511: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/stacked_lstm_logs/deep-conv-lstm-20230802-153650/deep-conv-lstm-20230802-153650.log
DEBUG: 2023-08-02 15:37:02,030: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 15:37:02,031: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 15:37:02,034: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 15:37:02,036: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 15:37:02,036: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 15:37:02,037: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 15:37:02,038: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 15:37:02,040: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 15:37:02,041: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 15:37:02,042: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 15:37:02,044: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 15:37:02,045: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 15:37:02,046: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 15:37:02,048: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 15:37:02,049: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 15:37:02,050: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 15:37:02,083: 1134177668.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-08-02 15:37:02,118: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 15:37:02,119: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 15:37:05,039: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 15:37:13,602: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 15:37:21,486: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.231 - accuracy: 0.9409 - val_loss: 0.1746 - val_accuracy: 0.9588
DEBUG: 2023-08-02 15:37:29,745: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1604 - accuracy: 0.9522 - val_loss: 0.129 - val_accuracy: 0.9656
DEBUG: 2023-08-02 15:37:38,053: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1634 - accuracy: 0.9499 - val_loss: 0.1323 - val_accuracy: 0.9676
DEBUG: 2023-08-02 15:37:46,400: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1423 - accuracy: 0.9566 - val_loss: 0.1669 - val_accuracy: 0.9575
DEBUG: 2023-08-02 15:37:54,794: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.144 - accuracy: 0.9549 - val_loss: 0.1349 - val_accuracy: 0.969
DEBUG: 2023-08-02 15:38:02,358: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1127 - accuracy: 0.9608 - val_loss: 0.0998 - val_accuracy: 0.9723
DEBUG: 2023-08-02 15:38:10,515: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1932 - accuracy: 0.9353 - val_loss: 0.152 - val_accuracy: 0.9487
DEBUG: 2023-08-02 15:38:18,669: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1302 - accuracy: 0.9522 - val_loss: 0.1061 - val_accuracy: 0.9629
DEBUG: 2023-08-02 15:38:26,871: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1375 - accuracy: 0.9561 - val_loss: 0.0868 - val_accuracy: 0.969
DEBUG: 2023-08-02 15:38:35,181: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1054 - accuracy: 0.9593 - val_loss: 0.12 - val_accuracy: 0.9595
DEBUG: 2023-08-02 15:38:43,464: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1239 - accuracy: 0.9571 - val_loss: 0.1237 - val_accuracy: 0.9561
DEBUG: 2023-08-02 15:38:51,985: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.093 - accuracy: 0.9646 - val_loss: 0.0894 - val_accuracy: 0.9676
DEBUG: 2023-08-02 15:38:59,893: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 15:39:08,377: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 15:39:08,378: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 15:39:09,271: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 15:39:25,273: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.5244 - accuracy: 0.8651 - val_loss: 0.7444 - val_accuracy: 0.7792
DEBUG: 2023-08-02 15:39:33,123: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2969 - accuracy: 0.9198 - val_loss: 0.2266 - val_accuracy: 0.9507
DEBUG: 2023-08-02 15:39:41,690: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1723 - accuracy: 0.9556 - val_loss: 0.1603 - val_accuracy: 0.9521
DEBUG: 2023-08-02 15:39:50,461: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1492 - accuracy: 0.9541 - val_loss: 0.148 - val_accuracy: 0.9575
DEBUG: 2023-08-02 15:39:59,855: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1226 - accuracy: 0.9625 - val_loss: 0.1168 - val_accuracy: 0.9554
DEBUG: 2023-08-02 15:40:09,109: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.118 - accuracy: 0.9644 - val_loss: 0.1127 - val_accuracy: 0.9575
DEBUG: 2023-08-02 15:40:17,896: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1219 - accuracy: 0.9619 - val_loss: 0.118 - val_accuracy: 0.9561
DEBUG: 2023-08-02 15:40:26,378: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1177 - accuracy: 0.9573 - val_loss: 0.112 - val_accuracy: 0.9581
DEBUG: 2023-08-02 15:40:34,842: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1097 - accuracy: 0.9588 - val_loss: 0.1076 - val_accuracy: 0.9602
DEBUG: 2023-08-02 15:40:43,269: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1007 - accuracy: 0.963 - val_loss: 0.104 - val_accuracy: 0.9602
DEBUG: 2023-08-02 15:40:51,935: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1058 - accuracy: 0.9597 - val_loss: 0.1024 - val_accuracy: 0.9575
DEBUG: 2023-08-02 15:41:00,522: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0938 - accuracy: 0.9597 - val_loss: 0.0847 - val_accuracy: 0.9581
DEBUG: 2023-08-02 15:41:09,104: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0864 - accuracy: 0.9669 - val_loss: 0.0865 - val_accuracy: 0.9595
DEBUG: 2023-08-02 15:41:17,949: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.1452 - accuracy: 0.9543 - val_loss: 0.1578 - val_accuracy: 0.95
DEBUG: 2023-08-02 15:41:26,586: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.1154 - accuracy: 0.9563 - val_loss: 0.1064 - val_accuracy: 0.9588
DEBUG: 2023-08-02 15:41:36,541: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 15:41:36,542: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 15:41:37,455: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 15:41:53,237: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2411 - accuracy: 0.9424 - val_loss: 0.24 - val_accuracy: 0.9325
DEBUG: 2023-08-02 15:42:01,693: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1609 - accuracy: 0.9543 - val_loss: 0.1493 - val_accuracy: 0.9514
DEBUG: 2023-08-02 15:42:09,965: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1434 - accuracy: 0.9521 - val_loss: 0.1478 - val_accuracy: 0.9507
DEBUG: 2023-08-02 15:42:18,498: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.126 - accuracy: 0.9585 - val_loss: 0.1402 - val_accuracy: 0.9514
DEBUG: 2023-08-02 15:42:27,566: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.2427 - accuracy: 0.9379 - val_loss: 0.3621 - val_accuracy: 0.9142
DEBUG: 2023-08-02 15:42:36,580: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1115 - accuracy: 0.9571 - val_loss: 0.1233 - val_accuracy: 0.9494
DEBUG: 2023-08-02 15:42:45,375: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1147 - accuracy: 0.9583 - val_loss: 0.1384 - val_accuracy: 0.9507
DEBUG: 2023-08-02 15:42:54,095: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1064 - accuracy: 0.9619 - val_loss: 0.1294 - val_accuracy: 0.9507
DEBUG: 2023-08-02 15:43:02,975: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.109 - accuracy: 0.957 - val_loss: 0.1407 - val_accuracy: 0.946
DEBUG: 2023-08-02 15:43:11,442: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.102 - accuracy: 0.96 - val_loss: 0.1202 - val_accuracy: 0.9541
DEBUG: 2023-08-02 15:43:20,090: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1137 - accuracy: 0.9617 - val_loss: 0.2221 - val_accuracy: 0.944
DEBUG: 2023-08-02 15:43:28,545: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1431 - accuracy: 0.9543 - val_loss: 0.1465 - val_accuracy: 0.9514
DEBUG: 2023-08-02 15:43:37,034: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0964 - accuracy: 0.9656 - val_loss: 0.1243 - val_accuracy: 0.9527
DEBUG: 2023-08-02 15:43:45,715: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.1032 - accuracy: 0.9571 - val_loss: 0.1093 - val_accuracy: 0.9548
DEBUG: 2023-08-02 15:43:54,709: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.1062 - accuracy: 0.9612 - val_loss: 0.1393 - val_accuracy: 0.9521
DEBUG: 2023-08-02 15:44:03,431: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.1075 - accuracy: 0.96 - val_loss: 0.1083 - val_accuracy: 0.9514
DEBUG: 2023-08-02 15:44:12,179: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.125 - accuracy: 0.9634 - val_loss: 0.3099 - val_accuracy: 0.9305
DEBUG: 2023-08-02 15:44:20,954: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.0781 - accuracy: 0.9671 - val_loss: 0.0939 - val_accuracy: 0.9568
DEBUG: 2023-08-02 15:44:29,463: keras_callback.py: on_epoch_end: Epoch 190/10000 - loss: 0.081 - accuracy: 0.9652 - val_loss: 0.0958 - val_accuracy: 0.9568
DEBUG: 2023-08-02 15:44:38,021: keras_callback.py: on_epoch_end: Epoch 200/10000 - loss: 0.0754 - accuracy: 0.9659 - val_loss: 0.0892 - val_accuracy: 0.9602
DEBUG: 2023-08-02 15:44:46,681: keras_callback.py: on_epoch_end: Epoch 210/10000 - loss: 0.0801 - accuracy: 0.9666 - val_loss: 0.1011 - val_accuracy: 0.9588
DEBUG: 2023-08-02 15:44:55,224: keras_callback.py: on_epoch_end: Epoch 220/10000 - loss: 0.2291 - accuracy: 0.9372 - val_loss: 0.1397 - val_accuracy: 0.9473
DEBUG: 2023-08-02 15:45:03,907: keras_callback.py: on_epoch_end: Epoch 230/10000 - loss: 0.0942 - accuracy: 0.9684 - val_loss: 0.1082 - val_accuracy: 0.9554
DEBUG: 2023-08-02 15:45:17,153: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 15:45:17,154: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 15:45:18,015: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 15:45:33,341: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2461 - accuracy: 0.9399 - val_loss: 0.2191 - val_accuracy: 0.9419
DEBUG: 2023-08-02 15:45:42,057: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1844 - accuracy: 0.9492 - val_loss: 0.1914 - val_accuracy: 0.9419
DEBUG: 2023-08-02 15:45:50,939: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1598 - accuracy: 0.9512 - val_loss: 0.1394 - val_accuracy: 0.9581
DEBUG: 2023-08-02 15:45:59,959: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1569 - accuracy: 0.949 - val_loss: 0.1425 - val_accuracy: 0.9554
DEBUG: 2023-08-02 15:46:08,841: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1258 - accuracy: 0.9581 - val_loss: 0.1115 - val_accuracy: 0.9602
DEBUG: 2023-08-02 15:46:17,787: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1352 - accuracy: 0.9543 - val_loss: 0.1111 - val_accuracy: 0.9581
DEBUG: 2023-08-02 15:46:26,562: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1211 - accuracy: 0.9551 - val_loss: 0.1154 - val_accuracy: 0.9541
DEBUG: 2023-08-02 15:46:35,327: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1225 - accuracy: 0.9541 - val_loss: 0.0977 - val_accuracy: 0.9602
DEBUG: 2023-08-02 15:46:43,968: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1146 - accuracy: 0.9563 - val_loss: 0.0955 - val_accuracy: 0.9581
DEBUG: 2023-08-02 15:46:52,495: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1008 - accuracy: 0.9607 - val_loss: 0.0959 - val_accuracy: 0.9608
DEBUG: 2023-08-02 15:47:01,245: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1272 - accuracy: 0.9538 - val_loss: 0.1048 - val_accuracy: 0.9588
DEBUG: 2023-08-02 15:47:09,811: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1028 - accuracy: 0.9583 - val_loss: 0.1069 - val_accuracy: 0.9575
DEBUG: 2023-08-02 15:47:18,324: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0871 - accuracy: 0.9619 - val_loss: 0.0912 - val_accuracy: 0.9575
DEBUG: 2023-08-02 15:47:30,203: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 15:47:30,204: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 15:47:31,066: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 15:47:47,253: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2956 - accuracy: 0.9269 - val_loss: 0.2434 - val_accuracy: 0.9379
DEBUG: 2023-08-02 15:47:56,019: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1529 - accuracy: 0.9583 - val_loss: 0.1417 - val_accuracy: 0.9541
DEBUG: 2023-08-02 15:48:04,838: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1356 - accuracy: 0.9575 - val_loss: 0.1225 - val_accuracy: 0.9602
DEBUG: 2023-08-02 15:48:13,580: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.126 - accuracy: 0.9575 - val_loss: 0.1224 - val_accuracy: 0.9662
DEBUG: 2023-08-02 15:48:22,343: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1131 - accuracy: 0.9634 - val_loss: 0.1161 - val_accuracy: 0.9588
DEBUG: 2023-08-02 15:48:31,166: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1106 - accuracy: 0.9593 - val_loss: 0.1204 - val_accuracy: 0.9642
DEBUG: 2023-08-02 15:48:40,024: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1022 - accuracy: 0.9671 - val_loss: 0.1065 - val_accuracy: 0.9642
DEBUG: 2023-08-02 15:48:48,789: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1022 - accuracy: 0.9649 - val_loss: 0.1067 - val_accuracy: 0.9642
DEBUG: 2023-08-02 15:48:57,743: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1057 - accuracy: 0.9619 - val_loss: 0.126 - val_accuracy: 0.9507
DEBUG: 2023-08-02 15:49:09,287: 4266479415.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 15:49:09,289: 4266479415.py: <module>: ---train---
DEBUG: 2023-08-02 15:49:09,290: 4266479415.py: <module>: logloss=0.078292
DEBUG: 2023-08-02 15:49:09,291: 4266479415.py: <module>: accuracy=0.967965
DEBUG: 2023-08-02 15:49:09,292: 4266479415.py: <module>: precision=0.971775
DEBUG: 2023-08-02 15:49:09,293: 4266479415.py: <module>: recall=0.970394
DEBUG: 2023-08-02 15:49:09,294: 4266479415.py: <module>: f1=0.970652
DEBUG: 2023-08-02 15:49:09,295: 4266479415.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.999898, 'WALKING_UPSTAIRS': 0.999767, 'WALKING_DOWNSTAIRS': 1.0, 'SITTING': 0.906049, 'STANDING': 0.918201}
DEBUG: 2023-08-02 15:49:09,296: 4266479415.py: <module>: ---valid---
DEBUG: 2023-08-02 15:49:09,298: 4266479415.py: <module>: logloss=0.084349
DEBUG: 2023-08-02 15:49:09,299: 4266479415.py: <module>: accuracy=0.964487
DEBUG: 2023-08-02 15:49:09,300: 4266479415.py: <module>: precision=0.968381
DEBUG: 2023-08-02 15:49:09,301: 4266479415.py: <module>: recall=0.967058
DEBUG: 2023-08-02 15:49:09,302: 4266479415.py: <module>: f1=0.967305
DEBUG: 2023-08-02 15:49:09,303: 4266479415.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.996743, 'WALKING_UPSTAIRS': 0.999065, 'WALKING_DOWNSTAIRS': 0.998478, 'SITTING': 0.89814, 'STANDING': 0.911404}
DEBUG: 2023-08-02 15:49:09,304: 4266479415.py: <module>: ---test---
DEBUG: 2023-08-02 15:49:09,305: 4266479415.py: <module>: logloss=0.420281
DEBUG: 2023-08-02 15:49:09,306: 4266479415.py: <module>: accuracy=0.927163
DEBUG: 2023-08-02 15:49:09,306: 4266479415.py: <module>: precision=0.928374
DEBUG: 2023-08-02 15:49:09,307: 4266479415.py: <module>: recall=0.928847
DEBUG: 2023-08-02 15:49:09,308: 4266479415.py: <module>: f1=0.927529
DEBUG: 2023-08-02 15:49:09,310: 4266479415.py: <module>: per-class f1={'LAYING': 0.986224, 'WALKING': 0.930425, 'WALKING_UPSTAIRS': 0.94626, 'WALKING_DOWNSTAIRS': 0.936959, 'SITTING': 0.876761, 'STANDING': 0.888544}
DEBUG: 2023-08-02 15:49:09,322: 1695527446.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 15:49:09,325: 1695527446.py: <module>: accuracy=0.944537253591714
DEBUG: 2023-08-02 15:49:09,329: 1695527446.py: <module>: precision=0.9450261084098219
DEBUG: 2023-08-02 15:49:09,334: 1695527446.py: <module>: recall=0.9462053494623178
DEBUG: 2023-08-02 15:49:09,338: 1695527446.py: <module>: f1=0.9444664453304888
DEBUG: 2023-08-02 15:49:09,343: 1695527446.py: <module>: per-class f1=[0.99181074 0.93907563 0.96336207 0.94250282 0.90926457 0.92078285]
