DEBUG: 2023-08-02 09:47:47,800: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/bidirectional_lstm_logs/deep-conv-lstm-20230802-094747/deep-conv-lstm-20230802-094747.log
DEBUG: 2023-08-02 09:47:59,704: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 09:47:59,704: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 09:47:59,708: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 09:47:59,709: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 09:47:59,710: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 09:47:59,710: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 09:47:59,711: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 09:47:59,712: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 09:47:59,713: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 09:47:59,714: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 09:47:59,715: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 09:47:59,716: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 09:47:59,717: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 09:47:59,718: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 09:47:59,719: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 09:47:59,720: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 09:47:59,758: 3642186603.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-08-02 09:47:59,825: 222416104.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 09:47:59,826: 222416104.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 09:48:02,740: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 09:48:09,559: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 09:48:15,458: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2502 - accuracy: 0.9298 - val_loss: 0.2869 - val_accuracy: 0.9123
DEBUG: 2023-08-02 09:48:21,986: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1719 - accuracy: 0.9531 - val_loss: 0.1575 - val_accuracy: 0.9636
DEBUG: 2023-08-02 09:48:28,323: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1623 - accuracy: 0.9505 - val_loss: 0.1318 - val_accuracy: 0.9663
DEBUG: 2023-08-02 09:48:34,777: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1278 - accuracy: 0.9588 - val_loss: 0.1175 - val_accuracy: 0.9669
DEBUG: 2023-08-02 09:48:41,159: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1455 - accuracy: 0.9543 - val_loss: 0.1315 - val_accuracy: 0.9649
DEBUG: 2023-08-02 09:48:47,472: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1358 - accuracy: 0.9576 - val_loss: 0.117 - val_accuracy: 0.969
DEBUG: 2023-08-02 09:48:54,010: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1252 - accuracy: 0.9544 - val_loss: 0.1083 - val_accuracy: 0.9696
DEBUG: 2023-08-02 09:49:00,579: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1333 - accuracy: 0.9531 - val_loss: 0.1186 - val_accuracy: 0.9602
DEBUG: 2023-08-02 09:49:07,014: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.111 - accuracy: 0.9605 - val_loss: 0.1021 - val_accuracy: 0.9663
DEBUG: 2023-08-02 09:49:13,569: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0997 - accuracy: 0.9622 - val_loss: 0.0927 - val_accuracy: 0.971
DEBUG: 2023-08-02 09:49:20,145: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1635 - accuracy: 0.9436 - val_loss: 0.1251 - val_accuracy: 0.9615
DEBUG: 2023-08-02 09:49:26,643: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1026 - accuracy: 0.9651 - val_loss: 0.0935 - val_accuracy: 0.969
DEBUG: 2023-08-02 09:49:33,127: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1038 - accuracy: 0.9639 - val_loss: 0.1015 - val_accuracy: 0.9669
DEBUG: 2023-08-02 09:49:39,691: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.109 - accuracy: 0.961 - val_loss: 0.0996 - val_accuracy: 0.969
DEBUG: 2023-08-02 09:49:46,363: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0736 - accuracy: 0.9732 - val_loss: 0.0751 - val_accuracy: 0.9771
DEBUG: 2023-08-02 09:49:52,975: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0838 - accuracy: 0.9723 - val_loss: 0.0822 - val_accuracy: 0.9757
DEBUG: 2023-08-02 09:49:59,615: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.0999 - accuracy: 0.9686 - val_loss: 0.2246 - val_accuracy: 0.9548
DEBUG: 2023-08-02 09:50:05,295: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 09:50:12,220: 222416104.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 09:50:12,221: 222416104.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 09:50:12,862: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 09:50:24,923: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3472 - accuracy: 0.8861 - val_loss: 0.3178 - val_accuracy: 0.8947
DEBUG: 2023-08-02 09:50:31,809: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2561 - accuracy: 0.9293 - val_loss: 0.2012 - val_accuracy: 0.9514
DEBUG: 2023-08-02 09:50:38,552: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1771 - accuracy: 0.9549 - val_loss: 0.2137 - val_accuracy: 0.948
DEBUG: 2023-08-02 09:50:45,300: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1716 - accuracy: 0.9524 - val_loss: 0.1586 - val_accuracy: 0.9595
DEBUG: 2023-08-02 09:50:52,218: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1401 - accuracy: 0.9565 - val_loss: 0.1316 - val_accuracy: 0.9561
DEBUG: 2023-08-02 09:50:59,006: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1106 - accuracy: 0.962 - val_loss: 0.1117 - val_accuracy: 0.9554
DEBUG: 2023-08-02 09:51:05,958: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1463 - accuracy: 0.9495 - val_loss: 0.1537 - val_accuracy: 0.9534
DEBUG: 2023-08-02 09:51:12,790: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1304 - accuracy: 0.9598 - val_loss: 0.1129 - val_accuracy: 0.9568
DEBUG: 2023-08-02 09:51:19,782: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1967 - accuracy: 0.9359 - val_loss: 0.1163 - val_accuracy: 0.9527
DEBUG: 2023-08-02 09:51:26,560: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0974 - accuracy: 0.9634 - val_loss: 0.0985 - val_accuracy: 0.9662
DEBUG: 2023-08-02 09:51:34,413: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1064 - accuracy: 0.9625 - val_loss: 0.0999 - val_accuracy: 0.9561
DEBUG: 2023-08-02 09:51:41,699: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0932 - accuracy: 0.9657 - val_loss: 0.1514 - val_accuracy: 0.9534
DEBUG: 2023-08-02 09:51:49,252: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.0923 - accuracy: 0.9676 - val_loss: 0.0996 - val_accuracy: 0.9595
DEBUG: 2023-08-02 09:51:56,500: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.1011 - accuracy: 0.9635 - val_loss: 0.1316 - val_accuracy: 0.9541
DEBUG: 2023-08-02 09:52:03,391: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0943 - accuracy: 0.9647 - val_loss: 0.0937 - val_accuracy: 0.9676
DEBUG: 2023-08-02 09:52:10,289: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0877 - accuracy: 0.9689 - val_loss: 0.0798 - val_accuracy: 0.9676
DEBUG: 2023-08-02 09:52:19,482: 222416104.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 09:52:19,484: 222416104.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 09:52:20,118: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 09:52:32,318: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2317 - accuracy: 0.9403 - val_loss: 0.2291 - val_accuracy: 0.9406
DEBUG: 2023-08-02 09:52:39,250: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2896 - accuracy: 0.9161 - val_loss: 0.2423 - val_accuracy: 0.9291
DEBUG: 2023-08-02 09:52:46,182: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1525 - accuracy: 0.957 - val_loss: 0.1527 - val_accuracy: 0.9507
DEBUG: 2023-08-02 09:52:53,118: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1314 - accuracy: 0.9605 - val_loss: 0.1559 - val_accuracy: 0.944
DEBUG: 2023-08-02 09:53:00,585: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1173 - accuracy: 0.9612 - val_loss: 0.1449 - val_accuracy: 0.9527
DEBUG: 2023-08-02 09:53:07,697: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.104 - accuracy: 0.9617 - val_loss: 0.1368 - val_accuracy: 0.9467
DEBUG: 2023-08-02 09:53:14,581: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.2433 - accuracy: 0.9271 - val_loss: 0.2078 - val_accuracy: 0.944
DEBUG: 2023-08-02 09:53:21,499: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1296 - accuracy: 0.9592 - val_loss: 0.1333 - val_accuracy: 0.95
DEBUG: 2023-08-02 09:53:28,359: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0902 - accuracy: 0.9651 - val_loss: 0.1155 - val_accuracy: 0.9561
DEBUG: 2023-08-02 09:53:35,178: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1248 - accuracy: 0.9593 - val_loss: 0.147 - val_accuracy: 0.948
DEBUG: 2023-08-02 09:53:43,279: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1774 - accuracy: 0.9404 - val_loss: 0.1832 - val_accuracy: 0.9352
DEBUG: 2023-08-02 09:53:56,385: 222416104.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 09:53:56,386: 222416104.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 09:53:57,144: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 09:54:10,642: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.4927 - accuracy: 0.837 - val_loss: 0.6441 - val_accuracy: 0.7792
DEBUG: 2023-08-02 09:54:17,654: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1998 - accuracy: 0.9505 - val_loss: 0.4778 - val_accuracy: 0.8501
DEBUG: 2023-08-02 09:54:24,431: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2517 - accuracy: 0.9271 - val_loss: 0.2228 - val_accuracy: 0.9291
DEBUG: 2023-08-02 09:54:31,521: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2381 - accuracy: 0.9274 - val_loss: 0.1942 - val_accuracy: 0.9433
DEBUG: 2023-08-02 09:54:38,444: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1576 - accuracy: 0.9581 - val_loss: 0.1409 - val_accuracy: 0.9595
DEBUG: 2023-08-02 09:54:45,747: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1537 - accuracy: 0.9516 - val_loss: 0.1282 - val_accuracy: 0.9581
DEBUG: 2023-08-02 09:54:52,973: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1244 - accuracy: 0.9615 - val_loss: 0.1179 - val_accuracy: 0.9595
DEBUG: 2023-08-02 09:55:00,032: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1448 - accuracy: 0.9556 - val_loss: 0.1269 - val_accuracy: 0.9575
DEBUG: 2023-08-02 09:55:06,999: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1474 - accuracy: 0.9561 - val_loss: 0.1114 - val_accuracy: 0.9649
DEBUG: 2023-08-02 09:55:13,941: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1452 - accuracy: 0.9526 - val_loss: 0.1175 - val_accuracy: 0.9581
DEBUG: 2023-08-02 09:55:21,179: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1112 - accuracy: 0.9595 - val_loss: 0.1048 - val_accuracy: 0.9588
DEBUG: 2023-08-02 09:55:28,454: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1028 - accuracy: 0.9659 - val_loss: 0.111 - val_accuracy: 0.9608
DEBUG: 2023-08-02 09:55:35,246: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1 - accuracy: 0.9639 - val_loss: 0.1176 - val_accuracy: 0.9602
DEBUG: 2023-08-02 09:55:42,133: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0903 - accuracy: 0.9698 - val_loss: 0.1114 - val_accuracy: 0.9581
DEBUG: 2023-08-02 09:55:51,218: 222416104.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 09:55:51,218: 222416104.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 09:55:51,884: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 09:56:05,058: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2082 - accuracy: 0.9451 - val_loss: 0.1787 - val_accuracy: 0.9521
DEBUG: 2023-08-02 09:56:12,546: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1441 - accuracy: 0.9576 - val_loss: 0.1385 - val_accuracy: 0.9602
DEBUG: 2023-08-02 09:56:19,430: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.199 - accuracy: 0.9433 - val_loss: 0.1595 - val_accuracy: 0.9561
DEBUG: 2023-08-02 09:56:27,142: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1322 - accuracy: 0.9588 - val_loss: 0.1361 - val_accuracy: 0.9615
DEBUG: 2023-08-02 09:56:35,002: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1083 - accuracy: 0.9639 - val_loss: 0.1229 - val_accuracy: 0.9649
DEBUG: 2023-08-02 09:56:42,463: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1115 - accuracy: 0.9608 - val_loss: 0.125 - val_accuracy: 0.9581
DEBUG: 2023-08-02 09:56:49,789: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1328 - accuracy: 0.9554 - val_loss: 0.3202 - val_accuracy: 0.8778
DEBUG: 2023-08-02 09:56:57,562: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1075 - accuracy: 0.9644 - val_loss: 0.1191 - val_accuracy: 0.9581
DEBUG: 2023-08-02 09:57:05,726: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1077 - accuracy: 0.9632 - val_loss: 0.1182 - val_accuracy: 0.9575
DEBUG: 2023-08-02 09:57:13,518: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.103 - accuracy: 0.9679 - val_loss: 0.1086 - val_accuracy: 0.9696
DEBUG: 2023-08-02 09:57:21,369: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.0888 - accuracy: 0.9681 - val_loss: 0.1001 - val_accuracy: 0.9689
DEBUG: 2023-08-02 09:57:28,931: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.0995 - accuracy: 0.9629 - val_loss: 0.1015 - val_accuracy: 0.9629
DEBUG: 2023-08-02 09:57:36,600: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1273 - accuracy: 0.9561 - val_loss: 0.1229 - val_accuracy: 0.9575
DEBUG: 2023-08-02 09:57:43,579: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.0918 - accuracy: 0.9681 - val_loss: 0.1194 - val_accuracy: 0.9615
DEBUG: 2023-08-02 09:57:51,434: 4266479415.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 09:57:51,437: 4266479415.py: <module>: ---train---
DEBUG: 2023-08-02 09:57:51,438: 4266479415.py: <module>: logloss=0.084251
DEBUG: 2023-08-02 09:57:51,439: 4266479415.py: <module>: accuracy=0.970835
DEBUG: 2023-08-02 09:57:51,441: 4266479415.py: <module>: precision=0.973777
DEBUG: 2023-08-02 09:57:51,442: 4266479415.py: <module>: recall=0.973188
DEBUG: 2023-08-02 09:57:51,444: 4266479415.py: <module>: f1=0.973315
DEBUG: 2023-08-02 09:57:51,445: 4266479415.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.999694, 'WALKING_UPSTAIRS': 0.999767, 'WALKING_DOWNSTAIRS': 0.999873, 'SITTING': 0.915583, 'STANDING': 0.924975}
DEBUG: 2023-08-02 09:57:51,446: 4266479415.py: <module>: ---valid---
DEBUG: 2023-08-02 09:57:51,447: 4266479415.py: <module>: logloss=0.088988
DEBUG: 2023-08-02 09:57:51,449: 4266479415.py: <module>: accuracy=0.966782
DEBUG: 2023-08-02 09:57:51,450: 4266479415.py: <module>: precision=0.969847
DEBUG: 2023-08-02 09:57:51,451: 4266479415.py: <module>: recall=0.969367
DEBUG: 2023-08-02 09:57:51,453: 4266479415.py: <module>: f1=0.96943
DEBUG: 2023-08-02 09:57:51,454: 4266479415.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.997149, 'WALKING_UPSTAIRS': 0.998126, 'WALKING_DOWNSTAIRS': 0.99899, 'SITTING': 0.905332, 'STANDING': 0.916984}
DEBUG: 2023-08-02 09:57:51,455: 4266479415.py: <module>: ---test---
DEBUG: 2023-08-02 09:57:51,457: 4266479415.py: <module>: logloss=0.358941
DEBUG: 2023-08-02 09:57:51,459: 4266479415.py: <module>: accuracy=0.936853
DEBUG: 2023-08-02 09:57:51,467: 4266479415.py: <module>: precision=0.938512
DEBUG: 2023-08-02 09:57:51,468: 4266479415.py: <module>: recall=0.938654
DEBUG: 2023-08-02 09:57:51,472: 4266479415.py: <module>: f1=0.937584
DEBUG: 2023-08-02 09:57:51,476: 4266479415.py: <module>: per-class f1={'LAYING': 0.993997, 'WALKING': 0.947804, 'WALKING_UPSTAIRS': 0.958942, 'WALKING_DOWNSTAIRS': 0.951091, 'SITTING': 0.87877, 'STANDING': 0.894897}
DEBUG: 2023-08-02 09:57:51,488: 1672468834.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 09:57:51,496: 1672468834.py: <module>: accuracy=0.9415302372201804
DEBUG: 2023-08-02 09:57:51,501: 1672468834.py: <module>: precision=0.9432831858185199
DEBUG: 2023-08-02 09:57:51,506: 1672468834.py: <module>: recall=0.9435886100223394
DEBUG: 2023-08-02 09:57:51,511: 1672468834.py: <module>: f1=0.9427531044277239
DEBUG: 2023-08-02 09:57:51,515: 1672468834.py: <module>: per-class f1=[0.99543379 0.95941727 0.9749728  0.956621   0.87692308 0.89315068]
