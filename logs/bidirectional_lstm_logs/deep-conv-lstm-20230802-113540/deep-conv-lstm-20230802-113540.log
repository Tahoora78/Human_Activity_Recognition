DEBUG: 2023-08-02 11:35:40,090: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/bidirectional_lstm_logs/deep-conv-lstm-20230802-113540/deep-conv-lstm-20230802-113540.log
DEBUG: 2023-08-02 11:35:51,456: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 11:35:51,457: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 11:35:51,459: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 11:35:51,460: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 11:35:51,461: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 11:35:51,462: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 11:35:51,463: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 11:35:51,464: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 11:35:51,465: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 11:35:51,465: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 11:35:51,466: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 11:35:51,467: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 11:35:51,468: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 11:35:51,469: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 11:35:51,470: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 11:35:51,471: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 11:35:51,502: 3642186603.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-08-02 11:35:51,557: 222416104.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 11:35:51,558: 222416104.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 11:35:54,187: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 11:36:00,665: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 11:36:06,375: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1914 - accuracy: 0.9281 - val_loss: 0.1279 - val_accuracy: 0.948
DEBUG: 2023-08-02 11:36:12,613: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1225 - accuracy: 0.9505 - val_loss: 0.1058 - val_accuracy: 0.9609
DEBUG: 2023-08-02 11:36:18,723: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0945 - accuracy: 0.9549 - val_loss: 0.0894 - val_accuracy: 0.9663
DEBUG: 2023-08-02 11:36:25,016: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0939 - accuracy: 0.9553 - val_loss: 0.1035 - val_accuracy: 0.9622
DEBUG: 2023-08-02 11:36:30,887: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1073 - accuracy: 0.9519 - val_loss: 0.1446 - val_accuracy: 0.9588
DEBUG: 2023-08-02 11:36:36,760: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 11:36:43,002: 222416104.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 11:36:43,003: 222416104.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 11:36:43,573: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 11:36:54,586: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1835 - accuracy: 0.9354 - val_loss: 0.15 - val_accuracy: 0.9399
DEBUG: 2023-08-02 11:37:00,805: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1441 - accuracy: 0.947 - val_loss: 0.2235 - val_accuracy: 0.9291
DEBUG: 2023-08-02 11:37:06,855: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0967 - accuracy: 0.9575 - val_loss: 0.0857 - val_accuracy: 0.9581
DEBUG: 2023-08-02 11:37:12,854: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0859 - accuracy: 0.9629 - val_loss: 0.0885 - val_accuracy: 0.9595
DEBUG: 2023-08-02 11:37:19,065: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1115 - accuracy: 0.9553 - val_loss: 0.1052 - val_accuracy: 0.9554
DEBUG: 2023-08-02 11:37:25,102: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1442 - accuracy: 0.948 - val_loss: 0.0978 - val_accuracy: 0.9588
DEBUG: 2023-08-02 11:37:31,601: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.085 - accuracy: 0.9637 - val_loss: 0.0797 - val_accuracy: 0.9602
DEBUG: 2023-08-02 11:37:38,919: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0856 - accuracy: 0.9639 - val_loss: 0.073 - val_accuracy: 0.9575
DEBUG: 2023-08-02 11:37:45,044: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0828 - accuracy: 0.9666 - val_loss: 0.0783 - val_accuracy: 0.9608
DEBUG: 2023-08-02 11:37:51,426: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.2564 - accuracy: 0.9038 - val_loss: 0.1141 - val_accuracy: 0.9514
DEBUG: 2023-08-02 11:38:03,682: 222416104.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 11:38:03,683: 222416104.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 11:38:04,267: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 11:38:16,187: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1644 - accuracy: 0.9446 - val_loss: 0.1532 - val_accuracy: 0.9399
DEBUG: 2023-08-02 11:38:24,443: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1317 - accuracy: 0.9512 - val_loss: 0.1214 - val_accuracy: 0.9419
DEBUG: 2023-08-02 11:38:32,076: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1153 - accuracy: 0.9504 - val_loss: 0.1312 - val_accuracy: 0.9453
DEBUG: 2023-08-02 11:38:39,773: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.0938 - accuracy: 0.9598 - val_loss: 0.1111 - val_accuracy: 0.9548
DEBUG: 2023-08-02 11:38:47,373: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0883 - accuracy: 0.961 - val_loss: 0.0932 - val_accuracy: 0.9541
DEBUG: 2023-08-02 11:38:56,036: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0861 - accuracy: 0.9637 - val_loss: 0.0947 - val_accuracy: 0.9575
DEBUG: 2023-08-02 11:39:02,454: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0856 - accuracy: 0.9605 - val_loss: 0.0956 - val_accuracy: 0.9494
DEBUG: 2023-08-02 11:39:08,081: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0817 - accuracy: 0.9678 - val_loss: 0.0983 - val_accuracy: 0.9615
DEBUG: 2023-08-02 11:39:13,344: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0991 - accuracy: 0.9585 - val_loss: 0.0999 - val_accuracy: 0.9602
DEBUG: 2023-08-02 11:39:21,206: 222416104.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 11:39:21,207: 222416104.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 11:39:21,655: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 11:39:31,044: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2203 - accuracy: 0.9249 - val_loss: 0.1606 - val_accuracy: 0.9392
DEBUG: 2023-08-02 11:39:36,411: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1258 - accuracy: 0.9516 - val_loss: 0.0968 - val_accuracy: 0.9507
DEBUG: 2023-08-02 11:39:41,661: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1044 - accuracy: 0.9558 - val_loss: 0.0901 - val_accuracy: 0.9595
DEBUG: 2023-08-02 11:39:46,954: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.14 - accuracy: 0.9472 - val_loss: 0.1233 - val_accuracy: 0.9507
DEBUG: 2023-08-02 11:39:52,165: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.162 - accuracy: 0.9409 - val_loss: 0.1101 - val_accuracy: 0.9554
DEBUG: 2023-08-02 11:39:57,506: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.0935 - accuracy: 0.9602 - val_loss: 0.0755 - val_accuracy: 0.9635
DEBUG: 2023-08-02 11:40:02,764: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1205 - accuracy: 0.9514 - val_loss: 0.0906 - val_accuracy: 0.9588
DEBUG: 2023-08-02 11:40:08,024: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0927 - accuracy: 0.96 - val_loss: 0.0891 - val_accuracy: 0.9588
DEBUG: 2023-08-02 11:40:13,263: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0872 - accuracy: 0.9619 - val_loss: 0.0774 - val_accuracy: 0.9588
DEBUG: 2023-08-02 11:40:18,539: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0908 - accuracy: 0.9583 - val_loss: 0.0771 - val_accuracy: 0.9676
DEBUG: 2023-08-02 11:40:26,722: 222416104.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 11:40:26,723: 222416104.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 11:40:27,144: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 11:40:36,219: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.1791 - accuracy: 0.9406 - val_loss: 0.1498 - val_accuracy: 0.946
DEBUG: 2023-08-02 11:40:41,567: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1495 - accuracy: 0.9431 - val_loss: 0.1231 - val_accuracy: 0.95
DEBUG: 2023-08-02 11:40:46,864: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.0877 - accuracy: 0.9629 - val_loss: 0.0985 - val_accuracy: 0.9514
DEBUG: 2023-08-02 11:40:52,131: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2226 - accuracy: 0.922 - val_loss: 0.1622 - val_accuracy: 0.9386
DEBUG: 2023-08-02 11:40:57,461: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.0878 - accuracy: 0.9593 - val_loss: 0.0887 - val_accuracy: 0.9575
DEBUG: 2023-08-02 11:41:02,757: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.2122 - accuracy: 0.9357 - val_loss: 0.094 - val_accuracy: 0.9554
DEBUG: 2023-08-02 11:41:08,092: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.0819 - accuracy: 0.9671 - val_loss: 0.0772 - val_accuracy: 0.9608
DEBUG: 2023-08-02 11:41:13,388: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.0956 - accuracy: 0.9632 - val_loss: 0.0878 - val_accuracy: 0.9656
DEBUG: 2023-08-02 11:41:18,662: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0857 - accuracy: 0.9646 - val_loss: 0.0903 - val_accuracy: 0.9595
DEBUG: 2023-08-02 11:41:23,964: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0775 - accuracy: 0.9649 - val_loss: 0.0921 - val_accuracy: 0.9629
DEBUG: 2023-08-02 11:41:32,804: 4266479415.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 11:41:32,806: 4266479415.py: <module>: ---train---
DEBUG: 2023-08-02 11:41:32,806: 4266479415.py: <module>: logloss=0.07122
DEBUG: 2023-08-02 11:41:32,807: 4266479415.py: <module>: accuracy=0.965366
DEBUG: 2023-08-02 11:41:32,808: 4266479415.py: <module>: precision=0.96854
DEBUG: 2023-08-02 11:41:32,809: 4266479415.py: <module>: recall=0.968219
DEBUG: 2023-08-02 11:41:32,809: 4266479415.py: <module>: f1=0.968337
DEBUG: 2023-08-02 11:41:32,810: 4266479415.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.999796, 'WALKING_UPSTAIRS': 0.999883, 'WALKING_DOWNSTAIRS': 0.999747, 'SITTING': 0.899927, 'STANDING': 0.910668}
DEBUG: 2023-08-02 11:41:32,811: 4266479415.py: <module>: ---valid---
DEBUG: 2023-08-02 11:41:32,811: 4266479415.py: <module>: logloss=0.074397
DEBUG: 2023-08-02 11:41:32,812: 4266479415.py: <module>: accuracy=0.964488
DEBUG: 2023-08-02 11:41:32,813: 4266479415.py: <module>: precision=0.967838
DEBUG: 2023-08-02 11:41:32,813: 4266479415.py: <module>: recall=0.967302
DEBUG: 2023-08-02 11:41:32,814: 4266479415.py: <module>: f1=0.967406
DEBUG: 2023-08-02 11:41:32,814: 4266479415.py: <module>: per-class f1={'LAYING': 1.0, 'WALKING': 0.997965, 'WALKING_UPSTAIRS': 0.998604, 'WALKING_DOWNSTAIRS': 0.999491, 'SITTING': 0.898593, 'STANDING': 0.909785}
DEBUG: 2023-08-02 11:41:32,815: 4266479415.py: <module>: ---test---
DEBUG: 2023-08-02 11:41:32,815: 4266479415.py: <module>: logloss=0.39154
DEBUG: 2023-08-02 11:41:32,816: 4266479415.py: <module>: accuracy=0.93124
DEBUG: 2023-08-02 11:41:32,816: 4266479415.py: <module>: precision=0.932061
DEBUG: 2023-08-02 11:41:32,817: 4266479415.py: <module>: recall=0.933032
DEBUG: 2023-08-02 11:41:32,818: 4266479415.py: <module>: f1=0.931556
DEBUG: 2023-08-02 11:41:32,819: 4266479415.py: <module>: per-class f1={'LAYING': 0.985769, 'WALKING': 0.93506, 'WALKING_UPSTAIRS': 0.957796, 'WALKING_DOWNSTAIRS': 0.937094, 'SITTING': 0.879617, 'STANDING': 0.894001}
DEBUG: 2023-08-02 11:45:56,767: 1672468834.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 11:45:56,769: 1672468834.py: <module>: accuracy=0.9388573337788172
DEBUG: 2023-08-02 11:45:56,773: 1672468834.py: <module>: precision=0.9396873165692611
DEBUG: 2023-08-02 11:45:56,777: 1672468834.py: <module>: recall=0.940685634267488
DEBUG: 2023-08-02 11:45:56,781: 1672468834.py: <module>: f1=0.9392202312997714
DEBUG: 2023-08-02 11:45:56,785: 1672468834.py: <module>: per-class f1=[0.98642534 0.94637224 0.96544276 0.94130926 0.89254598 0.90322581]
