DEBUG: 2023-08-02 14:57:55,722: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/rnn_lstm_logs/deep-conv-lstm-20230802-145755/deep-conv-lstm-20230802-145755.log
DEBUG: 2023-08-02 14:58:06,884: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 14:58:06,885: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 14:58:06,889: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 14:58:06,890: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 14:58:06,891: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 14:58:06,891: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 14:58:06,893: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 14:58:06,893: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 14:58:06,894: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 14:58:06,895: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 14:58:06,896: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 14:58:06,897: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 14:58:06,897: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 14:58:06,899: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 14:58:06,901: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 14:58:06,902: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 14:58:06,937: 582463155.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-08-02 14:58:06,975: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 14:58:06,976: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 14:58:09,477: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 14:58:14,477: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 14:58:18,142: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3267 - accuracy: 0.9117 - val_loss: 0.3507 - val_accuracy: 0.9143
DEBUG: 2023-08-02 14:58:22,225: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2965 - accuracy: 0.907 - val_loss: 0.2489 - val_accuracy: 0.9386
DEBUG: 2023-08-02 14:58:27,108: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1959 - accuracy: 0.9419 - val_loss: 0.2063 - val_accuracy: 0.944
DEBUG: 2023-08-02 14:58:31,107: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2205 - accuracy: 0.9296 - val_loss: 0.1779 - val_accuracy: 0.9534
DEBUG: 2023-08-02 14:58:35,209: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1602 - accuracy: 0.9468 - val_loss: 0.1427 - val_accuracy: 0.9588
DEBUG: 2023-08-02 14:58:39,188: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1622 - accuracy: 0.9472 - val_loss: 0.1465 - val_accuracy: 0.9561
DEBUG: 2023-08-02 14:58:43,168: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1867 - accuracy: 0.9355 - val_loss: 0.1397 - val_accuracy: 0.9588
DEBUG: 2023-08-02 14:58:47,092: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1258 - accuracy: 0.9527 - val_loss: 0.1377 - val_accuracy: 0.9629
DEBUG: 2023-08-02 14:58:51,207: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1923 - accuracy: 0.9353 - val_loss: 0.1497 - val_accuracy: 0.9561
DEBUG: 2023-08-02 14:58:56,241: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1182 - accuracy: 0.9559 - val_loss: 0.1137 - val_accuracy: 0.969
DEBUG: 2023-08-02 14:59:01,085: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1295 - accuracy: 0.9524 - val_loss: 0.1256 - val_accuracy: 0.9615
DEBUG: 2023-08-02 14:59:05,617: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1264 - accuracy: 0.9519 - val_loss: 0.1136 - val_accuracy: 0.9656
DEBUG: 2023-08-02 14:59:10,482: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1157 - accuracy: 0.9564 - val_loss: 0.1049 - val_accuracy: 0.969
DEBUG: 2023-08-02 14:59:14,727: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.3173 - accuracy: 0.9207 - val_loss: 0.196 - val_accuracy: 0.944
DEBUG: 2023-08-02 14:59:18,930: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.1628 - accuracy: 0.9433 - val_loss: 0.1339 - val_accuracy: 0.9622
DEBUG: 2023-08-02 14:59:23,235: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.1207 - accuracy: 0.9571 - val_loss: 0.176 - val_accuracy: 0.9575
DEBUG: 2023-08-02 14:59:27,585: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.1289 - accuracy: 0.9571 - val_loss: 0.1291 - val_accuracy: 0.9615
DEBUG: 2023-08-02 14:59:30,710: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 14:59:35,120: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 14:59:35,120: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 14:59:35,483: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 14:59:42,791: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3344 - accuracy: 0.9045 - val_loss: 0.2604 - val_accuracy: 0.9251
DEBUG: 2023-08-02 14:59:46,828: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.5373 - accuracy: 0.7941 - val_loss: 0.4018 - val_accuracy: 0.8467
DEBUG: 2023-08-02 14:59:50,961: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2505 - accuracy: 0.9249 - val_loss: 0.2303 - val_accuracy: 0.9196
DEBUG: 2023-08-02 14:59:55,423: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1902 - accuracy: 0.9387 - val_loss: 0.211 - val_accuracy: 0.9379
DEBUG: 2023-08-02 14:59:59,616: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1598 - accuracy: 0.9504 - val_loss: 0.1855 - val_accuracy: 0.9413
DEBUG: 2023-08-02 15:00:03,983: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1681 - accuracy: 0.9467 - val_loss: 0.1388 - val_accuracy: 0.9534
DEBUG: 2023-08-02 15:00:08,339: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1657 - accuracy: 0.9487 - val_loss: 0.1771 - val_accuracy: 0.9291
DEBUG: 2023-08-02 15:00:12,915: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1581 - accuracy: 0.9517 - val_loss: 0.1666 - val_accuracy: 0.9521
DEBUG: 2023-08-02 15:00:17,307: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1366 - accuracy: 0.9524 - val_loss: 0.1676 - val_accuracy: 0.9311
DEBUG: 2023-08-02 15:00:21,475: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.2317 - accuracy: 0.933 - val_loss: 0.2115 - val_accuracy: 0.9433
DEBUG: 2023-08-02 15:00:25,741: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1291 - accuracy: 0.9553 - val_loss: 0.1559 - val_accuracy: 0.9548
DEBUG: 2023-08-02 15:00:33,863: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 15:00:33,863: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 15:00:34,204: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 15:00:41,488: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3323 - accuracy: 0.9198 - val_loss: 0.2677 - val_accuracy: 0.9237
DEBUG: 2023-08-02 15:00:45,651: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2359 - accuracy: 0.9372 - val_loss: 0.2101 - val_accuracy: 0.9318
DEBUG: 2023-08-02 15:00:49,884: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2064 - accuracy: 0.9418 - val_loss: 0.2322 - val_accuracy: 0.9298
DEBUG: 2023-08-02 15:00:53,952: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1605 - accuracy: 0.9551 - val_loss: 0.1528 - val_accuracy: 0.9426
DEBUG: 2023-08-02 15:00:58,022: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1733 - accuracy: 0.9514 - val_loss: 0.156 - val_accuracy: 0.9541
DEBUG: 2023-08-02 15:01:02,127: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.3944 - accuracy: 0.838 - val_loss: 0.3714 - val_accuracy: 0.8386
DEBUG: 2023-08-02 15:01:06,220: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.3639 - accuracy: 0.8545 - val_loss: 0.3242 - val_accuracy: 0.8771
DEBUG: 2023-08-02 15:01:10,314: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.312 - accuracy: 0.8903 - val_loss: 0.2652 - val_accuracy: 0.9061
DEBUG: 2023-08-02 15:01:15,611: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 15:01:15,612: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 15:01:15,935: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 15:01:23,766: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.5224 - accuracy: 0.8174 - val_loss: 0.4458 - val_accuracy: 0.8285
DEBUG: 2023-08-02 15:01:28,041: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.4109 - accuracy: 0.8812 - val_loss: 0.3387 - val_accuracy: 0.9041
DEBUG: 2023-08-02 15:01:32,251: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2523 - accuracy: 0.932 - val_loss: 0.2265 - val_accuracy: 0.9426
DEBUG: 2023-08-02 15:01:36,402: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1988 - accuracy: 0.9478 - val_loss: 0.216 - val_accuracy: 0.9372
DEBUG: 2023-08-02 15:01:40,572: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.2496 - accuracy: 0.9354 - val_loss: 0.2257 - val_accuracy: 0.9338
DEBUG: 2023-08-02 15:01:44,643: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.44 - accuracy: 0.8422 - val_loss: 0.3636 - val_accuracy: 0.8751
DEBUG: 2023-08-02 15:01:48,759: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.3073 - accuracy: 0.9119 - val_loss: 0.2493 - val_accuracy: 0.9332
DEBUG: 2023-08-02 15:01:52,849: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.2919 - accuracy: 0.9279 - val_loss: 0.2316 - val_accuracy: 0.9372
DEBUG: 2023-08-02 15:01:59,154: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 15:01:59,155: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 15:01:59,476: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 15:02:06,894: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.7644 - accuracy: 0.7318 - val_loss: 0.5627 - val_accuracy: 0.788
DEBUG: 2023-08-02 15:02:11,166: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2515 - accuracy: 0.9374 - val_loss: 0.1937 - val_accuracy: 0.9494
DEBUG: 2023-08-02 15:02:15,248: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.3284 - accuracy: 0.8969 - val_loss: 0.2694 - val_accuracy: 0.9169
DEBUG: 2023-08-02 15:02:19,426: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1982 - accuracy: 0.943 - val_loss: 0.1729 - val_accuracy: 0.9527
DEBUG: 2023-08-02 15:02:23,688: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1643 - accuracy: 0.9522 - val_loss: 0.1349 - val_accuracy: 0.9534
DEBUG: 2023-08-02 15:02:27,944: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1705 - accuracy: 0.9492 - val_loss: 0.152 - val_accuracy: 0.9575
DEBUG: 2023-08-02 15:02:32,195: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1554 - accuracy: 0.9524 - val_loss: 0.1549 - val_accuracy: 0.9446
DEBUG: 2023-08-02 15:02:36,449: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.143 - accuracy: 0.9563 - val_loss: 0.1486 - val_accuracy: 0.9568
DEBUG: 2023-08-02 15:02:40,690: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1185 - accuracy: 0.96 - val_loss: 0.1433 - val_accuracy: 0.9514
DEBUG: 2023-08-02 15:02:44,944: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1919 - accuracy: 0.9424 - val_loss: 0.1691 - val_accuracy: 0.9386
DEBUG: 2023-08-02 15:02:49,141: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1242 - accuracy: 0.9605 - val_loss: 0.1406 - val_accuracy: 0.9635
DEBUG: 2023-08-02 15:02:53,380: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1578 - accuracy: 0.9517 - val_loss: 0.16 - val_accuracy: 0.9554
DEBUG: 2023-08-02 15:02:59,886: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 15:02:59,888: 2155350369.py: <module>: ---train---
DEBUG: 2023-08-02 15:02:59,889: 2155350369.py: <module>: logloss=0.121251
DEBUG: 2023-08-02 15:02:59,890: 2155350369.py: <module>: accuracy=0.959864
DEBUG: 2023-08-02 15:02:59,891: 2155350369.py: <module>: precision=0.963356
DEBUG: 2023-08-02 15:02:59,892: 2155350369.py: <module>: recall=0.962778
DEBUG: 2023-08-02 15:02:59,892: 2155350369.py: <module>: f1=0.962901
DEBUG: 2023-08-02 15:02:59,893: 2155350369.py: <module>: per-class f1={'LAYING': 0.999823, 'WALKING': 0.995809, 'WALKING_UPSTAIRS': 0.99342, 'WALKING_DOWNSTAIRS': 0.997331, 'SITTING': 0.890096, 'STANDING': 0.900924}
DEBUG: 2023-08-02 15:02:59,894: 2155350369.py: <module>: ---valid---
DEBUG: 2023-08-02 15:02:59,895: 2155350369.py: <module>: logloss=0.131867
DEBUG: 2023-08-02 15:02:59,896: 2155350369.py: <module>: accuracy=0.958006
DEBUG: 2023-08-02 15:02:59,897: 2155350369.py: <module>: precision=0.961269
DEBUG: 2023-08-02 15:02:59,898: 2155350369.py: <module>: recall=0.960817
DEBUG: 2023-08-02 15:02:59,900: 2155350369.py: <module>: f1=0.960795
DEBUG: 2023-08-02 15:02:59,901: 2155350369.py: <module>: per-class f1={'LAYING': 0.999646, 'WALKING': 0.991823, 'WALKING_UPSTAIRS': 0.989771, 'WALKING_DOWNSTAIRS': 0.993942, 'SITTING': 0.888091, 'STANDING': 0.901495}
DEBUG: 2023-08-02 15:02:59,902: 2155350369.py: <module>: ---test---
DEBUG: 2023-08-02 15:02:59,903: 2155350369.py: <module>: logloss=0.448826
DEBUG: 2023-08-02 15:02:59,904: 2155350369.py: <module>: accuracy=0.929703
DEBUG: 2023-08-02 15:02:59,905: 2155350369.py: <module>: precision=0.93117
DEBUG: 2023-08-02 15:02:59,906: 2155350369.py: <module>: recall=0.930955
DEBUG: 2023-08-02 15:02:59,907: 2155350369.py: <module>: f1=0.930292
DEBUG: 2023-08-02 15:02:59,908: 2155350369.py: <module>: per-class f1={'LAYING': 0.986298, 'WALKING': 0.935177, 'WALKING_UPSTAIRS': 0.927888, 'WALKING_DOWNSTAIRS': 0.95718, 'SITTING': 0.87994, 'STANDING': 0.895265}
DEBUG: 2023-08-02 15:02:59,919: 1672468834.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 15:02:59,922: 1672468834.py: <module>: accuracy=0.9375208820581357
DEBUG: 2023-08-02 15:02:59,926: 1672468834.py: <module>: precision=0.9384635226408576
DEBUG: 2023-08-02 15:02:59,930: 1672468834.py: <module>: recall=0.9391373100113056
DEBUG: 2023-08-02 15:02:59,936: 1672468834.py: <module>: f1=0.9382964724941535
DEBUG: 2023-08-02 15:02:59,939: 1672468834.py: <module>: per-class f1=[0.99634369 0.94780793 0.9527897  0.95852535 0.87367406 0.9006381 ]
