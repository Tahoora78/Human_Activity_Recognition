DEBUG: 2023-08-02 08:31:15,411: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/rnn_lstm_logs/deep-conv-lstm-20230802-083115/deep-conv-lstm-20230802-083115.log
DEBUG: 2023-08-02 08:31:26,348: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:31:26,350: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 08:31:26,352: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 08:31:26,353: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 08:31:26,354: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 08:31:26,355: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 08:31:26,356: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 08:31:26,357: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 08:31:26,358: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 08:31:26,358: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 08:31:26,359: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 08:31:26,360: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 08:31:26,361: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 08:31:26,363: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 08:31:26,363: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 08:31:26,364: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 08:31:26,392: 582463155.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-08-02 08:31:26,422: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:31:26,423: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:31:28,659: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:31:33,022: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 08:31:36,539: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.434 - accuracy: 0.8688 - val_loss: 0.4692 - val_accuracy: 0.8327
DEBUG: 2023-08-02 08:31:40,462: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2423 - accuracy: 0.9362 - val_loss: 0.1896 - val_accuracy: 0.9507
DEBUG: 2023-08-02 08:31:44,311: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2109 - accuracy: 0.9391 - val_loss: 0.185 - val_accuracy: 0.9514
DEBUG: 2023-08-02 08:31:48,587: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1806 - accuracy: 0.9451 - val_loss: 0.3161 - val_accuracy: 0.913
DEBUG: 2023-08-02 08:31:52,403: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1526 - accuracy: 0.9531 - val_loss: 0.1384 - val_accuracy: 0.9642
DEBUG: 2023-08-02 08:31:56,159: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1584 - accuracy: 0.9473 - val_loss: 0.127 - val_accuracy: 0.9656
DEBUG: 2023-08-02 08:31:59,753: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.189 - accuracy: 0.9419 - val_loss: 0.1525 - val_accuracy: 0.9622
DEBUG: 2023-08-02 08:32:03,348: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1291 - accuracy: 0.9536 - val_loss: 0.1206 - val_accuracy: 0.9669
DEBUG: 2023-08-02 08:32:06,978: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1274 - accuracy: 0.9544 - val_loss: 0.1314 - val_accuracy: 0.9669
DEBUG: 2023-08-02 08:32:10,557: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1255 - accuracy: 0.9521 - val_loss: 0.1007 - val_accuracy: 0.9683
DEBUG: 2023-08-02 08:32:14,140: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.12 - accuracy: 0.9536 - val_loss: 0.1735 - val_accuracy: 0.9602
DEBUG: 2023-08-02 08:32:17,765: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1391 - accuracy: 0.9516 - val_loss: 0.1326 - val_accuracy: 0.9541
DEBUG: 2023-08-02 08:32:21,330: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1085 - accuracy: 0.9595 - val_loss: 0.1024 - val_accuracy: 0.9669
DEBUG: 2023-08-02 08:32:21,521: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 08:32:25,487: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:32:25,488: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:32:25,806: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:32:32,866: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3812 - accuracy: 0.8781 - val_loss: 0.3293 - val_accuracy: 0.896
DEBUG: 2023-08-02 08:32:36,927: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2294 - accuracy: 0.9426 - val_loss: 0.2118 - val_accuracy: 0.9433
DEBUG: 2023-08-02 08:32:40,920: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.3261 - accuracy: 0.9134 - val_loss: 0.2312 - val_accuracy: 0.9318
DEBUG: 2023-08-02 08:32:44,707: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1787 - accuracy: 0.95 - val_loss: 0.1626 - val_accuracy: 0.9453
DEBUG: 2023-08-02 08:32:48,513: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.3809 - accuracy: 0.8565 - val_loss: 0.3521 - val_accuracy: 0.8785
DEBUG: 2023-08-02 08:32:52,709: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.3426 - accuracy: 0.8783 - val_loss: 0.259 - val_accuracy: 0.9149
DEBUG: 2023-08-02 08:32:57,074: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.2576 - accuracy: 0.9237 - val_loss: 0.2223 - val_accuracy: 0.9311
DEBUG: 2023-08-02 08:33:03,525: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:33:03,526: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:33:03,847: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:33:11,190: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3629 - accuracy: 0.907 - val_loss: 0.3566 - val_accuracy: 0.9021
DEBUG: 2023-08-02 08:33:15,565: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2463 - accuracy: 0.9362 - val_loss: 0.206 - val_accuracy: 0.9365
DEBUG: 2023-08-02 08:33:20,486: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1871 - accuracy: 0.9497 - val_loss: 0.1611 - val_accuracy: 0.9446
DEBUG: 2023-08-02 08:33:25,732: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1554 - accuracy: 0.9549 - val_loss: 0.1471 - val_accuracy: 0.946
DEBUG: 2023-08-02 08:33:29,686: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1593 - accuracy: 0.9541 - val_loss: 0.1363 - val_accuracy: 0.9494
DEBUG: 2023-08-02 08:33:33,468: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1771 - accuracy: 0.9485 - val_loss: 0.1627 - val_accuracy: 0.9467
DEBUG: 2023-08-02 08:33:37,331: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1453 - accuracy: 0.9554 - val_loss: 0.15 - val_accuracy: 0.9473
DEBUG: 2023-08-02 08:33:41,260: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.2117 - accuracy: 0.9315 - val_loss: 0.1555 - val_accuracy: 0.95
DEBUG: 2023-08-02 08:33:45,416: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:33:45,417: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:33:45,678: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:33:52,642: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3281 - accuracy: 0.9021 - val_loss: 0.3159 - val_accuracy: 0.9142
DEBUG: 2023-08-02 08:33:56,357: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.3067 - accuracy: 0.9021 - val_loss: 0.2125 - val_accuracy: 0.9345
DEBUG: 2023-08-02 08:34:00,082: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.2664 - accuracy: 0.9296 - val_loss: 0.1934 - val_accuracy: 0.946
DEBUG: 2023-08-02 08:34:03,936: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2136 - accuracy: 0.9448 - val_loss: 0.17 - val_accuracy: 0.9467
DEBUG: 2023-08-02 08:34:07,713: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1986 - accuracy: 0.9424 - val_loss: 0.137 - val_accuracy: 0.9561
DEBUG: 2023-08-02 08:34:11,557: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1533 - accuracy: 0.9521 - val_loss: 0.1249 - val_accuracy: 0.9554
DEBUG: 2023-08-02 08:34:15,311: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1616 - accuracy: 0.9477 - val_loss: 0.1468 - val_accuracy: 0.95
DEBUG: 2023-08-02 08:34:19,190: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.2225 - accuracy: 0.9367 - val_loss: 0.2113 - val_accuracy: 0.9386
DEBUG: 2023-08-02 08:34:22,895: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1563 - accuracy: 0.9527 - val_loss: 0.138 - val_accuracy: 0.9534
DEBUG: 2023-08-02 08:34:26,821: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1343 - accuracy: 0.9556 - val_loss: 0.1233 - val_accuracy: 0.9534
DEBUG: 2023-08-02 08:34:30,708: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1176 - accuracy: 0.9605 - val_loss: 0.1381 - val_accuracy: 0.9595
DEBUG: 2023-08-02 08:34:34,308: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1242 - accuracy: 0.959 - val_loss: 0.1153 - val_accuracy: 0.9608
DEBUG: 2023-08-02 08:34:37,951: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.1158 - accuracy: 0.9588 - val_loss: 0.1164 - val_accuracy: 0.9588
DEBUG: 2023-08-02 08:34:41,860: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.1023 - accuracy: 0.96 - val_loss: 0.1187 - val_accuracy: 0.9649
DEBUG: 2023-08-02 08:34:45,585: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.1091 - accuracy: 0.9592 - val_loss: 0.1091 - val_accuracy: 0.9608
DEBUG: 2023-08-02 08:34:49,351: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.2614 - accuracy: 0.9055 - val_loss: 0.205 - val_accuracy: 0.9244
DEBUG: 2023-08-02 08:34:55,615: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:34:55,616: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:34:55,872: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:35:02,812: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3585 - accuracy: 0.9036 - val_loss: 0.2307 - val_accuracy: 0.9365
DEBUG: 2023-08-02 08:35:06,866: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2821 - accuracy: 0.9186 - val_loss: 0.3351 - val_accuracy: 0.8906
DEBUG: 2023-08-02 08:35:10,448: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.353 - accuracy: 0.8788 - val_loss: 0.2519 - val_accuracy: 0.923
DEBUG: 2023-08-02 08:35:14,324: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1964 - accuracy: 0.9364 - val_loss: 0.1679 - val_accuracy: 0.948
DEBUG: 2023-08-02 08:35:17,882: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1746 - accuracy: 0.9458 - val_loss: 0.1544 - val_accuracy: 0.948
DEBUG: 2023-08-02 08:35:21,305: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1729 - accuracy: 0.9433 - val_loss: 0.152 - val_accuracy: 0.9554
DEBUG: 2023-08-02 08:35:24,816: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1531 - accuracy: 0.9509 - val_loss: 0.1461 - val_accuracy: 0.9521
DEBUG: 2023-08-02 08:35:28,589: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1428 - accuracy: 0.9509 - val_loss: 0.1279 - val_accuracy: 0.9541
DEBUG: 2023-08-02 08:35:32,148: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1623 - accuracy: 0.9477 - val_loss: 0.175 - val_accuracy: 0.9521
DEBUG: 2023-08-02 08:35:36,233: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1863 - accuracy: 0.936 - val_loss: 0.1472 - val_accuracy: 0.9467
DEBUG: 2023-08-02 08:35:39,923: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1272 - accuracy: 0.9559 - val_loss: 0.137 - val_accuracy: 0.9494
DEBUG: 2023-08-02 08:35:43,835: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1383 - accuracy: 0.9541 - val_loss: 0.1243 - val_accuracy: 0.9595
DEBUG: 2023-08-02 08:35:47,465: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.2442 - accuracy: 0.9151 - val_loss: 0.1862 - val_accuracy: 0.9365
DEBUG: 2023-08-02 08:35:51,317: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.1507 - accuracy: 0.9494 - val_loss: 0.1475 - val_accuracy: 0.9554
DEBUG: 2023-08-02 08:35:55,152: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.1499 - accuracy: 0.9504 - val_loss: 0.1247 - val_accuracy: 0.9527
DEBUG: 2023-08-02 08:36:00,197: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 08:36:00,200: 2155350369.py: <module>: ---train---
DEBUG: 2023-08-02 08:36:00,203: 2155350369.py: <module>: logloss=0.113077
DEBUG: 2023-08-02 08:36:00,204: 2155350369.py: <module>: accuracy=0.95956
DEBUG: 2023-08-02 08:36:00,205: 2155350369.py: <module>: precision=0.963643
DEBUG: 2023-08-02 08:36:00,207: 2155350369.py: <module>: recall=0.962455
DEBUG: 2023-08-02 08:36:00,208: 2155350369.py: <module>: f1=0.962744
DEBUG: 2023-08-02 08:36:00,212: 2155350369.py: <module>: per-class f1={'LAYING': 0.999735, 'WALKING': 0.996941, 'WALKING_UPSTAIRS': 0.997315, 'WALKING_DOWNSTAIRS': 0.998226, 'SITTING': 0.884437, 'STANDING': 0.899809}
DEBUG: 2023-08-02 08:36:00,213: 2155350369.py: <module>: ---valid---
DEBUG: 2023-08-02 08:36:00,214: 2155350369.py: <module>: logloss=0.119423
DEBUG: 2023-08-02 08:36:00,216: 2155350369.py: <module>: accuracy=0.958411
DEBUG: 2023-08-02 08:36:00,217: 2155350369.py: <module>: precision=0.962794
DEBUG: 2023-08-02 08:36:00,218: 2155350369.py: <module>: recall=0.96106
DEBUG: 2023-08-02 08:36:00,219: 2155350369.py: <module>: f1=0.961431
DEBUG: 2023-08-02 08:36:00,220: 2155350369.py: <module>: per-class f1={'LAYING': 0.999296, 'WALKING': 0.994744, 'WALKING_UPSTAIRS': 0.993819, 'WALKING_DOWNSTAIRS': 0.996957, 'SITTING': 0.883314, 'STANDING': 0.900458}
DEBUG: 2023-08-02 08:36:00,220: 2155350369.py: <module>: ---test---
DEBUG: 2023-08-02 08:36:00,222: 2155350369.py: <module>: logloss=0.466048
DEBUG: 2023-08-02 08:36:00,223: 2155350369.py: <module>: accuracy=0.930905
DEBUG: 2023-08-02 08:36:00,224: 2155350369.py: <module>: precision=0.931519
DEBUG: 2023-08-02 08:36:00,225: 2155350369.py: <module>: recall=0.93234
DEBUG: 2023-08-02 08:36:00,226: 2155350369.py: <module>: f1=0.93088
DEBUG: 2023-08-02 08:36:00,228: 2155350369.py: <module>: per-class f1={'LAYING': 0.987438, 'WALKING': 0.9363, 'WALKING_UPSTAIRS': 0.939407, 'WALKING_DOWNSTAIRS': 0.937158, 'SITTING': 0.882464, 'STANDING': 0.902512}
DEBUG: 2023-08-02 08:36:00,239: 3423627708.py: <module>: ---Final Test Scores Averaged over Folds---
