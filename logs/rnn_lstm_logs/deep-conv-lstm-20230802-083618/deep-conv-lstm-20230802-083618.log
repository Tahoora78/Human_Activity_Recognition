DEBUG: 2023-08-02 08:36:18,079: 62444462.py: <module>: /home/tahoora/Projects/college_project/Human_Activity_Recognition/notebooks/../logs/rnn_lstm_logs/deep-conv-lstm-20230802-083618/deep-conv-lstm-20230802-083618.log
DEBUG: 2023-08-02 08:36:29,093: 62444462.py: <module>: X_train.shape=(7406, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:36:29,094: 62444462.py: <module>: y_train.shape=(7406, 1) y_test.shape=(2993, 1)
DEBUG: 2023-08-02 08:36:29,097: utils.py: check_class_balance: train labels
DEBUG: 2023-08-02 08:36:29,097: utils.py: check_class_balance: LAYING (0): 1412 samples (19.07 %)
DEBUG: 2023-08-02 08:36:29,098: utils.py: check_class_balance: WALKING (1): 1224 samples (16.53 %)
DEBUG: 2023-08-02 08:36:29,099: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 1072 samples (14.47 %)
DEBUG: 2023-08-02 08:36:29,100: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 987 samples (13.33 %)
DEBUG: 2023-08-02 08:36:29,101: utils.py: check_class_balance: SITTING (4): 1290 samples (17.42 %)
DEBUG: 2023-08-02 08:36:29,102: utils.py: check_class_balance: STANDING (5): 1421 samples (19.19 %)
DEBUG: 2023-08-02 08:36:29,102: utils.py: check_class_balance: test labels
DEBUG: 2023-08-02 08:36:29,103: utils.py: check_class_balance: LAYING (0): 545 samples (18.21 %)
DEBUG: 2023-08-02 08:36:29,104: utils.py: check_class_balance: WALKING (1): 496 samples (16.57 %)
DEBUG: 2023-08-02 08:36:29,105: utils.py: check_class_balance: WALKING_UPSTAIRS (2): 470 samples (15.7 %)
DEBUG: 2023-08-02 08:36:29,106: utils.py: check_class_balance: WALKING_DOWNSTAIRS (3): 419 samples (14.0 %)
DEBUG: 2023-08-02 08:36:29,106: utils.py: check_class_balance: SITTING (4): 507 samples (16.94 %)
DEBUG: 2023-08-02 08:36:29,107: utils.py: check_class_balance: STANDING (5): 556 samples (18.58 %)
DEBUG: 2023-08-02 08:36:29,136: 582463155.py: <module>: dcl_params={'batch_size': 128, 'epochs': 10000, 'lr': 0.001, 'verbose': 0}
DEBUG: 2023-08-02 08:36:29,169: 2623015374.py: <module>: X_tr.shape=(5924, 128, 6, 1) X_val.shape=(1482, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:36:29,170: 2623015374.py: <module>: y_tr.shape=(5924, 6) y_val.shape=(1482, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:36:31,549: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:36:38,140: attrs.py: create: Creating converter from 5 to 3
DEBUG: 2023-08-02 08:36:43,471: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2636 - accuracy: 0.9299 - val_loss: 0.228 - val_accuracy: 0.9393
DEBUG: 2023-08-02 08:36:49,420: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.18 - accuracy: 0.9436 - val_loss: 0.1475 - val_accuracy: 0.9555
DEBUG: 2023-08-02 08:36:55,184: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.142 - accuracy: 0.9519 - val_loss: 0.119 - val_accuracy: 0.9629
DEBUG: 2023-08-02 08:37:01,427: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2035 - accuracy: 0.9335 - val_loss: 0.1401 - val_accuracy: 0.9548
DEBUG: 2023-08-02 08:37:07,494: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1497 - accuracy: 0.9494 - val_loss: 0.1212 - val_accuracy: 0.9656
DEBUG: 2023-08-02 08:37:13,219: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1108 - accuracy: 0.958 - val_loss: 0.1039 - val_accuracy: 0.9622
DEBUG: 2023-08-02 08:37:19,285: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1088 - accuracy: 0.957 - val_loss: 0.1104 - val_accuracy: 0.9676
DEBUG: 2023-08-02 08:37:25,192: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.102 - accuracy: 0.9602 - val_loss: 0.0985 - val_accuracy: 0.9696
DEBUG: 2023-08-02 08:37:31,420: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.0982 - accuracy: 0.9588 - val_loss: 0.1071 - val_accuracy: 0.9683
DEBUG: 2023-08-02 08:37:37,311: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1164 - accuracy: 0.9539 - val_loss: 0.1126 - val_accuracy: 0.9669
DEBUG: 2023-08-02 08:37:43,236: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1555 - accuracy: 0.9448 - val_loss: 0.1241 - val_accuracy: 0.9636
DEBUG: 2023-08-02 08:37:45,832: attrs.py: __getitem__: Creating converter from 3 to 5
DEBUG: 2023-08-02 08:37:51,805: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:37:51,805: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:37:52,311: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:38:03,529: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2577 - accuracy: 0.9284 - val_loss: 0.1959 - val_accuracy: 0.9359
DEBUG: 2023-08-02 08:38:10,259: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2312 - accuracy: 0.9328 - val_loss: 0.1847 - val_accuracy: 0.9446
DEBUG: 2023-08-02 08:38:16,792: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1734 - accuracy: 0.9467 - val_loss: 0.1702 - val_accuracy: 0.95
DEBUG: 2023-08-02 08:38:23,633: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.2445 - accuracy: 0.944 - val_loss: 0.2786 - val_accuracy: 0.9338
DEBUG: 2023-08-02 08:38:30,693: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1353 - accuracy: 0.9538 - val_loss: 0.1347 - val_accuracy: 0.9494
DEBUG: 2023-08-02 08:38:37,557: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1433 - accuracy: 0.958 - val_loss: 0.3552 - val_accuracy: 0.9278
DEBUG: 2023-08-02 08:38:43,482: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1166 - accuracy: 0.9598 - val_loss: 0.1555 - val_accuracy: 0.9217
DEBUG: 2023-08-02 08:38:49,344: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.129 - accuracy: 0.9603 - val_loss: 0.1321 - val_accuracy: 0.9554
DEBUG: 2023-08-02 08:38:55,329: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1171 - accuracy: 0.9637 - val_loss: 0.1126 - val_accuracy: 0.9595
DEBUG: 2023-08-02 08:39:01,207: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.1066 - accuracy: 0.9666 - val_loss: 0.105 - val_accuracy: 0.9608
DEBUG: 2023-08-02 08:39:06,913: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1491 - accuracy: 0.9634 - val_loss: 0.164 - val_accuracy: 0.9514
DEBUG: 2023-08-02 08:39:12,785: keras_callback.py: on_epoch_end: Epoch 120/10000 - loss: 0.1051 - accuracy: 0.9686 - val_loss: 0.0982 - val_accuracy: 0.9635
DEBUG: 2023-08-02 08:39:18,434: keras_callback.py: on_epoch_end: Epoch 130/10000 - loss: 0.107 - accuracy: 0.9662 - val_loss: 0.1119 - val_accuracy: 0.9568
DEBUG: 2023-08-02 08:39:24,288: keras_callback.py: on_epoch_end: Epoch 140/10000 - loss: 0.093 - accuracy: 0.9728 - val_loss: 0.099 - val_accuracy: 0.9683
DEBUG: 2023-08-02 08:39:30,086: keras_callback.py: on_epoch_end: Epoch 150/10000 - loss: 0.0976 - accuracy: 0.972 - val_loss: 0.099 - val_accuracy: 0.9669
DEBUG: 2023-08-02 08:39:35,807: keras_callback.py: on_epoch_end: Epoch 160/10000 - loss: 0.0888 - accuracy: 0.9664 - val_loss: 0.0812 - val_accuracy: 0.9683
DEBUG: 2023-08-02 08:39:41,602: keras_callback.py: on_epoch_end: Epoch 170/10000 - loss: 0.5503 - accuracy: 0.8673 - val_loss: 0.1865 - val_accuracy: 0.9433
DEBUG: 2023-08-02 08:39:47,241: keras_callback.py: on_epoch_end: Epoch 180/10000 - loss: 0.1139 - accuracy: 0.9561 - val_loss: 0.1016 - val_accuracy: 0.9622
DEBUG: 2023-08-02 08:39:58,877: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:39:58,878: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:39:59,470: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:40:10,527: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2075 - accuracy: 0.9467 - val_loss: 0.1804 - val_accuracy: 0.9453
DEBUG: 2023-08-02 08:40:17,064: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1504 - accuracy: 0.9566 - val_loss: 0.1487 - val_accuracy: 0.9507
DEBUG: 2023-08-02 08:40:23,990: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1192 - accuracy: 0.9595 - val_loss: 0.1344 - val_accuracy: 0.9527
DEBUG: 2023-08-02 08:40:30,463: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1102 - accuracy: 0.9612 - val_loss: 0.1293 - val_accuracy: 0.9554
DEBUG: 2023-08-02 08:40:37,405: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1132 - accuracy: 0.9619 - val_loss: 0.114 - val_accuracy: 0.9588
DEBUG: 2023-08-02 08:40:43,955: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1461 - accuracy: 0.9586 - val_loss: 0.1374 - val_accuracy: 0.9548
DEBUG: 2023-08-02 08:40:50,901: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.1371 - accuracy: 0.9588 - val_loss: 0.1304 - val_accuracy: 0.9575
DEBUG: 2023-08-02 08:40:57,753: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1039 - accuracy: 0.9654 - val_loss: 0.1054 - val_accuracy: 0.9635
DEBUG: 2023-08-02 08:41:04,946: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1125 - accuracy: 0.9598 - val_loss: 0.1222 - val_accuracy: 0.9521
DEBUG: 2023-08-02 08:41:12,248: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.0891 - accuracy: 0.9644 - val_loss: 0.1099 - val_accuracy: 0.95
DEBUG: 2023-08-02 08:41:19,456: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1205 - accuracy: 0.9593 - val_loss: 0.1092 - val_accuracy: 0.9581
DEBUG: 2023-08-02 08:41:28,232: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:41:28,233: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:41:28,790: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:41:40,184: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.2346 - accuracy: 0.9359 - val_loss: 0.176 - val_accuracy: 0.95
DEBUG: 2023-08-02 08:41:46,301: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.1503 - accuracy: 0.9546 - val_loss: 0.123 - val_accuracy: 0.9541
DEBUG: 2023-08-02 08:41:52,355: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1506 - accuracy: 0.9556 - val_loss: 0.1319 - val_accuracy: 0.9588
DEBUG: 2023-08-02 08:41:58,364: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.7911 - accuracy: 0.77 - val_loss: 0.3969 - val_accuracy: 0.9169
DEBUG: 2023-08-02 08:42:04,596: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.3861 - accuracy: 0.8837 - val_loss: 0.292 - val_accuracy: 0.9115
DEBUG: 2023-08-02 08:42:10,836: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1688 - accuracy: 0.9526 - val_loss: 0.1993 - val_accuracy: 0.9413
DEBUG: 2023-08-02 08:42:20,966: 2623015374.py: <module>: X_tr.shape=(5925, 128, 6, 1) X_val.shape=(1481, 128, 6, 1) X_test.shape=(2993, 128, 6, 1)
DEBUG: 2023-08-02 08:42:20,967: 2623015374.py: <module>: y_tr.shape=(5925, 6) y_val.shape=(1481, 6) y_test.shape=(2993, 6)
WARNING: 2023-08-02 08:42:21,590: optimizer.py: _process_kwargs: `lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
DEBUG: 2023-08-02 08:42:33,571: keras_callback.py: on_epoch_end: Epoch 10/10000 - loss: 0.3199 - accuracy: 0.9143 - val_loss: 0.252 - val_accuracy: 0.9244
DEBUG: 2023-08-02 08:42:40,436: keras_callback.py: on_epoch_end: Epoch 20/10000 - loss: 0.2055 - accuracy: 0.9406 - val_loss: 0.206 - val_accuracy: 0.944
DEBUG: 2023-08-02 08:42:47,463: keras_callback.py: on_epoch_end: Epoch 30/10000 - loss: 0.1693 - accuracy: 0.9538 - val_loss: 0.1562 - val_accuracy: 0.9527
DEBUG: 2023-08-02 08:42:54,735: keras_callback.py: on_epoch_end: Epoch 40/10000 - loss: 0.1308 - accuracy: 0.9563 - val_loss: 0.1292 - val_accuracy: 0.9581
DEBUG: 2023-08-02 08:43:02,026: keras_callback.py: on_epoch_end: Epoch 50/10000 - loss: 0.1221 - accuracy: 0.9593 - val_loss: 0.1219 - val_accuracy: 0.9568
DEBUG: 2023-08-02 08:43:08,813: keras_callback.py: on_epoch_end: Epoch 60/10000 - loss: 0.1188 - accuracy: 0.9565 - val_loss: 0.1379 - val_accuracy: 0.9561
DEBUG: 2023-08-02 08:43:15,606: keras_callback.py: on_epoch_end: Epoch 70/10000 - loss: 0.214 - accuracy: 0.9401 - val_loss: 0.162 - val_accuracy: 0.9413
DEBUG: 2023-08-02 08:43:22,330: keras_callback.py: on_epoch_end: Epoch 80/10000 - loss: 0.1135 - accuracy: 0.9635 - val_loss: 0.1121 - val_accuracy: 0.9649
DEBUG: 2023-08-02 08:43:29,481: keras_callback.py: on_epoch_end: Epoch 90/10000 - loss: 0.1235 - accuracy: 0.9647 - val_loss: 0.1068 - val_accuracy: 0.971
DEBUG: 2023-08-02 08:43:36,568: keras_callback.py: on_epoch_end: Epoch 100/10000 - loss: 0.116 - accuracy: 0.9592 - val_loss: 0.1251 - val_accuracy: 0.9588
DEBUG: 2023-08-02 08:43:43,659: keras_callback.py: on_epoch_end: Epoch 110/10000 - loss: 0.1703 - accuracy: 0.9475 - val_loss: 0.2413 - val_accuracy: 0.9419
DEBUG: 2023-08-02 08:43:54,741: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 08:43:54,743: 2155350369.py: <module>: ---train---
DEBUG: 2023-08-02 08:43:54,744: 2155350369.py: <module>: logloss=0.088451
DEBUG: 2023-08-02 08:43:54,745: 2155350369.py: <module>: accuracy=0.967357
DEBUG: 2023-08-02 08:43:54,746: 2155350369.py: <module>: precision=0.971215
DEBUG: 2023-08-02 08:43:54,747: 2155350369.py: <module>: recall=0.969615
DEBUG: 2023-08-02 08:43:54,749: 2155350369.py: <module>: f1=0.970031
DEBUG: 2023-08-02 08:43:54,752: 2155350369.py: <module>: per-class f1={'LAYING': 0.999911, 'WALKING': 0.99949, 'WALKING_UPSTAIRS': 0.999883, 'WALKING_DOWNSTAIRS': 0.999365, 'SITTING': 0.903441, 'STANDING': 0.918092}
DEBUG: 2023-08-02 08:43:54,753: 2155350369.py: <module>: ---valid---
DEBUG: 2023-08-02 08:43:54,754: 2155350369.py: <module>: logloss=0.099496
DEBUG: 2023-08-02 08:43:54,755: 2155350369.py: <module>: accuracy=0.963542
DEBUG: 2023-08-02 08:43:54,757: 2155350369.py: <module>: precision=0.967449
DEBUG: 2023-08-02 08:43:54,757: 2155350369.py: <module>: recall=0.965998
DEBUG: 2023-08-02 08:43:54,758: 2155350369.py: <module>: f1=0.966399
DEBUG: 2023-08-02 08:43:54,759: 2155350369.py: <module>: per-class f1={'LAYING': 0.999646, 'WALKING': 0.996324, 'WALKING_UPSTAIRS': 0.997673, 'WALKING_DOWNSTAIRS': 0.998473, 'SITTING': 0.895781, 'STANDING': 0.910495}
DEBUG: 2023-08-02 08:43:54,760: 2155350369.py: <module>: ---test---
DEBUG: 2023-08-02 08:43:54,760: 2155350369.py: <module>: logloss=0.493618
DEBUG: 2023-08-02 08:43:54,761: 2155350369.py: <module>: accuracy=0.933044
DEBUG: 2023-08-02 08:43:54,762: 2155350369.py: <module>: precision=0.934442
DEBUG: 2023-08-02 08:43:54,764: 2155350369.py: <module>: recall=0.934147
DEBUG: 2023-08-02 08:43:54,766: 2155350369.py: <module>: f1=0.933379
DEBUG: 2023-08-02 08:43:54,768: 2155350369.py: <module>: per-class f1={'LAYING': 0.996715, 'WALKING': 0.937023, 'WALKING_UPSTAIRS': 0.95634, 'WALKING_DOWNSTAIRS': 0.938727, 'SITTING': 0.87054, 'STANDING': 0.90093}
DEBUG: 2023-08-02 08:43:54,777: 3423627708.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 09:02:00,211: 2155350369.py: <module>: ---Cross Validation Scores---
DEBUG: 2023-08-02 09:02:00,213: 2155350369.py: <module>: ---train---
DEBUG: 2023-08-02 09:02:00,214: 2155350369.py: <module>: logloss=0.088451
DEBUG: 2023-08-02 09:02:00,215: 2155350369.py: <module>: accuracy=0.967357
DEBUG: 2023-08-02 09:02:00,216: 2155350369.py: <module>: precision=0.971215
DEBUG: 2023-08-02 09:02:00,217: 2155350369.py: <module>: recall=0.969615
DEBUG: 2023-08-02 09:02:00,218: 2155350369.py: <module>: f1=0.970031
DEBUG: 2023-08-02 09:02:00,219: 2155350369.py: <module>: per-class f1={'LAYING': 0.999911, 'WALKING': 0.99949, 'WALKING_UPSTAIRS': 0.999883, 'WALKING_DOWNSTAIRS': 0.999365, 'SITTING': 0.903441, 'STANDING': 0.918092}
DEBUG: 2023-08-02 09:02:00,220: 2155350369.py: <module>: ---valid---
DEBUG: 2023-08-02 09:02:00,221: 2155350369.py: <module>: logloss=0.099496
DEBUG: 2023-08-02 09:02:00,222: 2155350369.py: <module>: accuracy=0.963542
DEBUG: 2023-08-02 09:02:00,223: 2155350369.py: <module>: precision=0.967449
DEBUG: 2023-08-02 09:02:00,224: 2155350369.py: <module>: recall=0.965998
DEBUG: 2023-08-02 09:02:00,225: 2155350369.py: <module>: f1=0.966399
DEBUG: 2023-08-02 09:02:00,225: 2155350369.py: <module>: per-class f1={'LAYING': 0.999646, 'WALKING': 0.996324, 'WALKING_UPSTAIRS': 0.997673, 'WALKING_DOWNSTAIRS': 0.998473, 'SITTING': 0.895781, 'STANDING': 0.910495}
DEBUG: 2023-08-02 09:02:00,226: 2155350369.py: <module>: ---test---
DEBUG: 2023-08-02 09:02:00,227: 2155350369.py: <module>: logloss=0.493618
DEBUG: 2023-08-02 09:02:00,228: 2155350369.py: <module>: accuracy=0.933044
DEBUG: 2023-08-02 09:02:00,230: 2155350369.py: <module>: precision=0.934442
DEBUG: 2023-08-02 09:02:00,231: 2155350369.py: <module>: recall=0.934147
DEBUG: 2023-08-02 09:02:00,232: 2155350369.py: <module>: f1=0.933379
DEBUG: 2023-08-02 09:02:00,233: 2155350369.py: <module>: per-class f1={'LAYING': 0.996715, 'WALKING': 0.937023, 'WALKING_UPSTAIRS': 0.95634, 'WALKING_DOWNSTAIRS': 0.938727, 'SITTING': 0.87054, 'STANDING': 0.90093}
DEBUG: 2023-08-02 09:02:06,266: 1672468834.py: <module>: ---Final Test Scores Averaged over Folds---
DEBUG: 2023-08-02 09:02:06,269: 1672468834.py: <module>: accuracy=0.9391914467089877
DEBUG: 2023-08-02 09:02:06,272: 1672468834.py: <module>: precision=0.9404552489725337
DEBUG: 2023-08-02 09:02:06,275: 1672468834.py: <module>: recall=0.9407986208232254
DEBUG: 2023-08-02 09:02:06,278: 1672468834.py: <module>: f1=0.9396534686362434
DEBUG: 2023-08-02 09:02:06,281: 1672468834.py: <module>: per-class f1=[0.99908341 0.94367694 0.96566524 0.94570136 0.87536232 0.90843155]
